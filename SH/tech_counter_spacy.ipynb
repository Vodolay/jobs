{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from collections import defaultdict, Counter\n",
    "from datasets import Dataset, DatasetDict, load_from_disk\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.lang.en import English\n",
    "from spacy.tokens import Span\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../TEST_dictio.json') as file:\n",
    "    dictio = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lister = list(dictio.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lister"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk(\"technology_mate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4268"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>rownum</th>\n",
       "      <th>text</th>\n",
       "      <th>vector</th>\n",
       "      <th>characteristics</th>\n",
       "      <th>skills</th>\n",
       "      <th>knowledge</th>\n",
       "      <th>education</th>\n",
       "      <th>experience</th>\n",
       "      <th>licensing</th>\n",
       "      <th>tasks</th>\n",
       "      <th>technology</th>\n",
       "      <th>__index_level_0__</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21120000</td>\n",
       "      <td>32</td>\n",
       "      <td>-Fluent in Python</td>\n",
       "      <td>[1.7284571, 5.4065976, 2.7643697, 0.0, 3.60923...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21120000</td>\n",
       "      <td>34</td>\n",
       "      <td>-Numpy, Pandas, SciKit Learn</td>\n",
       "      <td>[0.9630493, 4.5101986, 4.3217683, 1.5772657, 4...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21120000</td>\n",
       "      <td>35</td>\n",
       "      <td>-Pytorch/ Tensorflow</td>\n",
       "      <td>[0.77844596, 4.1698484, 3.685791, 1.3213146, 4...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21120001</td>\n",
       "      <td>11</td>\n",
       "      <td>Develop modeling tools, training recipes, and ...</td>\n",
       "      <td>[1.8754358, 1.6910514, 4.4068537, 3.811725, 3....</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21120001</td>\n",
       "      <td>15</td>\n",
       "      <td>In connection with the above duties, apply kno...</td>\n",
       "      <td>[1.0316418, 1.5662135, 3.4645085, 1.9919258, 3...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4263</th>\n",
       "      <td>21010691</td>\n",
       "      <td>23</td>\n",
       "      <td>You are expert in data mining, machine learnin...</td>\n",
       "      <td>[1.849313, 3.841259, 1.1690421, 0.18912286, 3....</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>65467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4264</th>\n",
       "      <td>21010691</td>\n",
       "      <td>24</td>\n",
       "      <td>You have over ten years of experience or demon...</td>\n",
       "      <td>[0.34398478, 2.2746296, 0.2923308, 2.319241, 3...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>65468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4265</th>\n",
       "      <td>21010691</td>\n",
       "      <td>25</td>\n",
       "      <td>You have over ten years of experience working ...</td>\n",
       "      <td>[0.0, 1.715601, 1.5144132, 3.019465, 4.664411,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>65469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4266</th>\n",
       "      <td>21010691</td>\n",
       "      <td>26</td>\n",
       "      <td>You have experience setting up and using large...</td>\n",
       "      <td>[2.0424194, 4.269342, 0.67640674, 0.0, 2.47688...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>65470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4267</th>\n",
       "      <td>21010691</td>\n",
       "      <td>27</td>\n",
       "      <td>You have experience working with enterprise-gr...</td>\n",
       "      <td>[1.8935864, 3.9178731, 0.661463, 0.0, 3.054381...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>65471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4268 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  rownum                                               text  \\\n",
       "0     21120000      32                                  -Fluent in Python   \n",
       "1     21120000      34                       -Numpy, Pandas, SciKit Learn   \n",
       "2     21120000      35                               -Pytorch/ Tensorflow   \n",
       "3     21120001      11  Develop modeling tools, training recipes, and ...   \n",
       "4     21120001      15  In connection with the above duties, apply kno...   \n",
       "...        ...     ...                                                ...   \n",
       "4263  21010691      23  You are expert in data mining, machine learnin...   \n",
       "4264  21010691      24  You have over ten years of experience or demon...   \n",
       "4265  21010691      25  You have over ten years of experience working ...   \n",
       "4266  21010691      26  You have experience setting up and using large...   \n",
       "4267  21010691      27  You have experience working with enterprise-gr...   \n",
       "\n",
       "                                                 vector  characteristics  \\\n",
       "0     [1.7284571, 5.4065976, 2.7643697, 0.0, 3.60923...                0   \n",
       "1     [0.9630493, 4.5101986, 4.3217683, 1.5772657, 4...                0   \n",
       "2     [0.77844596, 4.1698484, 3.685791, 1.3213146, 4...                0   \n",
       "3     [1.8754358, 1.6910514, 4.4068537, 3.811725, 3....                0   \n",
       "4     [1.0316418, 1.5662135, 3.4645085, 1.9919258, 3...                0   \n",
       "...                                                 ...              ...   \n",
       "4263  [1.849313, 3.841259, 1.1690421, 0.18912286, 3....                0   \n",
       "4264  [0.34398478, 2.2746296, 0.2923308, 2.319241, 3...                0   \n",
       "4265  [0.0, 1.715601, 1.5144132, 3.019465, 4.664411,...                0   \n",
       "4266  [2.0424194, 4.269342, 0.67640674, 0.0, 2.47688...                0   \n",
       "4267  [1.8935864, 3.9178731, 0.661463, 0.0, 3.054381...                0   \n",
       "\n",
       "      skills  knowledge  education  experience  licensing  tasks  technology  \\\n",
       "0          0          0          0           0          0      0           1   \n",
       "1          0          0          0           0          0      0           1   \n",
       "2          0          0          0           0          0      0           1   \n",
       "3          0          0          0           0          0      1           1   \n",
       "4          0          0          0           0          0      1           1   \n",
       "...      ...        ...        ...         ...        ...    ...         ...   \n",
       "4263       1          0          0           0          0      0           1   \n",
       "4264       0          0          0           1          0      0           1   \n",
       "4265       0          0          0           1          0      0           1   \n",
       "4266       1          0          0           0          0      0           1   \n",
       "4267       1          0          0           0          0      0           1   \n",
       "\n",
       "      __index_level_0__  \n",
       "0                    32  \n",
       "1                    34  \n",
       "2                    35  \n",
       "3                    62  \n",
       "4                    66  \n",
       "...                 ...  \n",
       "4263              65467  \n",
       "4264              65468  \n",
       "4265              65469  \n",
       "4266              65470  \n",
       "4267              65471  \n",
       "\n",
       "[4268 rows x 13 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = English()\n",
    "matcher = Matcher(nlp.vocab)\n",
    "ruler = nlp.add_pipe(\"entity_ruler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = defaultdict(dict)\n",
    "temp = []\n",
    "cnt = Counter()\n",
    "colours = defaultdict(dict)\n",
    "key_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test': ['ABBYY', 'ABBY', 'Adobe Analytics', 'Adobe Audience Manager', 'Adobe CC', 'Adobe Launch', 'Adobe Target', 'Adobe XD', 'AdobeXD', 'ADONIS', 'AFT Fathom', 'Airflow', 'AKS', 'Alation', 'Altium Designer', 'Amadeus', 'Amazon Connect', 'Anaplan', 'Android', 'Android Studio', 'Angular', 'AngularJS', 'Ansible', 'Ansys', 'Ant', 'API Gateway', 'APL', 'App Engine', 'AppEngine', 'Apple Health', 'ArcGIS', 'ARCore', 'Argo', 'Argo CD', 'ArgoCD', 'ARKit', 'Asana', 'ASP.NET', 'Assembly', 'Atom', 'AutoCAD', 'Autodesk', 'Automation Anywhere', 'Avaya', 'AWS', 'Amazon Web Services', 'Axure', 'Azure', 'Microsoft Cloud', 'Azure Data Lake', 'Azure DevOps', 'Microsoft TFS', 'Azure Machine Learning', 'Azure SQL', 'Babylon.js', 'Bash', 'Bazel', 'Beam', 'BigQuery', 'Bitbucket', 'BlazeMeter', 'Blue Prism', 'BluePrism', 'Botmock', 'Botsociety', 'BSD', 'Buck', 'C#', 'C#/', 'C++', 'C', 'Caffe', 'Calico', 'Camtasia', 'Cassandra', 'CentOS', 'Ceph', 'Chef', 'ClearSCADA', 'ClickHouse', 'Clojure', 'CloudFormation', 'CMake', 'COBOL', 'Cognitive Search', 'Collibra', 'Confluence', 'Cordova', 'Core ML', 'CoreML', 'Cosmos DB', 'Couchbase', 'Craft', 'CSS', 'CSS3', 'Cucumber', 'CUDA', 'Cykit', 'Cypher', 'Cypress', 'Cython', 'Dart', 'Dash', 'Dask', 'Databrick(s)', 'Data bricks', 'Datadog', 'DataFlow', 'DataRobot', 'DataStage', 'Data Studio', 'DB2', 'DBT', 'Debian', 'Debussy', 'Delphi', 'Delta lake', 'Delta', 'Deno', 'Dialogflow', 'DigitalOcean', 'DirectX', 'Discord', 'Dispatcher', 'Django', 'DNS', 'Doc(s)', 'Docker(s)', 'DPDK', 'Druid', 'Drupal', 'DVC', 'DynamoDB', 'Dynamo DB', 'Dynatrace', 'EC2', 'Eclipse', 'ECMAScript', 'ES2016', 'ECS', 'EKS', 'Elastic Beanstalk', 'ElasticSearch', 'Elastic Search', 'Electron', 'Elixir', 'ELK', 'Eloquent', 'Emacs', 'EMR', 'Envoy Proxy', 'EPICS', 'Erlang', 'Erwin', 'Excel', 'Express', 'F#', 'F#/', 'Falcon', 'Fast.io', 'FastAPI', 'Felix', 'Figma', 'FileNet', 'Firebase', 'Flake8', 'Flake', 'Flask', 'Flink', 'Flood.io', 'Flow', 'Flutter', 'FME Desktop', 'FME Server', 'FOG', 'Fortran', 'Gatsby', 'GCP', 'Google Cloud', 'GDB', 'Gimp', 'Git', 'GitHub', 'Gitlab', 'GKE', 'Glow', 'Gmail', 'Go', 'Golang', 'Google Ads', 'Google Analytics', 'GA360', 'Google Calendar', 'Google Fit', 'Google Marketing Platform', 'Google Suite', 'Google Tag Manager', 'Gradle', 'Grafana', 'GraphQL', 'Groovy', 'GRPC', 'GStreamer', 'H2O', 'Hack', 'Hacklang', 'Hadoop', 'Handlebars', 'Happo', 'Haskell', 'HBase', 'Heroku', 'HDInsight(s)', 'HHVM', 'Hibernate', 'HIP', 'Hive', 'HLSL', 'Hootsuite', 'Horovod', 'HTML', 'HTML5', 'HubSpot', 'Hudi', 'Hyperion', 'Hyperscience', 'Hyper V', 'HyperV', 'IBM Cloud', 'IBM IGC', 'IBM Watson', 'Iceberg', 'Illustrator', 'InfluxDB', 'Informatica', 'InsightVM', 'InSpec', 'IntelliJ', 'Invision', 'iOS', 'Istio', 'Ixia', 'Jackrabbit', 'Oak', 'JADE', 'Jaeger', 'Java', 'JavaOS', 'JavaScript', 'JS', 'Java Script', 'JCR', 'Jenkins', 'Jetson', 'Jira', 'JMeter', 'JMP', 'jQuery', 'Juju', 'Julia', 'Jupyter', 'JupyterLab', 'Jupyter Notebook', 'JupyterNotebook', 'Kafka', 'Karate', 'Kegg', 'Keras', 'Kibana', 'Kinesis', 'Kotlin', 'Ksh', 'Kubeflow', 'Kubernetes', 'K8(s)', 'Lambda(s)', 'Laravel', 'LDQ', 'Leaflet', 'LeafletJS', 'Lex', 'Linode', 'Linux', 'LISP', 'LLDB', 'LLVM', 'Locust', 'Logstash', 'Looker', 'Lua', 'Lucene', 'Lucidchart', 'Lucid Chart', 'LUIS', 'MacOS', 'Mac', 'OS X', 'Mari', 'MariaDB', 'MasterCAM', 'Mathcad', 'Matlab', 'Matplotlib', 'Maven', 'Max', 'Maya', 'Mercurial', 'Metasploit', 'Microsoft 365', 'Office 365', 'O365', 'MS 365', 'Microsoft Deployment Toolkit', 'Microsoft Office', 'MS Office', 'Microsoft Project', 'MS Project', 'Microsoft SQL Server', 'SQLServer', 'Microsoft Teams', 'MSTeams', 'MicroStation', 'Microstrategy', 'MLFlow', 'MLlib', 'SparkML', 'Mocha', 'Mockito', 'MongoDB', 'Mustache', 'MXNet', 'Mypy', 'MySQL', 'Neo4j', 'Neovim', 'Nessus', 'NestJS', '.NET', 'NET', '.NET Core', '.NET Framework', 'NetBeans', 'New Relic', 'Nexus', 'Nginx', 'NLTK', 'Node', 'Node.js', 'NodeJS', 'Notepad++', 'Nuance', 'Nuke', 'NumPy', 'OAuth', 'Objective C', 'Obj C', 'Omnify', 'Onshape', 'ONNX', 'OpenCl', 'OpenCV', 'OpenGL', 'OpenLDAP', 'OpenMP', 'OpenShift', 'Openstack', 'OpenTracing', 'OpenVINO', 'Oracle', 'Oracle Cloud', 'OrCAD', 'OSGI', 'OWASP', 'PagerDuty', 'Pandas', 'Pega', 'Perforce', 'Perl', 'Photoshop', 'PHP', 'PHPStorm', 'PlayFab', 'PostGIS', 'PostgreSQL', 'Postgres', 'Power BI', 'PowerBI', 'Powerpoint', 'PowerShell', 'Pre Commit', 'Presto', 'Prometheus', 'ProtoBuf', 'Protractor', 'Pulumi', 'Puppet', 'PureCloud', 'PureConnect', 'Pure Data', 'PyCharm', 'PyQt', 'PySpark', 'Pytest', 'Python', 'PyTorch', 'QGIS', 'Qlik', 'QML', 'Qt', 'Quarkus', 'R', 'RabbitMQ', 'Radium', 'RAML', 'Rasa', 'React', 'React.js', 'ReactJS', 'React Native', 'Reaktor', 'Redis', 'Redshift', 'Redux', 'RESTful', 'Restlet', 'Rider', 'Rook', 'ROS', 'R Shiny', 'RSpec', 'RStudio', 'Ruby', 'RubyMine', 'Ruby on Rails', 'Rust', 'RxSwift', 'S3', 'SABA cloud', 'Sabre', 'SageMaker', 'Salesforce', 'Salesforce.com', 'Saleforce', 'SaltStack', 'SAP', 'SAS', 'Scala', 'Scala.js', 'ScalaJS', 'SciKit Learn', 'SKlearn', 'Scipy', 'Seaborn', 'Selenium', 'Sentry', 'ServiceNow', 'SharePoint', 'Sheet(s)', 'Shell', 'SignalFx', 'Singularity', 'Sisense', 'Sketch', 'Slack', 'Slide(s)', 'Slim', 'Sling', 'Slurm', 'Snowflake', 'Solaris', 'SolidWorks', 'Solr', 'Spark', 'Spinnaker', 'Splunk', 'Spring', 'Spring Boot', 'SQL', 'SQLite', 'Statsmodel(s)', 'Streamlit', 'STRING', 'Sublime Text', 'Subversion', 'SVN', 'SumoLogic', 'Sumo Logic', 'Svelte', 'Swagger', 'Swarm', 'Swift', 'Symfony', 'SysDig', 'Tableau', 'Talend', 'TBB', 'Tealium', 'TensorFlow', 'Tensor Flow', 'Teradata', 'Terraform', 'TestRail', 'Test Rail', 'TextMate', 'Theano', 'Three.js', 'TM1Py', 'Tomcat', 'Torch', 'Travelport', 'TVM', 'TypeScript', 'Ubuntu', 'UiPath', 'UML', 'Uniprot', 'Unity', 'Unix', 'Unreal', 'UrbanCode', 'Vagrant', 'Valgrind', 'VBA', 'VCS', 'Verilog', 'VHDL', 'Vim', 'Virtual Agent Designer', 'Visio', 'Visual Studio', 'Visual Studio Code', 'VSCode', 'VMWare', 'VoiceXML', 'VPC(s)', 'vSphere', 'Vue', 'Vue.js', 'Vuforia', 'Vulkan', 'Vyond', 'WebdriverIO', 'WebGL', 'WebRTC', 'Webstorm', 'Whois', 'WinDbg', 'Windows', 'Word', 'Wordpress', 'Workfusion', 'WSL', 'Xamarin', 'Xcode', 'XLA', 'XML', 'xSQL', 'YAML', 'Yarn', 'Yocto', 'Zendesk', 'Ziva', 'ZMQ', 'Zoho', 'Zookeeper', 'Zoom', 'Zsh']}\n"
     ]
    }
   ],
   "source": [
    "print(dictio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -Fluent in Python\n",
      "1 -Numpy, Pandas, SciKit Learn\n",
      "2 -Pytorch/ Tensorflow\n",
      "3 Develop modeling tools, training recipes, and prototypes utilizing programming skills in Python\n",
      "4 In connection with the above duties, apply knowledge and/or skills of Python, Linux/Unix; NoSQL; Data Visualization Tools; Software Architecture; and Software Development Methodology.\n",
      "5 Familiarity with common ML libraries such as TensorFlow, scikit-learn, Pandas, Numpy, NLTK, PyTorch, and Keras\n",
      "6 Experience with Git and the Atlassian tools (Jira, Confluence, etc.)\n",
      "7 2+ years' experience with Python and specifically with scikit-learn and TensorFlow Python libraries\n",
      "8 Experience with code versioning systems (GitHub)\n",
      "9 3 to 5 years of experience as a DevOps Engineer, software developer or system administrator supporting multi-tiered application/solutions in a cloud environment, specifically AWS\n",
      "10 Proficiency in scripting (Python, bash, zsh, ksh, ruby etc.)\n",
      "11 Proficiency with monitoring, alerting and reporting tools such as Splunk, New Relic, etc.\n",
      "12 Experience with cloud infrastructures, preferably AWS.\n",
      "13 Experience with data analysis tool sets in AWS (SageMaker, Data Lakes)\n",
      "14 Experience leveraging TensorFlow and/or time series forecasting\n",
      "15 Python knowledge including the use libraries such as Cykit, Pytorch or equivalents.\n",
      "16 Work with cutting edge Google Cloud tools like AppEngine and Cloud Storage.\n",
      "17 Use Git and learn our workflow as you go.\n",
      "18 NestJS: 2 ans (Obligatoire)\n",
      "19 Integration onto mobile and onboard devices via iOS, Android, Windows & Linux APIs and other SDKs.\n",
      "20 Familiarity with current deep learning literature: Computer Vision (CNN, image classification, scene recognition, object detection techniques such as YOLO, SSD, or Mask R-CNN), Generative Models (GAN, VAE)\n",
      "21 Experience in iOS / Android App development\n",
      "22 Extensive programming experience in Python and related libraries (Numpy, Scipy, Pandas) with some knowledge of Object-Oriented Programming in C#, Java or C++\n",
      "23 Expertise in at least one of the following Deep Learning libraries: Tensorflow, PyTorch\n",
      "24 Proficient with Python, SQL and general database concepts.\n",
      "25 Proficient in at least one programming language eg: Python, Java, C++ or R\n",
      "26 Familiarity with at least two of: Tensorflow, Keras, PyTorch and Sklearn\n",
      "27 Ability to write robust code for deployable services in Python; working knowledge of SQL (familiarity with multiple languages considered an asset).\n",
      "28 Experience with cloud computing platforms (e.g., Microsoft Azure, AWS, GCP).\n",
      "29 Experience with software engineering best practices including Git, Docker, CI/CD, test driven development, and code review.\n",
      "30 Familiarity with big data technologies (e.g., Apache Spark, Airflow, etc.), natural language processing and deep learning frameworks (e.g., TensorFlow, PyTorch) is an asset but not required.\n",
      "31 PyTorch, TensorFlow/Keras, Horovod, etc)\n",
      "32 - Highly skilled in SQL, Python & AWS (Data stack: AWS, Snowflake, dbt, Sisense).\n",
      "33 - Experience working with common ML and statistical libraries and packages (Pytorch, Tensorflow, numpy, pandas, scikit-learn, etc...).\n",
      "34 You write production-level code using Java, Python, or Scala\n",
      "35 You’ll be using a very large database (petabytes of event data in Snowflake) that is clean, flexible, and fast\n",
      "36 Build and maintain our ML development stack hosted on AWS and running with Sagemaker\n",
      "37 Write Airflow ETLs to prepare data for consumption by ML models\n",
      "38 You are familiar with Snowflake and how to efficiently query data from it\n",
      "39 You are familiar with the AWS cloud environment and how to deploy components\n",
      "40 Maintaining and improving our existing ML cloud applications hosted on Azure and GCP;\n",
      "41 Solid programming skills in Python, specifically, experience in distributed and parallel computations, optimization strategies (optimization in terms of memory and computation);\n",
      "42 Proven ability to automate and productionize machine learning applications and workflows, build AI-driven products on major cloud platforms (in-depth knowledge of Azure or GCP services is a plus);\n",
      "43 Strong familiarity of data engineering pipelines, understanding how different types of data (structured and unstructured data) are stored, retrieved and processed in automated pipelines (in-depth knowledge of AirFlow is a plus);\n",
      "44 Excellent knowledge of Python\n",
      "45 TensorFlow, PyTorch, CUDA)\n",
      "46 Knowledge of computer vision neural networks such as Fast-RCNN, ResNet, Mask-RCNN\n",
      "47 Bonus: Experience with Docker, video analytics, and/or GUI development a plus\n",
      "48 Object oriented programming with Python\n",
      "49 Proficiency with a deep learning framework such as TensorFlow or Keras\n",
      "50 Proficiency with Python and basic libraries for machine learning such as scikit-learn and pandas\n",
      "51 Knowledge of Kubernetes and containerization\n",
      "52 Work with modern big data tools like BigQuery, Kafka, Airflow, Python etc\n",
      "53 Experience working in modern, cloud-first environments (AWS, GCP or Azure).\n",
      "54 Very strong SQL proficiency\n",
      "55 Experience with software development languages such as Python or R for data transformation\n",
      "56 Git, Docker, Airflow, Jenkins etc\n",
      "57 Extensive BigQuery, Python, Kafka, Airflow, ElasticSearch experience\n",
      "58 In depth knowledge of Google Analytics\n",
      "59 SQL proficiency: 4 years (required)\n",
      "60 Continuously improve our machine learning workflow by keeping up to date with the latest optimizations in libraries such as PyTorch, and expand our usage of modern tools such as DVC\n",
      "61 Strong experience with Python and programming fundamentals\n",
      "62 Extensive experience with NLP and PyTorch\n",
      "63 Experience with data manipulation and processing, such as SQL or pandas\n",
      "64 Work within and coordinate with a small team to analyze, implement, and optimize DirectML-TensorFlow and PyTorch for machine learning models.\n",
      "65 TensorFlow, Keras, PyTorch, Caffe, ONNX, etc) and familiarity with CNN/LSTM model architectures\n",
      "66 Experience with writing GPU shaders (CUDA, OpenCL, HLSL) is a plus\n",
      "67 Several years of experience of installation, configuration, administration, networking and troubleshooting of Linux Servers.\n",
      "68 Several years of experience in Cloud (AWS, Azure, Google Cloud).\n",
      "69 YAML.\n",
      "70 Experience in orchestration tools like Kubernetes (kubectl).\n",
      "71 Experience in containerization tools, primarily Docker.\n",
      "72 Experience in SIEM tools (ELK, Splunk, PagerDuty, Kafka, Sumologic, etc).\n",
      "73 Experience in scripting (GO, Python).\n",
      "74 ITSM tools (JIRA, ServiceNow, Confluence, etc).\n",
      "75 Git, Github\n",
      "76 Network Protocols (TCP/IP, HTTP, ISO/OSI,etc).\n",
      "77 Solid years experience with software engineering and C, C++ programming\n",
      "78 Experience with Machine Learning/Deep Learning frameworks like Tensorflow, Pytorch\n",
      "79 Experience in developing computer vision algorithms using OpenCV and/or Deep Learning approaches\n",
      "80 Experience with system software (driver/OS level) on Android/Linux/Windows environment\n",
      "81 Experience with GPGPU compute like OpenCL, DirectX Compute\n",
      "82 Experience in development of any of the deep learning compiler frameworks like TVM, Glow or XLA; or other LLVM-based compilers\n",
      "83 Experience with Kubernetes, CI/CD automation, Docker, and microservice architecture.\n",
      "84 Cloud experience - AWS, Azure, or GCP.\n",
      "85 Expert with deep learning frameworks - Tensorflow, Pytorch, Keras\n",
      "86 Expert with Python\n",
      "87 Spark, Flink, Apache Beam)\n",
      "88 3 years of experience developing advanced Python using Object Oriented techniques, Modules (i.e\n",
      "89 Experience with Tensorflow, or equivalents\n",
      "90 Advanced experience with the whole life-cycle of Python dependency management strategy across multiple repositories\n",
      "91 AWS\n",
      "92 You have extensive experience with deploying and managing core infrastructure on the AWS cloud\n",
      "93 Linux\n",
      "94 Our production systems run on Linux\n",
      "95 Python\n",
      "96 You must know Python, and not as a simple recreational tool that you have experimented with\n",
      "97 Experience with ZMQ is a major asset.\n",
      "98 MongoDB\n",
      "99 APIs\n",
      "100 Build and maintain quality assurance test suites using Cypress, Mocha, an dother automated testing tools\n",
      "101 Expertise in working with at least one deep learning framework, such as PyTorch, TensorFlow, Caffe.\n",
      "102 Experienced in cloud providers such as GCP or AWS\n",
      "103 Proficient in Python\n",
      "104 2+ years of proven experience working in public cloud platforms such as Microsoft Azure or Amazon Web Services\n",
      "105 Experience developing in Powershell, Python or other programming languages\n",
      "106 Experience working with both structured and distributed data technologies ranging from SQL to Hadoop, Hive and Spark.\n",
      "107 Our sensor development team is responsible for building the endpoint sensor which deploys on multiple platforms including Windows, Mac, and Linux\n",
      "108 Support development teams in designing and building software with cross-platform deliverables (Windows, Mac, Linux)\n",
      "109 In depth knowledge with C++ and Windows OS Kernel Development\n",
      "110 Strong low-level OS internals in either Windows, Mac OS, or Linux\n",
      "111 Hands on experience with big data systems like Hadoop, Spark, AWS EMR, Azure HDInsights, etc.\n",
      "112 Relational and NoSql database systems experience\n",
      "113 Experience with AWS environments.\n",
      "114 ML frameworks: TensorFlow, Torch, Caffe, or Theano.\n",
      "115 Python, Scala, Java or .NET.\n",
      "116 Oracle, MySQL, PostgreSQL or MongoDB\n",
      "117 Hadoop/AWS EMR, Apache Spark\n",
      "118 AWS product knowledge (e.g\n",
      "119 EC2, VPCs, Lambda, API Gateway, etc.)\n",
      "120 AWS Console, CLI and SDK experience\n",
      "121 Infrastructure as code: Terraform, CDK, or CloudFormation\n",
      "122 Git version control\n",
      "123 Strong programming skills in Python and Scala required\n",
      "124 Java, R, Haskell) a plus.\n",
      "125 scikit-learn, tensorflow, keras, pytorch, Spark MLlib) required.\n",
      "126 Hadoop, Spark, Kafka) required.\n",
      "127 Experience with building and deploying API's with Docker and Kubernetes required.\n",
      "128 Experience with Elastic Search, Lucene a plus but not required.\n",
      "129 Academic or work experience with Mechanical software AFT Fathom, Ansys, Sidewinder, MathCAD, and Bentley MicroStation CAD software is an asset.\n",
      "130 These sensor features will need to work seamlessly in container orchestration platforms such as Kubernetes in a diverse range of deployment configurations.\n",
      "131 Lead the definition, design, and implementation of container-specific features in the Linux sensor\n",
      "132 Experience in leading the definition, design and implementation of product features in C/C++ on Linux / Unix with the following characteristics:\n",
      "133 Familiarity with golang programming language is preferred but not required\n",
      "134 Experience with Kubernetes is preferred but not required\n",
      "135 AWS, Azure), on-premise cloud (e.g\n",
      "136 VMWare vSphere, Openstack) and cloud native (e.g\n",
      "137 Docker Swarm, Kubernetes).\n",
      "138 3+ years of experience in C/C++ programming.\n",
      "139 Strong understanding of a variety of operating systems such as Windows, Linux, or Android.\n",
      "140 Familiarity with the basics of SQL or other databases.\n",
      "141 Familiarity with a version control system, preferably Git.\n",
      "142 -Fluent in Python\n",
      "143 -Numpy, Pandas, SciKit Learn\n",
      "144 -Pytorch/ Tensorflow\n",
      "145 Hands-on experience with big data technologies (e.g., Hadoop/Spark) and scalable realtime systems that process stream data\n",
      "146 Strong analytical skills demonstrated through advanced Microsoft Excel and Microsoft Powerpoint\n",
      "147 Experience working with testing automation software such as Selenium or Cypress.\n",
      "148 A strong track record of performing machine learning model development using Python (numpy, pandas, tensorflow, pytorch, scikit-learn, etc.) and SQL/NoSQL interaction patterns.\n",
      "149 Familiarity with Linux/OS X command line, version control software (git), and general software development principles with a machine learning software development life-cycle orientation.\n",
      "150 At least three years of experience working with Microsoft Azure Cloud technologies will be desirable.\n",
      "151 Experience building data pipelines with SAP or Salesforce as a source and ADLS or Synapse (Azure Data Warehouse) will be beneficial.\n",
      "152 Strong knowledge of database programming languages including Azure SQL, DB2, and TERADATA.\n",
      "153 Good knowledge of advanced analytics languages like R, Python, and others is desirable.\n",
      "154 Basic knowledge of popular data discovery, analytics and BI tools like Power BI, Microstrategy, Tableau, Qlik, and alike.\n",
      "155 Write production-ready Python/c code\n",
      "156 Familiar with PyTorch and TensorFlow\n",
      "157 Familiar with well known deep learning models such as Yolo, SSD, faster RCNN and able to adapt it to new applications\n",
      "158 Experience with PyTorch, Tensorflow and OpenCV\n",
      "159 Experience in optimization on GPU / CPU / other architectures (CUDA, SSE, NEON, OpenMP or other SIMD)\n",
      "160 Code integration and unit tests in python and C#\n",
      "161 Understanding of SQL and NoSQL databases\n",
      "162 Understanding of Azure Cloud and Azure DevOps Pipelines\n",
      "163 Several years of industrial experience and strong C++ development skills.\n",
      "164 Used to working in Linux.\n",
      "165 Interfaces such as GMSL2, FPDLINK III\n",
      "166 Experience with Python\n",
      "167 De solides compétences en programmation dans divers langages (C++, Scala, Java, R) et une maîtrise de Python ou C++\n",
      "168 De solides compétences dans l'utilisation des cadres d'apprentissage automatique de pointe actuels tels que Scikit-Learn, H2O, Keras, TensorFlow and Spark, etc.\n",
      "169 Strong Programming skills in various languages (C++, Scala, Java, R) with proficiency in Python and/or C++\n",
      "170 Strong skills in the use of current state of the art machine learning frameworks such as Scikit-Learn, H2O, Keras, TensorFlow and Spark, etc.\n",
      "171 Must have at least 1 year of experience with Deep Learning frameworks like PyTorch or TensorFlow.\n",
      "172 Must have at least 3 years of industry experience with C/C++, Python coding or other high-level languages.\n",
      "173 Extensive and up-to-date knowledge and hands-on experience of machine learning and data engineering technologies (Kubernetes, spark, Databrick, GPU, etc.)\n",
      "174 Python, Java and Kotlin\n",
      "175 Tensorflow and PyTorch\n",
      "176 AWS, GCP, and Kubernetes\n",
      "177 MySQL, DynamoDB, Kafka, Apache Beam and Google DataFlow\n",
      "178 Strong programming skills in Python.\n",
      "179 Experience with deep learning frameworks like Tensorflow or PyTorch.\n",
      "180 Experience with docker or other container technologies.\n",
      "181 Experience with programming languages commonly used in data science applications (Python, R and SQL preferred)\n",
      "182 Provide advanced troubleshooting via remote sessions to modify customer’s environment towards a resolution that include, but are not limited to: Installation issues, best practice configuration, network troubleshooting, Windows, Linux, Mac and Unix OS configuration.\n",
      "183 Experience with security products, such as Firewalls, IPSec, IDS/IPS, Anti -Spam, Anti-Virus, Web Security proxies, Email Security filters, VPNs\n",
      "184 Experience with Linux operating systems through the command line level\n",
      "185 Experience with cloud virtualization such as Amazon AWS or Microsoft Azure\n",
      "186 Proficient in MS Office Suite - Word, Excel, and PowerPoint\n",
      "187 This role will be responsible for developing embedded linux software and microcontroller-based firmware for our state of the art ultrasonic imaging platforms.\n",
      "188 You should love writing modern C++ and have experience with code and algorithm optimizations for power-sensitive applications\n",
      "189 Build Ultrasonic image capture software on an Arm64 embedded Linux platform.\n",
      "190 C++ 11/14 Programming experience.\n",
      "191 Embedded Linux development (bootloader, device tree, kernel drivers, Yocto etc.)\n",
      "192 1 years of Machine learning experience, mathematical and statistical knowledge, Python, R, Spark\n",
      "193 1 or more years of experience with Azure or any other cloud ML build and implementation\n",
      "194 Proficiency in R, Python, Spark\n",
      "195 Knowledge of scalable, distributed systems using Cloud Providers such as Microsoft Azure will be preferred\n",
      "196 Experience with Data Bricks and Kubernetes will be an asset\n",
      "197 Familiarity with Tensorflow or Pytorch will be an asset\n",
      "198 Experience with python and/or other scripting languages\n",
      "199 Proven history of programming/scripting experiences (Python, C/C++/C#, Java)\n",
      "200 Deliver innovations into production quality C++ code that can be deployed to hundreds\n",
      "201 o Software development experience in a Linux environment working in collaboration with\n",
      "202 o Proficiency in both C++ and python\n",
      "203 o Proficient developing and debugging software in a Linux environment\n",
      "204 o Modern C++ (C++11 or newer ; experience with the boost library\n",
      "205 o Linux experience - Configuring an embedded Linux build (e.g\n",
      "206 Yocto)\n",
      "207 o writing server code, drivers, and configuring devices on a full Linux distribution (e.g.\n",
      "208 Ubuntu Server)\n",
      "209 o Hands on experience in Linux or/and Android security (for example, Kernel hardening,\n",
      "210 features (for example, secure boot, disk encryption, integrity protection, Linux kernel\n",
      "211 o Multiple programming languages including C++, Python and Rust\n",
      "212 o Strong proficiency in C++ 14 and above with use of templates, lambdas and exception\n",
      "213 Experience with SolidWorks™ in a machine design capacity.\n",
      "214 Experience writing infrastructure code for cloud environments in Google Cloud Platform, AWS and / or Azure.\n",
      "215 Experience with writing infrastructure as code with HashiCorp Terraform.\n",
      "216 Experience with container orchestration technologies, specifically Kubernetes and ECS, OpenShift\n",
      "217 Bash/Python/Ruby/Perl)\n",
      "218 simulations and data visualization (C, C++, TypeScript);\n",
      "219 stereo cameras, IMU, LiDAR);\n",
      "220 Proficiency in one major programming language (preferably Python) and SQL\n",
      "221 Experience with data modeling, ETL design and tooling (especially Airflow), and transforming data to meet business goals\n",
      "222 Experience designing (or architecting) and deploying production solutions to the cloud with AWS, Azure or GCP\n",
      "223 SciKit Learn, TensorFlow, etc.)\n",
      "224 Terraform) and Kubernetes (EKS)\n",
      "225 Experience creating integrations, managing user permissions and optimizing queries in Snowflake\n",
      "226 Bigdata Technologies (Hive/Spark)\n",
      "227 Spark ML\n",
      "228 Leverage open source technologies like Kubeflow, Kubernetes, Spark, Docker, Airflow, Tensorflow and PyTorch\n",
      "229 Strong coding skills in Python/Java/Scala or equivalent\n",
      "230 Experience with distributed data processing tools like Hive, Spark, Airflow and popular ML frameworks like Tensor flow or Pytorch is preferred\n",
      "231 Experience with Docker, Kubernetes, Spark is a plus\n",
      "232 Experience with distributed data processing tools like Hive, Spark, Airflow is a plus\n",
      "233 You'll work within an agile team using Protractor/Selenium/Javascript/Cucumber test automation framework to create complex test scenarios before integrating different systems\n",
      "234 Develop and execute Automated tests in Java\n",
      "235 Besides the proven experience and technical products mentioned above and working in an Agile environment testing iOS and Android native apps, experience with some of these products may give you extra comfort in the role: Experience with Protractor or Angular Development experience with Javascript, Typescript, Java, Python, Ruby, C++\n",
      "236 Strong QA development using Selenium and Java Working knowledge of Oracle DB and ability to author scripts and procedures for test data management tools and processes Strong knowledge of QA and software testing methodologies in support of a variety of software development methodologies, e.g\n",
      "237 API microservice development in PHP (Laravel) and SQL.\n",
      "238 We are hiring both junior and senior positions, but we expect you to have at least 2 years experience of PHP backend API development\n",
      "239 Familiar with PHP and Laravel\n",
      "240 We use PHP 7-8, Laravel (with Eloquent).\n",
      "241 We are looking into using Go (golang) more so it’s a bonus if you have any experience of this.\n",
      "242 Comfortable and quick with Git and code reviews.\n",
      "243 Confident in writing SQL queries, in MySQL as well as using ORMs.\n",
      "244 Bonus: if you have an additional strong skill such as ops/dev ops, cloud infrastructure (we use AWS), database design, big data, machine learning.\n",
      "245 HJ Machine & Pattern(HJMP) is looking for a smart, creative, and experienced CMM Tech & quality engineering professional who has a working knowledge of GD&T and other quality tools\n",
      "246 MasterCAM, Onshape, AutoCAD etc.\n",
      "247 Proven experience with software engineering and C, C++ programming\n",
      "248 Experience with Machine Learning/Deep Learning frameworks like Tensorflow, Pytorch\n",
      "249 Experience in developing computer vision algorithms using OpenCV and/or Deep Learning approaches\n",
      "250 Experience with system software (driver/OS level) on Android/Linux/Windows environment\n",
      "251 Experience with GPGPU compute like OpenCL, DirectX Compute\n",
      "252 Experience in development of any of the deep learning compiler frameworks like TVM, Glow or XLA; or other LLVM-based compilers\n",
      "253 Experience with any/all of the following: Go, Python, Scala, Java, C++, JavaScript\n",
      "254 Web Services: JSON, REST, RPC, XML, AWS EC2 & S3.\n",
      "255 Data storage: RDMBS, NoSQL, and Caching Technologies such as PostgreSQL, MySQL, Cassandra, SQLServer, Redis, and/or MemCache.\n",
      "256 Contributions to the open source community (GitHub, Stack Overflow, blogging).\n",
      "257 Existing exposure to Go, AWS, Cassandra, Kafka, Elasticsearch, GRPC, Docker, Kubernetes, Jenkins\n",
      "258 To thrive in this development career, you'll need to be an expert in Java (Java 8 preferred) and have a firm grasp on Spring Boot, Javascript, Angular and/or React\n",
      "259 You'll need to be familiar with open source tools such as Apache KAFKA and web technologies\n",
      "260 You will: research, conceive and develop superior UI designs to make our Clients lives easier develop and build unit testing for a reusable set of UI components and design patterns develop and build unit testing for Java RESTful APIs Leverage you Database development skills to Design stable, reliable and effective databases You have 2-5 years of experience in relevant skills gained and developed in the same or similar role.\n",
      "261 Strong UI development with React, Angular or JS Framework\n",
      "262 Strong development of RESTful Java APIs for Microservices Architecture\n",
      "263 Strong SQL coding skills with Java & Spring\n",
      "264 To give just one example, starting with an empty Python script, write a code to model flooding caused by a levee failure\n",
      "265 You must know Python cold, and not as a simple recreational tool that you have experimented with\n",
      "266 You must know Pandas extraordinarily well and use on a large scale via multiprocessing is key (working with large datasets terabytes in size, developing customized functions, knowing how to speed computation).\n",
      "267 We are a NoSQL Shop: You must understand MongoDB structures/ projections/MapReduce/etc\n",
      "268 Build and maintain data pipelines using tools like Hadoop, Python, API Gateway, SageMaker, ECS/EKS, Fargate Lambda, Airflow, CloudWatch, AWS CDK\n",
      "269 Own the AWS stack which comprises all ML resources\n",
      "270 3+ years experience coding in Python (preferred)\n",
      "271 Experience with Kubernetes and ML CI/CD workflows\n",
      "272 3+ years experience with AWS or other public cloud platforms (GCP, Azure, etc.)\n",
      "273 Python: 3 years (preferred)\n",
      "274 Extracting, transforming and loading massive datasets using distributed computing framework technologies (Hadoop, Spark, etc.);\n",
      "275 Have experience with writing software in one of the major languages such as C++, C#, Java, Python;\n",
      "276 Have familiarity with the Unix command line and bash scripting;\n",
      "277 Experience with Deep Learning packages such as Tensorflow, Theano, Keras and PyTorch is an asset;\n",
      "278 Hadoop, Spark) as well as SQL, NoSQL and graph databases is an asset;\n",
      "279 Write complex SQL queries with multiple joins to automate and manipulate data extracts\n",
      "280 GCP, AWS or Azure preferred\n",
      "281 1+ years of experience building interactive dashboards using at least 1 data visualization tool such as Data Studio, Tableau, PowerBI or Looker\n",
      "282 Experience building visualisations exclusively using Python or other programmatic libraries will also be considered.\n",
      "283 2+ years of experience using Python\n",
      "284 Java or other programming language experience will also be considered\n",
      "285 2+ years of experience using SQL\n",
      "286 Experience using data science libraries such as pandas, matplotlib, scikit-learn, keras, nltk etc\n",
      "287 Experience using Tensorflow is a strong asset\n",
      "288 Experience using ETL/orchestration/workflow management frameworks like Apache Airflow preferred, but not required\n",
      "289 Strong understanding of Google Cloud BigQuery preferred\n",
      "290 Understanding of digital marketing ecosystems and tools like Google Marketing Platform, GA360, Google Ads, Adobe Suite etc\n",
      "291 Experience with big data technologies MapReduce/Hadoop/Hive/Presto/Spark\n",
      "292 Expert in Java, C++ or Python\n",
      "293 Experience with large scale Whole page Optimization, Search or Recommendation algorithms\n",
      "294 Thorough understanding of Python\n",
      "295 Thorough understanding of ML frameworks (PyTorch, TensorFlow, CUDA)\n",
      "296 Knowledge of computer vision neural networks such as Fast-RCNN, ResNet, Mask-RCNN\n",
      "297 Experience with Docker, video analytics, and/or GUI development is desirable, but not required\n",
      "298 Proficiency programming in two or more of C++, C#, Javascript or Python\n",
      "299 | Maîtrise de la programmation dans deux ou plus de deux des langages suivants : C++, C#, JavaScript ou Python.\n",
      "300 Android, iOS, React Native, Electron, Qt, React, Vue.js)\n",
      "301 | Expérience des cadres d'applications mobiles, de bureau ou web (par exemple, Android, iOS, React Native, Electron, Qt, React, Vue.js).\n",
      "302 Experience with game engines such as Unreal or Unity\n",
      "303 | Expérience des moteurs de jeu tels qu'Unreal ou Unity.\n",
      "304 Experience with WebGL/WebXR frameworks (e.g\n",
      "305 Babylon.js, Three.js)\n",
      "306 | Expérience des environnements WebGL/WebXR (par exemple, Babylon.js, Three.js).\n",
      "307 Experience leveraging computer vision libraries such as OpenCV\n",
      "308 | Expérience de l'utilisation de bibliothèques de vision par ordinateur telles que OpenCV.\n",
      "309 Deep knowledge of at least one modern programming language (Java and/or Python preferred)\n",
      "310 Deep knowledge of Javascript/HTML/CSS and at least one major web framework (React, Vue, Angular)\n",
      "311 Experience designing and deploying dynamically scalable, highly available, fault tolerant and reliable cloud applications (AWS preferred)\n",
      "312 Experience with Cordova, Android, iOS development\n",
      "313 Technologies We Use: Python, Java, Javascript, Typescript, Fast.io, Quarkus, Vue, React Native, Kotlin, Redis, Postgres, Kubernetes, Docker, Jenkins, AWS, GCP, Azure\n",
      "314 Experience with programming languages such as Python\n",
      "315 Experience with manipulating big data sets via SQL able to process, filter and present large quantities of data\n",
      "316 Familiarity with packages related to data processing, data visualization and statistic analysis such as Pandas, NumPy, SciPy, Statsmodel and Seaborn.\n",
      "317 Experience in developing machine-learning algorithms, statistical and mathematical optimization models via machine-learning frameworks, such as Scikit-Learn, MLlib, Tensorflow and Keras.\n",
      "318 Ability to deploy machine learning models to cloud platform with good familiarity with AWS, such as EC2, S3, Dynamodb and lambda\n",
      "319 Experience with PySpark and/or Databricks\n",
      "320 Comfortable using development environments such as VSCode, Pycharm, Jupyter Notebook\n",
      "321 Experience working with APIs, Docker and or Linux an asset\n",
      "322 Experience with Tableau and AutoML tools an asset\n",
      "323 5+ years experience with Linux Operating Systems (e.g., Debian, Ubuntu\n",
      "324 Good knowledge of infrastructure management and automation systems (e.g., Ansible, Chef: SaltStack is a plus)\n",
      "325 Experience with Database Administration, including but not limited to MySQL, MongoDB\n",
      "326 Scripting (e.g, Bash, Python)\n",
      "327 Experience managing infrastructure on public clouds (like AWS, GCP)\n",
      "328 Development of scripts or applications (XML, REST, JavaScript) to simulate various management activities and network scenarios on a web based (browser) platform\n",
      "329 Strong programming skills (Javascript, XML)\n",
      "330 Familiarity with automation frameworks (Mocha) as well as web automation components (Selenium, webdriverio)\n",
      "331 Linux operating environment, Windows, Virtual Machines\n",
      "332 Answer questions, troubleshoot, and resolve issues reported by partners & customers; issues can include, but are not limited to: Installation issues, best practice configuration, network troubleshooting, Windows, Linux, Mac and Unix OS configuration.\n",
      "333 Demonstrable knowledge of fundamentals of Windows OS including how Portable Executables and Services load and execute.\n",
      "334 Knowledge of how the Windows registry works.\n",
      "335 Able to read and understand Windows events in Application, Windows, and Security Event stores.\n",
      "336 Understanding of the PC boot process from UEFI bootstrap through how the Windows OS loads.\n",
      "337 Understanding of the Windows Network stack and how network protocols operate (HTTP(s), DNS, IPv4 Subnetting, how ephemeral ports are assigned, DHCP).\n",
      "338 Understanding of .Net, Java, and other execution models in Windows\n",
      "339 Design, develop, test, deploy and support workloads on AWS SageMaker models\n",
      "340 In this role you can learn AWS Sagemaker if you have experience with other comparable cloud environment tools.\n",
      "341 Develop automation code and provide fixes and improvements using Python/R\n",
      "342 Develop and support customized interactive Tableau dashboards for internal business partners\n",
      "343 In this role you can learn Tableau by leveraging your current experience with other similar tools.\n",
      "344 Must have 1+ years experience in using Python/R and SQL (Hadoop, Microsoft SQL Server, SAS, Oracle, etc) to analyze data and gather valuable insights\n",
      "345 Working knowledge of MS Office Suite of products (Word, Excel, PowerPoint)\n",
      "346 Experience and/or training in Cloud platforms like AWS, MS Azure, and Google Cloud Platform\n",
      "347 Provide advanced troubleshooting via remote sessions to modify customer’s environment towards a resolution that include, but are not limited to: Installation issues, best practice configuration, network troubleshooting, Windows, Linux, Mac and Unix OS configuration.\n",
      "348 Experience with security products, such as Firewalls, IPSec, IDS/IPS, Anti -Spam, Anti-Virus, Web Security proxies, Email Security filters, VPNs\n",
      "349 Experience with Linux operating systems through the command line level\n",
      "350 Experience with cloud virtualization such as Amazon AWS or Microsoft Azure\n",
      "351 Kubeflow, AWS Sagemaker, Google AI Platform, Azure Machine Learning, DataRobot, MLFlow).\n",
      "352 Strong experience in Python used both for ML and automation tasks.\n",
      "353 Database and programming languages experience and data manipulation and integration skills using SQL, Oracle, Hadoop, NoSQL Databases, or similar tools\n",
      "354 Experience with Kubernetes and the ecosystem of Cloud Native tools.\n",
      "355 Experience with Azure or AWS platforms is an asset\n",
      "356 OO development, multithreading, SQL & NoSQL, micro-services architecture, and TDD\n",
      "357 Solid coding skills and experience in Java or similar languages\n",
      "358 Experience with one or more dynamic languages like Python or JavaScript.\n",
      "359 Ruby, Java, Javascript, Selenium, RSpec\n",
      "360 experience with scripting (Python, Bash)\n",
      "361 Familiarity with AWS\n",
      "362 Ruby, Java, Python, and React.js\n",
      "363 Kubernetes, Docker, Kafka\n",
      "364 PostgreSQL, NoSQL\n",
      "365 AWS\n",
      "366 Computer Programming Skills: capability to develop test platforms in C#.net\n",
      "367 Experience with SQL database management, Matlab is required\n",
      "368 Knowledge of Windows, Load Balancing, Firewalls and Virtual Machines\n",
      "369 Unix OS experience (BSD/Linux/Solaris)\n",
      "370 Hands-on experience with the installation, configuration, and/or operation of network equipment such as Cisco, Juniper or other network hardware manufacturers – a valuable asset\n",
      "371 Programming and/or scripting, SQL databases, network traffic monitoring, or firewall technologies – especially in a Telecom, ISP, or Cable Internet environment – a valuable asset\n",
      "372 Good computer skills in MS Office\n",
      "373 Ideal candidate will have served as a developer in prior roles and have a deep understanding of modern, highly scalable architectures leveraging the latest technologies including NET/C#, Restful APIs, micro-services, cloud computing etc.\n",
      "374 Must have strong working knowledge of Microsoft Office\n",
      "375 Work closely with the Production Support team in maintaining and enhancing the Production Regression package on Selenium through Windows Virtual Machine.\n",
      "376 Experience developing automation in at least one OO language - Java, Python, or web-based technologies\n",
      "377 Basic knowledge of scripting in at least one – Groovy, Bash, Ruby and Perl\n",
      "378 Expertise in automation testing tools like Selenium, Robot framework, Karate and Cucumber\n",
      "379 Experience with Docker and Jenkins\n",
      "380 Good understanding on build tools like Maven, Gradle and Ant\n",
      "381 Predominantly on a Microsoft .Net and Microsoft Azure aligned stack.\n",
      "382 Hands-on experience programming with .Net C#\n",
      "383 Experience processing tabular data sources and structured data formats like XML and JSON\n",
      "384 Scalable/enterprise-scale service development and API patterns experience, ideally with Microsoft Azure services\n",
      "385 4+ years scripting in Python\n",
      "386 Kubernetes, Docker).\n",
      "387 Linux.\n",
      "388 Docker, Ansible .\n",
      "389 Python, bash, C++.\n",
      "390 Gitlab.\n",
      "391 Develop and maintain scalable and reusable data pipelines and APIs on cloud services such as AWS, to support all systems for all things ML related\n",
      "392 Experience building scalable data pipelines and databases on cloud services such as AWS\n",
      "393 Python preferred.\n",
      "394 Experience working with SQL, NoSQL databases (such as DynamoDB, MongoDB), and data warehouses (such as Snowflake, Redshift)\n",
      "395 Exposure to Docker, Kubernetes, Airflow, Spark an asset\n",
      "396 Familiarity with agile tooling to efficiently build as a team: Git, Jira, Confluence, etc.\n",
      "397 Experience in R, SAS programming, and script/macro code development\n",
      "398 Experience with products such as R-Shiny, Python, JMP, SAS/GRAPH, SAS Output Delivery System\n",
      "399 3+ years proficiency in one or more core analytical tools / suites / languages such as Python, R, Spark Scala and understanding of their limitations\n",
      "400 Advanced hands-on experience with machines learning toolkits: Tensorflow, Pytorch, Scikit-Learn\n",
      "401 Experience using SQL/noSQL and knowledge in database management.\n",
      "402 Experience working with large dataset, experience working with distributed computing tools (Map/Reduce, Hadoop, Hive, etc.) and Machine Learning pipelines (Spark, DASK, Argo, etc.)\n",
      "403 Experience using Power BI, Tableau, and/or other visualization tools\n",
      "404 Experience working with frontend ML systems such as Dash, Streamlit, etc.\n",
      "405 Experience with source code management tools such as GIT, Jira, Bitbucket, or Azure DevOps\n",
      "406 Experience in working with Cloud based Data systems (Azure Data lake, Databricks, Azure SQL and PostgreSQL Systems)\n",
      "407 Azure: 5 years (Preferred)\n",
      "408 Working knowledge with any programming languages (Python, Java Script etc.) is a big plus.\n",
      "409 Working knowledge with Data Visualization tools (Tableau, Power BI etc.) would be an added advantage.\n",
      "410 Experienced in developing frontends using web technologies such as HTML 5, JavaScript, CSS, React.js & UI frameworks\n",
      "411 Experience in programming with Node.js\n",
      "412 2+ years experience with Infrastructure as Code (IaC) tooling (eg Terraform, CloudFormation)\n",
      "413 Containerization / Cloud Native (OpenShift, Kubernetes, EKS/GKE, ECS).\n",
      "414 Strong knowledge of foundational elements of public cloud (AWS, Azure or Google Cloud).\n",
      "415 Proficiency in source code management with Git.\n",
      "416 Google Cloud: 1 year (preferred)\n",
      "417 Microsoft Azure: 1 year (preferred)\n",
      "418 Terraform: 2 years (preferred)\n",
      "419 Source Code Management with Git: 1 year (preferred)\n",
      "420 Non-Shell scripting languages: 2 years (preferred)\n",
      "421 AWS: 3 years (required)\n",
      "422 2+ years experience with Infrastructure as Code (IaC) tooling (eg Terraform, ARM)\n",
      "423 2+ years experience with Powershell or alternative Windows focussed automation tooling\n",
      "424 Advanced knowledge of Microsoft Azure\n",
      "425 Proficiency in source code management with Git.\n",
      "426 Advanced knowledge of Microsoft Azure: 3 years (preferred)\n",
      "427 At least one non-shell scripting language: 1 year (preferred)\n",
      "428 Powershell / Windows focussed automation: 2 years (preferred)\n",
      "429 Source code management in Git: 1 year (preferred)\n",
      "430 Terraform: 1 year (preferred)\n",
      "431 · Good knowledge of AutoCAD Electrical and MS Office\n",
      "432 Knowledge of Advance Process Control (Pavilion 8); simulation (Matlab, loop tuning software)\n",
      "433 3+ years of Software Development experience with modern programming languages (Python, C/C++, Julia)\n",
      "434 Experience with at least one deep learning framework (TensorFlow, PyTorch, MXNet …)\n",
      "435 Experience working in version control such as git\n",
      "436 AWS, Azure …)\n",
      "437 Expert in leveraging ReadyAPI and Selenium tools for testing\n",
      "438 JAVA microservices: 8 years (required)\n",
      "439 Design block level Python reference code and integrate in the system level Python reference code\n",
      "440 Python coding\n",
      "441 C++ coding\n",
      "442 Work within and coordinate with a small team to analyze, implement, and optimize DirectML-TensorFlow and PyTorch for machine learning models.\n",
      "443 TensorFlow, Keras, PyTorch, Caffe, ONNX, etc) and familiarity with CNN/LSTM model architectures\n",
      "444 Experience with writing GPU shaders (CUDA, OpenCL, HLSL) is a plus\n",
      "445 Familiar with DevOps Processes, Pipelines and Tooling (Github, Jenkins, UrbanCode Deploy, Jira, etc)\n",
      "446 Building required infrastructure for optimal extraction, transformation and loading of data from various data sources using Apache Airflow and ElasticSearch technologies\n",
      "447 Build applications on RedHat Openshift and Cloud Foundry cloud\n",
      "448 5+ years’ experience developing scalable, configurable applications using Python and Java\n",
      "449 3+ years' experience with ElasticSearch Stack (Logstash, ElasticSearch, Kibana)\n",
      "450 5+ years’ experience with relational/non-relational databases (Postgresql, MongoDB)\n",
      "451 Experience containerizing and deploying applications with Docker/Kubernetes and building DevOps pipelines (GitHub, Jenkins, Artifact Repository, Ansible, etc)\n",
      "452 Familiar with messaging technologies (Kafka, Spark, etc)\n",
      "453 · Hands on coding of algorithms in C++, Python.\n",
      "454 · Work with ROS Melodic, TensorFlow, OpenCV, GStreamer, Docker, RGB/IR Cameras, and Biometric solutions.\n",
      "455 · Experience with ML frameworks (like TensorFlow, MxNet or PyTorch) and libraries, deep learning algorithms and model architectures, and deep learning literature.\n",
      "456 · Familiarity with Jira, Git, SVN, Jenkins, CI/CD and deployment pipelines\n",
      "457 Experience with test automation & Python\n",
      "458 VMWare, HyperV, AWS, GCP)\n",
      "459 3+ years experiencing working with Linux-based software\n",
      "460 Experience with: Jenkins, GIT, Bash, Perl, Test Rail, Azure, AWS\n",
      "461 Strong programming skills in at least one of the following: Python, C++, Java.\n",
      "462 Experience with open source libraries like OpenCV, TensorFlow, Caffe, Yolo, etc...\n",
      "463 Familiarity with PlayFab or Firebase\n",
      "464 Experience in Continuous Integration environments, ideally using Github Actions.\n",
      "465 Working knowledge in Cypress, JavaScript and TypeScript.\n",
      "466 Experience with Python\n",
      "467 Experience working in a containerized (Docker, Kubernetes) environment.\n",
      "468 You have experience with containerizing your applications using Docker and deploying them using your CI/CD pipeline.\n",
      "469 You have experience with cloud infrastructure providers and tooling (AWS, GCP etc.).\n",
      "470 Experience with Python and agent-based modelling and simulation infrastructure is a plus.\n",
      "471 Solides compétences en programmation Python, connaissances Unix.\n",
      "472 Expérience pratique des cadres ML, des bibliothèques et des paquets ML/DL (par exemple, Tensorflow ou PyTorch).\n",
      "473 Expérience de travail dans des environnements de calcul haute performance et de Cloud/Azure.\n",
      "474 Expérience de l'optimisation des systèmes distribués, de la programmation GPU/Cuda.\n",
      "475 Expérience de travail avec un ou plusieurs des éléments suivants : onnx, Slurm, Docker, Singularity, Dask, plateformes ML de bout en bout (telles que MLflow).\n",
      "476 Solid Python programming skill, Unix knowledge\n",
      "477 Tensorflow or PyTorch)\n",
      "478 Experience working in High performance computing and Cloud/Azure environments.\n",
      "479 Experience with distributed system optimization, GPU/Cuda programming\n",
      "480 Experience working with one or more of the following: onnx, Slurm, Docker, Singularity, Dask, end-to-end ML platforms (such as MLflow)\n",
      "481 Hands on experience with Deep Learning frameworks like PyTorch, TensorFlow.\n",
      "482 Proficiency in programming languages like Python and C/C++\n",
      "483 Experience with runtime environments (OpenVINO, ONNX runtime, TVM etc.) would be a huge plus.\n",
      "484 Analyse large datasets with tools like jupyter notebooks, python and sql, and translate them into actionable insights for our client, or the larger public through white paper publications\n",
      "485 Proficient in SQL, Excel, Python\n",
      "486 GIS software (arcGIS, QGIS)\n",
      "487 You should love writing modern C++ and have experience with code and algorithm optimizations for power-sensitive applications.\n",
      "488 Build Ultrasonic image capture software in C++ on an embedded Linux platform.\n",
      "489 C++ 11/14 Programming experience.\n",
      "490 Embedded Linux development (bootloader, device tree, kernel drivers, Yocto etc.)\n",
      "491 Write complex SQL queries with multiple joins to automate and manipulate data extracts\n",
      "492 Championing deployment tooling within the StackPros team, with tools such as Docker, Kubernetes, Jenkins, etc.\n",
      "493 Championing version control technology frameworks and creating/implementing working processes within the Data Systems team, with tools such as Git or SVN\n",
      "494 GCP, AWS or Azure preferred\n",
      "495 2+ years of experience building interactive dashboards using at least 1 data visualization tool such as Data Studio, Tableau, PowerBI or Looker\n",
      "496 Experience building visualisations exclusively using Python or other programmatic libraries will also be considered.\n",
      "497 3+ years of experience using Python\n",
      "498 Java or other programming language experience will also be considered\n",
      "499 3+ years of experience using SQL\n",
      "500 Experience using data science libraries such as pandas, matplotlib, scikit-learn, keras, nltk etc\n",
      "501 Experience using Tensorflow is a strong asset\n",
      "502 Experience using ETL/orchestration/workflow management frameworks like Apache Airflow preferred, but not required\n",
      "503 Strong understanding of Google Cloud BigQuery preferred\n",
      "504 Understanding of digital marketing ecosystems and tools like Google Marketing Platform, GA360, Google Ads, Adobe Suite etc\n",
      "505 · Proficient in Microsoft Office (Excel, Word, Access and Outlook).\n",
      "506 Experience in Software Development and coding in a general-purpose programming language such as C, C++, PHP, Java, JavaScript, Node.js (Typescript), Python, etc.\n",
      "507 Experience programming in two or more of the languages including but not limited to C, C++, PHP, Java, JavaScript, Node.js (Typescript) or Python\n",
      "508 Experience working with some of the following: web application development, Unix/Linux environments, mobile application development, distributed and parallel systems, machine learning, information retrieval, networking, developing large software systems, and/or security software development\n",
      "509 Must have APQP experience\n",
      "510 Proficiency with database applications and administration systems, specifically Microsoft Office and the use of statistical software.\n",
      "511 You have experience implementing and debugging microservices, using SQL databases, and leveraging Google Cloud Platform/AWS tooling and services\n",
      "512 We use Go and Java; so you're not shy of mixing it up because you understand the importance of \"the right tool for the right job\"\n",
      "513 Experience in SQL\n",
      "514 Proficiency in at least one modern programming language such as Python and Java\n",
      "515 Apply big data technologies for data extraction transformation and loading (Spark, PySpark, Hadoop, MapReduce, etc)\n",
      "516 Analyze data using analytics tools such as Redshift and ElasticSearch to develop hypothesis and design data driven solutions for our business\n",
      "517 Experience with data technologies including EMR, S3, Dynamodb, ElasticSearch\n",
      "518 Proficiency in coding algorithms using C/C++, Python and MATLAB\n",
      "519 Familiarity with software architecture design in C/C++ and API programming\n",
      "520 · Worked in AWS environment and development and operations\n",
      "521 · Working knowledge of Kubernetes\n",
      "522 · Expert knowledge of backend software development using Java spring to expose and consume RESTful webservices, Async message Queues\n",
      "523 Java: 8 years (required)\n",
      "524 Design and develop a large-scale event-streaming platform using technologies such as Apache Kafka, Flink, Samza, RabbitMQ or similar platforms.\n",
      "525 Experience with MQTT, AMQP, Kafka, or other messaging frameworks\n",
      "526 Strong software development skills using Python, C/C++, Java\n",
      "527 Knowledge of Docker and Kubernetes\n",
      "528 Good experience Node.js, React, Typescript, Python\n",
      "529 Experience with relational database systems including PostgreSQL, Oracle, MySQL, and DB2; and writing complex SQL queries\n",
      "530 Experience with popular Node.js web frameworks and/or utility libraries such as Nest.js, Express, Hapi, Underscore/Lodash, Async, Bluebird.\n",
      "531 Strong proficiency working with database systems such as MySQL, MongoDB PostgreSQL.\n",
      "532 Experience with React.js frameworks\n",
      "533 Experience with ECMAScript 6\n",
      "534 Experience with Container Technologies Docker - (swarm, compose)\n",
      "535 Experience with scheduling and orchestration technologies (Kubernetes, zookeeper, etcd, consul)\n",
      "536 Experience in creating API design/technical documentation (Raml, swagger)\n",
      "537 Experience in post-mortem analysis of a node process\n",
      "538 Experience in messaging protocols such as AMQP (, Rabbitmq, Kafka, Nats, Redis).\n",
      "539 Experience with JIRA, GIT, Postman, and Jenkins\n",
      "540 Our tech stack is Node.js, React, Python, Swift and Kotlin, PHP.\n",
      "541 Python, Pandas, Sci-Kit.\n",
      "542 Snowflake, Presto, Hive, or other data warehousing technologies.\n",
      "543 Airflow, DBT.\n",
      "544 SQL.\n",
      "545 Experience working on AWS.\n",
      "546 Git or other version control systems.\n",
      "547 Experience working with Kubernetes\n",
      "548 We are looking for a candidate with strong C++ software skills and passionate algorithm development capabilities who loves architectural challenges and application of modern design patterns for maintainability\n",
      "549 The ideal candidate has at least five years of relevant Software Engineering experience and some experience with programming languages other than C++.\n",
      "550 5+ years of professional experience developing software in C++\n",
      "551 C++17 experience\n",
      "552 Python, Java, Rust…)\n",
      "553 We are looking for a candidate with a strong technical background in AWS cloud-native software development.\n",
      "554 We are looking for a candidate with a strong technical background in AWS cloud-native software development.\n",
      "555 Minimum 3 years of AWS experience\n",
      "556 Experience in AWS cloud-native application development and devops is an asset.\n",
      "557 Experience in AWS cloud-native development, devops and knowledge of micro-service architecture on Kubernetes and AWS Serverless environments\n",
      "558 Programming experience in Typescript/JS and Python are an asset.\n",
      "559 Strong capabilities around dimensional modelling, data mining and data visualization preferably with tools such as Power BI\n",
      "560 Expert ability to draft, analyse and debug SQL queries and be proficient in scripting languages such as Java, Python, C Sharp, Perl, and others.\n",
      "561 Experience with Google Big Query or Snowflake an asset\n",
      "562 This role is ideally suited to a hands-on technical product manager with a background in software engineering (preferably python and/or C++) that is looking to flex their versatility on both the business and delivery sides of the equation\n",
      "563 Work closely with cross-functional teams and engineers, effectively documenting and communicating requirements into actionable workflows eg Jira tickets\n",
      "564 Experience in cloud native architecture including containerization (Docker etc) and CICD pipeline.\n",
      "565 Experience working with some or all of: OpenCV, ROS, Nvidia Deepstream and platforms, RESTAPI, TensorRT, Openvino, Edge or IOT focused ML frameworks\n",
      "566 Experience with Google Dialogflow is an asset\n",
      "567 Experience with open-source programming languages such as Python, R or Scala is an asset\n",
      "568 Working knowledge of visualization tools such as Tableau and Power BI would be an asset\n",
      "569 · Intermediate knowledge of MS Office Suite\n",
      "570 4+ years of experience in writing production Python code, shell scripts; experience in another relevant language like Scala a plus\n",
      "571 2+ years of experience building and deploying distributed and ML-related infrastructure using frameworks and libraries such as Keras, PyTorch, Horovod, Ludwig, Ray, MXNet, BytePS\n",
      "572 Strong understanding and 2+ years of experience using multiple state of the art Big Data systems such as Spark, Storm, Flink, S3, Redshift; experience with the Azure ecosystem a plus\n",
      "573 At least 2 years of experience working with one or more data mining tools such as R, Python, Scala or SAS\n",
      "574 Hands-on experience working with Big Data technologies such as Spark, Cassandra, and/or Hadoop\n",
      "575 Hands-on experience writing complex SQL queries and working with relational databases such as Oracle, DB2 or SQL Server\n",
      "576 Hands-on experience constructing and manipulating JSON and XML documents and working with NoSQL databases such as MangoDB and CouchDB\n",
      "577 o 4 years of experience with both relational and NoSQL technologies\n",
      "578 o 2 years of experience using data transformation and integration services such as Kafka Connect and/or Py.Spark\n",
      "579 o Knowledge of the Python data ecosystem using pandas and NumPy Experience building and deploying ML pipelines\n",
      "580 o Knowledge of RPA automation tools such as UIPath or Blue Prism\n",
      "581 Be proficient with MS Office (including advanced knowledge of MS Word, Excel, Access & and\n",
      "582 PowerPoint), Adobe Acrobat Professional.\n",
      "583 Worked in AWS environment and development and operations\n",
      "584 Working knowledge of Kubernetes\n",
      "585 Expert knowledge of backend software development using Java spring to expose and consume RESTful web services, Async message Queues\n",
      "586 AWS: 5 years (preferred)\n",
      "587 Kubernetes: 4 years (preferred)\n",
      "588 Responsible for embedded Linux software architecture and implementation.\n",
      "589 Developing C/C++ software according to the company SDLC process.\n",
      "590 Experienced with embedded LINUX, U-Boot, BSP.\n",
      "591 In-depth knowledge of Ethernet switching, routing and application level protocols (L2/L3 protocols) – RSTP, LLDP, STP, IGMP, VRRP, RIP, OSPF, TCP/IP, HTTP, NAT, IGMP, QoS, VLAN, VPN etc.\n",
      "592 Experienced with UNIX/POSIX programming interface.\n",
      "593 Strong experience with low level device drivers (I2C, SPI Master/Slave, Serial/HCI, GPIO, USB, SD, NAND, NOR, RAM, FPGA/CPLD, SerDes, PHY).\n",
      "594 Able to read schematic diagrams, experience with debug and test tools such as Oscilloscope, Logic Analyzer, Multi-meter, JTAG debugger.\n",
      "595 3+ years of experience in modern C++\n",
      "596 3+ years of Experience developing modern compilers, especially with LLVM and MLIR.\n",
      "597 3+ years of Experience with Linux and Windows system programming.\n",
      "598 Python) and advanced SQL skills.\n",
      "599 5+ years of SQL experience\n",
      "600 Knowledge and direct experience with AWS technologies\n",
      "601 Advanced knowledge in scripting with R/Python for statistical analysis\n",
      "602 Knowledge in writing and optimizing SQL to handle extremely large datasets\n",
      "603 Experienced with data visualization using Tableau or similar BI tools to create end-to-end dashboard solutions and reports which effectively convey results to a wide range of users.\n",
      "604 Familiarity with AWS and big data analytic tools (EMR, AWS Athena)\n",
      "605 Knowledge in building advanced visualizations in Tableau\n",
      "606 Experience with AWS, Google Cloud Platform or other PaaS-based solutions\n",
      "607 Knowledge of a wide range of modern programming languages, including PHP, Node.js, Java, ReactJS/React-Native, Objective-C and Swift\n",
      "608 3+ years of experience working with Linux systems, familiar with Linux fundamentals including network protocols\n",
      "609 (Windows experience is a plus)\n",
      "610 Experience with programming and/or scripting languages (Python, Ruby, Bash, Go, Java, PowerShell)\n",
      "611 Experience with container technologies Docker, Kubernetes required\n",
      "612 Experience with Hadoop strongly desired\n",
      "613 Systems configuration management experience with automation tools such as Puppet, Chef, Ansible, and Terraform (Puppet and Terraform preferred).\n",
      "614 Experience building automation tools and managing Continuous Integration (CI) pipelines (Gitlab, Jenkins, TeamCity).\n",
      "615 Experience with Monitoring, Metrics and Central logging tools (ELK, Prometheus, InfluxDB, Grafana, etc.)\n",
      "616 Understanding of source control systems (Git, HG).\n",
      "617 Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design\n",
      "618 Languages include: Java, C and C++\n",
      "619 Experience in the software development and analysis of simulations (knowledge of simulation environments and tools like MATLAB would be an asset)\n",
      "620 Recognized for your strong understanding of databases and big data including MySQL, NoSQL databases, SPLUNK, Python and Alteryx\n",
      "621 Knowledge of Tableau, Splunk or Alteryx\n",
      "622 Experience with some of the following programming languages: C/C++, Java\n",
      "623 Experience with SQL, database design and development (MySQL, SQL Server, PostgreSQL Oracle, Hadoop, MongoDB…)\n",
      "624 Demonstrable knowledge of advanced elements of Windows OS\n",
      "625 Knowledge of how the Windows registry works including backup/restore, key editing, and what each hive is used for\n",
      "626 Understand Windows events including filtering and source allocation\n",
      "627 Understanding of the Windows Network stack including how filters are loaded, the order of operations in stack decisions, and how to manipulate the stack\n",
      "628 Understanding of .Net, Java, and other execution models in Windows including how resources are allocated in each one\n",
      "629 System administration/support experience in Windows and/or Linux\n",
      "630 Comprehensive experience with enterprise networked environments and enterprise networking technologies (LAN/WAN, routers, gateways, firewalls, DNS, LDAP, SQL, Apache)\n",
      "631 Experience with Windows 2008/2012 Server and/or Macintosh environments\n",
      "632 Experience troubleshooting SQLite queries including creating simple to moderately complex queries and the ability to navigate a database on the fly\n",
      "633 Experience working with Windows PowerShell including scripting - Experience troubleshooting MacOS and Linux including command-line interface (CLI) interactions\n",
      "634 Advanced programming skills in Python, Scala, R, and /or Java required\n",
      "635 Experience with Spark is an asset\n",
      "636 Experience with PostgreSQL, HDFS/Hive, MinIO is an asset\n",
      "637 Experience with visualization tools an asset: Power BI/Tableau\n",
      "638 Exposure to Kubernetes, Airflow, Jenkins is an asset\n",
      "639 Demonstrable knowledge of advanced elements of Windows OS\n",
      "640 Knowledge of how the Windows registry works including backup/restore, key editing, and what each hive is used for\n",
      "641 Understand Windows events including filtering and source allocation\n",
      "642 Understanding of the Windows Network stack including how filters are loaded, the order of operations in stack decisions, and how to manipulate the stack\n",
      "643 Understanding of .Net, Java, and other execution models in Windows including how resources are allocated in each one\n",
      "644 System administration/support experience in Windows and/or Linux\n",
      "645 Comprehensive experience with enterprise networked environments and enterprise networking technologies (LAN/WAN, routers, gateways, firewalls, DNS, LDAP, SQL, Apache)\n",
      "646 Experience with Windows 2008/2012 Server and/or Macintosh environments\n",
      "647 Experience troubleshooting SQLite queries including creating simple to moderately complex queries and the ability to navigate a database on the fly\n",
      "648 Experience working with Windows PowerShell including scripting - Experience troubleshooting MacOS and Linux including command-line interface (CLI) interactions\n",
      "649 Deep knowledge of Javascript/HTML/CSS and today’s major web frameworks (React, Vue, Angular)\n",
      "650 Experience in delivering mobile applications on both Android and iOS\n",
      "651 Knowledge of multi-tier architectures across multiple technology stacks .net, Java, J2EE, web servers, caching, application servers, RDBMS/NoSQL: Postgres, Dynamo DB\n",
      "652 Experience with Cordova, Android, iOS development\n",
      "653 Experience with Flutter/Dart\n",
      "654 Technologies We Use: Javascript, Typescript, Vue, React Native, Kotlin, Python, Java, Fast.io, Quarkus, Redis, Postgres, Kubernetes, Docker, Jenkins, AWS, GCP, Azure\n",
      "655 Deep experience in modern web development with HTML5, CSS3.0, and Javascript frameworks (React, Vue, AngularJS)\n",
      "656 Experience with modern Javascript tooling (Webpack, Gulp, Grunt, etc.) and Proficiency in at least one modern dynamic programming language (Ruby, Python, Javascript)\n",
      "657 You have strong opinions on the standards modern HTML, CSS, and Javascript should be held to\n",
      "658 Strong experience with advanced analytics tools for Object-oriented/object function scripting using languages such as R, Python, Java, C++, Scala, and others.\n",
      "659 Experience in working with DevOps capabilities like version control, automated builds, testing and release management capabilities using tools like Git, Azure DevOps\n",
      "660 Experience working with popular data discovery, analytics and BI software tools like Tableau, Qlik, PowerBI and others for semantic-layer-based data discovery.\n",
      "661 KEY SKILLS/ TASKS: Integration between AI modules and infrastructure (Databases, User Interface, Server, etc...), SQL and NoSQL, Dockers, Kubernetes, Apache Hadoop, Apache Spark, Apache Kafka, Cloud environments (e.g., AWS, GCP, Azure), CI/CD, Web Services, Python\n",
      "662 Advanced knowledge in SQL and NoSQL and familiarity with various types of databases\n",
      "663 Experience with containerization (e.g., Dockers)\n",
      "664 Experience with distributed systems like big data processing/streaming/storage engines (e.g., Apache Hadoop, Apache Spark, Apache Kafka), different Cloud environments (e.g., AWS, GCP, Azure), or resource management systems (e.g., Apache Mesos, Kubernetes)\n",
      "665 (Python)\n",
      "666 Maintain, assess, and create Web sites using React framework\n",
      "667 5+ years of experience working with React.js and developing front end web applications\n",
      "668 Strong HTML, CSS, responsive design, and JavaScript skills\n",
      "669 Familiarities with modern JavaScript tools including Node, npm, Webpack, GraphQL\n",
      "670 Experience with Gatsby\n",
      "671 Proficiency with Git version control\n",
      "672 Experience with capabilities of major Cloud Service providers (Google, AWS, Azure) a plus\n",
      "673 Working with the internals of a distributed compute engine (Spark, Presto, DBT, or Flink/Beam)\n",
      "674 Query optimization, resource allocation and management, and data lake performance (Presto, SQL)\n",
      "675 Cloud infrastructure (Google Cloud, Kubernetes, Terraform)\n",
      "676 Security products and methods (Apache Ranger, Apache Knox, OAuth, IAM, Kerberos)\n",
      "677 Deploying and scaling ML solutions using open-source frameworks (MLFlow, TFX, H2O, etc.)\n",
      "678 Building full-stack applications (Ruby/Rails, React, TypeScript)\n",
      "679 Background and practical experience in statistics and/or computational mathematics (Bayesian and Frequentist approaches, NumPy, PyMC3, etc.)\n",
      "680 Modern Big-Data storage technologies (Iceberg, Hudi, Delta)\n",
      "681 3+ years of programming experience with at least one modern language such as Java, C++, or C# including object-oriented design\n",
      "682 3+ years of programming experience with at least one modern language such as Java, C++, or C# including object-oriented design\n",
      "683 Administer Windows server and desktop platforms within the control system environment\n",
      "684 Knowledge of Microsoft Windows desktop and server Operating Systems, security, virtualization, Active Directory, and computer networking fundamentals\n",
      "685 Ruby and/or Rails, JavaScript, PHP, or Laravel is preferred\n",
      "686 Our client is looking for a Software Engineer to contribute to the overall design, development, and maintenance of their back-end AWS product services.\n",
      "687 In a web applications back-end development or equivalent role using PHP/Python or another server side scripting language\n",
      "688 Working with SQL relational databases and NoSQL databases\n",
      "689 Experience working with AWS services (Glue, Athena, Redshift, EMR, Kinesis, Lambda, etc.)\n",
      "690 Experience with API development (Slim, Restlet, Falcon)\n",
      "691 Experience using a version control system (Subversion or Git)\n",
      "692 Experience working in a Mac OS X and/or Linux environment\n",
      "693 Our core technologies currently include Python, Java, Scala, and we continue to adopt the best of breed in cloud-native, low-latency technologies\n",
      "694 Excellent SQL (required) coding and experience with a broad array of development tools and platforms including a strong Linux background and big data management tools/languages such as Python(required), Java and Scala.\n",
      "695 Expertise in relational database design and data models (Oracle, Teradata, RedShift)\n",
      "696 Experience with Cloud platforms – Azure, AWS, Snowflake\n",
      "697 Experience with CI/CD – Git/Bitbucket, JIRA, Bamboo\n",
      "698 Experience with Databrick, Delta Lake, Spark data pipeline development an asset\n",
      "699 Preferred experience with business intelligence tools such as Sisense, Qliksense, Tableau and MicroStrategy an asset\n",
      "700 Python including data processing modules NumPy, Pandas, SciPy\n",
      "701 Python Machine Learning modules such as Keras, TensorFlow, PyTorch\n",
      "702 SQL (MySQL and Postgres)\n",
      "703 TimeSeries database (InfluxDB)\n",
      "704 Cloud computing specifically AWS (VPC, S3, Aurora, RDS, EC2, Step Functions, Lambda, SageMaker)\n",
      "705 APIs: REST, GraphQL\n",
      "706 Development tools: PyCharm, Docker, GIT, Jira, Confluence\n",
      "707 Ability to read and make sense of common web technologies and languages such as HTML, JavaScript, PHP etc.\n",
      "708 Python) to understand and contribute to research tools and ad-hoc scripts.\n",
      "709 DNS\n",
      "710 Whois\n",
      "711 HTML\n",
      "712 Python\n",
      "713 Recognized for your strong understanding of databases and big data including MySQL, NoSQL databases, SPLUNK, Python and Alteryx\n",
      "714 Knowledge of Tableau, Splunk or Alteryx\n",
      "715 Experience with some of the following programming languages: C/C++, Java\n",
      "716 Experience with SQL, database design and development (MySQL, SQL Server, PostgreSQL Oracle, Hadoop, MongoDB…)\n",
      "717 Ability to write robust code in Python\n",
      "718 Familiarity with machine learning frameworks and data analysis tools such as numpy, pandas, scikit-learn, or pytorch\n",
      "719 Professional coding experience in one or more modern databases such as MongoDB, PostgreSQL.\n",
      "720 3 years of experience in Golang, Java, C++, or equivalent (academic projects count)\n",
      "721 An understanding of insert and query efficiency in RDBMS (such as PostgreSQL or MySQL)\n",
      "722 Experience with Python\n",
      "723 An understanding of Docker\n",
      "724 Good experience with JavaScript / TypeScript, CSS, Sass, and other modern web frameworks.\n",
      "725 (Python, Go, JavaScript etc.)\n",
      "726 Experience analyzing database queries and write good performance SQL.\n",
      "727 Experience with Vue is an asset.\n",
      "728 Experience with graphics design and visual design tools such as Adobe Creative Suite (Photoshop, Adobe Illustrator), Figma, etc\n",
      "729 Have software engineering experience with proficiency in Python based development\n",
      "730 Have detailed experience of Agile software development methodologies using tools such as GIT, Jira, and Confluence\n",
      "731 Demonstrate experience with UNIX/Linux operating systems and cloud hosting such as AWS, Kubernetes, EKS, containers and microservices\n",
      "732 Python: 3 years (preferred)\n",
      "733 Git: 2 years (preferred)\n",
      "734 Good experience with scaling web applications, ideally with Python and MySQL applications.\n",
      "735 Knowledge of Kubernetes is an asset.\n",
      "736 Experience analyzing database queries and write good performance SQL is an asset.\n",
      "737 Python/SQL Data Engineer - Big Data Platform Build - Dataiku\n",
      "738 On behalf of our client in the Banking Sector, PROCOM is looking for a Python/SQL Data Engineer - Big Data Platform Build - Dataiku.\n",
      "739 Python/SQL Data Engineer - Big Data Platform Build - Dataiku – Mandatory Skills\n",
      "740 Python or R (either acceptable) Pandas for libraries within the data frame/Numpy for adding in logic\n",
      "741 SQL expertise database and queries (nested SQL, pivots using SQL, case management)\n",
      "742 Designed and implemented the infrastructure required for optimal extraction transformation, and loading of data from a wide variety of data sources using SQL, MSSQL, Spark, TSQL, NoSQL,\n",
      "743 Python/SQL Data Engineer - Big Data Platform Build - Dataiku – Nice to Have Skills\n",
      "744 Experience with Amazon AWS big data services (Lambda architecture, Kinesis, Glue) or equivalent cloud services\n",
      "745 Understanding of Jenkins, GitHub\n",
      "746 Python/SQL Data Engineer - Big Data Platform Build - Dataiku - Assignment Location\n",
      "747 The successful candidate has strong knowledge of the Windows operating system, is familiar with building and measuring efficient computational data flows and combining these skills to combat the continuous evolution of the threat landscape\n",
      "748 Programming experience - Python/Lua\n",
      "749 Strong knowledge of Windows operating system, internals and forensiz tools\n",
      "750 Big data experience, Elastic Search, Kibana, Redshift\n",
      "751 Have software engineering experience with proficiency in Python based development\n",
      "752 Have detailed experience of Agile software development methodologies using tools such as GIT, Jira, and Confluence\n",
      "753 Demonstrate experience with UNIX/Linux operating systems and cloud hosting such as AWS, Kubernetes, EKS, containers and microservices\n",
      "754 Python: 5 years (preferred)\n",
      "755 GIT, Jira, and Confluence: 5 years (preferred)\n",
      "756 UNIX/Linux: 5 years (preferred)\n",
      "757 AWS, Kubernetes, EKS, containers and microservices: 5 years (preferred)\n",
      "758 Strong Python developer experience\n",
      "759 Hands on experience with Django, Flask, or other Python frameworks\n",
      "760 Substantial knowledge of HTML, CSS, JavaScript (ES6+)\n",
      "761 Proficient understanding of code versioning tools such as Git\n",
      "762 Knowledge of AWS is a plus\n",
      "763 Strong SQL skills, including but not limited to PostgreSQL\n",
      "764 Strong Knowledge of Python and Elasticsearch Queries\n",
      "765 Understanding of Docker\n",
      "766 Knowledge of version control systems, GIT preferred\n",
      "767 Understanding of JavaScript engines and browser rendering engines\n",
      "768 Knowledge or experience with Docker\n",
      "769 Proficiency in Python, Java, or Scala\n",
      "770 Scripting in JMeter, Artillery and other testing languages\n",
      "771 Use of back end testing tools such as Flood.io or Blazemeter\n",
      "772 Java virtual machine testing and diagnostics\n",
      "773 Infrastructure capacity planning for AWS environments and Oracle eComm platforms\n",
      "774 Front-end scripting with HTML5, Javascript and CSS\n",
      "775 Following agile sprint development cycles using JIRA/Confluence or a similar platform\n",
      "776 Linux-based container development with Docker and Kubernetes, with Jenkins/Koala/Travis\n",
      "777 KEY SKILLS/ TASKS: Automotive, embedded C or C++, ADAS experience is a plus\n",
      "778 Collaborate with Controls Engineers in architecting requirements, and supporting design reviews to create C, and/or C++ code\n",
      "779 3+ (Intermediate Engineer) or 8+ (Senior Engineer) years designing and developing in C and/or C++\n",
      "780 Development knowledge in another language, such as Python, Matlab\n",
      "781 Exposure to Automotive Platforms, such as Ethernet/CAN/LIN, AUTOSAR\n",
      "782 Interest in Data Analytics, Tools and Databases, such as Machine Learning, HUE, Jupyter, PowerBI, Hadoop/SQL/noSQL\n",
      "783 Windows, Linux, Virtual Machine).\n",
      "784 Hands-on practical software coding experience in SQL and Python preferred\n",
      "785 Knowledge of R and C/C++ is an asset.\n",
      "786 Knowledge of scientific weather software applications (e.g., NCO, NCL, NCVIEW,WGRIB, ECCODES), standard scientific data formats (e.g., GRIB, NETCDF, HDF5, XML,CSV, BUFR) desirable.\n",
      "787 Proficiency in Python, and RDKit, scikit-learn, and PyTorch libraries\n",
      "788 4+ years of Python or Java development experience\n",
      "789 4+ years of SQL experience\n",
      "790 required MySQL, PostreSQL, NoSQL, Machine Learning solutions desired\n",
      "791 Understanding of Microsoft Azure Data & AI products\n",
      "792 Expertise in one or more technologies like Teradata, Oracle Exadata, IBM Netezza, SAP (HANA, BW), HDInsight, Hadoop, Cloudera/Hortonworks, Apache Spark, Snowflake, MapR, AWS (Redshift, Glue), Google (BigQuery)\n",
      "793 Azure Data Engineer or Azure AI Engineer\n",
      "794 Front-end web development: HTML, JavaScript, CSS, AJAX, TypeScript, React/Redux\n",
      "795 Back-end and scripting: Java, Python, C++, PHP, Go, SQL\n",
      "796 Proficiency with modern source control (Github/Gitlab)\n",
      "797 Experience using CI/CD tools: Jenkins, GitLab CI, ArgoCD\n",
      "798 Good experience with container techniques (Kubernetes) on public cloud platforms (GCP, AWS)\n",
      "799 Expertise in ETL, SQL\n",
      "800 Expertise in Azure, Azure Data Bricks, Azure SQL, Synapse\n",
      "801 Expertise developing dataflows using NiFi/ADF, Databricks.\n",
      "802 Advanced, hands-on experience in Spark architecture and implementation\n",
      "803 Experience in working with Distributed Message Systems like Kafka\n",
      "804 Hands on experience in Python, Pyspark or R\n",
      "805 Expert in writing complex SQL and procedures.\n",
      "806 Knowledge of security measures like HTTPS and Kerberos\n",
      "807 Knowledge in Graph Databases, preferably Neo4J, Cypher and Cosmos DB\n",
      "808 Azure Data Lake Store, Databricks Deltalake\n",
      "809 Spark ML\n",
      "810 Good experience working with Azure Databricks, Azure Data Factory and Azure Data Lake\n",
      "811 Experience with the Microsoft SQL Server Analytics stack including: Core SQL, SSIS, SSRS, SSAS,\n",
      "812 Programming experience in Python\n",
      "813 Experience working with SQL and NoSQL databases\n",
      "814 Gradle, Maven, Bamboo, TeamCity, Git)\n",
      "815 Data Visualization experience in Power BI, Tableau, or similar\n",
      "816 Experience using the Apache Hadoop ecosystem (Spark, Data Lake, Hive, HDFS, Impala) to tackle \"big data\" problems\n",
      "817 Some experience using Docker\n",
      "818 You'll work within an agile team using Protractor/Selenium/Javascript/Cucumber test automation framework to create complex test scenarios before integrating different systems\n",
      "819 Develop and execute Automated tests in Java\n",
      "820 Experience with Protractor or Angular\n",
      "821 Development experience with Javascript, Typescript, Java, Python, Ruby, C++\n",
      "822 Strong QA development using Selenium and Java\n",
      "823 Working knowledge of Oracle DB and ability to author scripts and procedures for test data management tools and processes\n",
      "824 Practical coding experience in Verilog, Python, or C/C++, demonstrated in research projects or prior work experience.\n",
      "825 Familiarity with at least one of these areas: digital logic design; data structures and algorithms; linear algebra; processor architecture; compiler tools (e.g., LLVM).\n",
      "826 Advanced knowledge of SQL and one of the data modeling tools such as Erwin, Workbench, SQL DBM or similar.\n",
      "827 Adapt to new technologies in Microsoft Azure Cloud\n",
      "828 Expertise in one of the Data modeling and architecture tools such as Erwin, Power designer, SQL DBM etc.\n",
      "829 Advanced skill with Excel, Python, SQL, NoSQL, R, Power BI, GIT, PowerShell, CLI\n",
      "830 Experience with cloud-based data warehouse architecture preferably in Azure\n",
      "831 Experience developing cloud-based solutions using Microsoft Azure Data Stack (ADFv2, Azure Data Lake Gen2, Azure Databricks, Analysis Services, Azure Functions, etc.)\n",
      "832 Experience with big data processing frameworks and techniques such as HDFS, MapReduce, Spark, Hive etc.\n",
      "833 Experience programming in Java, C++, Python or related language\n",
      "834 Experience with AWS and Sagemaker\n",
      "835 Extensive experience coding and building solutions using Python.\n",
      "836 Extensive experience with statistical packages such as spaCy, scikit-learn, etc.\n",
      "837 Working knowledge of Docker and Kubernetes.\n",
      "838 As a backend engineer you design, build, and maintain microservices written in Java/Go leveraging a wide variety of technologies built in house and open source that power our Tier 1 services affecting millions of daily active users with tens of thousands of requests per second.\n",
      "839 Experience coding with C++, Java, Python, or Go\n",
      "840 Experience with programming languages such as Go, Python, C++, Java\n",
      "841 This Data Engineering role is an opportunity to perform product development, programming, ETL and database work in support of Data Science, Data Reporting & Visualization, and Product Development functions within a small team using technologies including but not limited to SQL Server, AWS, Python, C#, SSIS, AWS, Windows, Linux, and the Apache Hadoop ecosystem.\n",
      "842 Assist in current day-to-day support activities of Data Visualization and Data Science teams, including generating reporting data sets for business users using Tableau, Excel, or other delivery methods.\n",
      "843 3+ years’ proven experience in database design, data manipulation and/or software engineering role using SQL Server or similar RDBMS environments, including stored procedures, views, and ETL processes (Extract, Transform, Load).\n",
      "844 Experience using cloud-enabled technologies such as Amazon Web Services (AWS), specifically S3, Athena, EMR, RDS, or other AWS database related products.\n",
      "845 Demonstrated knowledge of advanced SQL and at least one procedural/object-oriented programming language (Python, C, C#, Java, etc).\n",
      "846 Hadoop, Spark, Kafka); experience compiling, manipulating and analyzing large datasets, with a good understanding of data processing frameworks.\n",
      "847 Experience developing SQL Server Integration Services would be beneficial.\n",
      "848 Programming experience in Unix shell scripting.\n",
      "849 Docker, Jenkins).\n",
      "850 Experience using Git, Github, Zenhub.\n",
      "851 Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design\n",
      "852 Experience with Amazon Web Services or Cloud Services\n",
      "853 Experience developing in Amazon Web Services - AWS\n",
      "854 3+ years’ experience in SQL/Spark, R, Python\n",
      "855 C, C++, Java, Python, or Go)\n",
      "856 Machine Learning Software such as Tensorflow/Pytorch, Caffe, Scikit-Learn, or Spark MLLib\n",
      "857 Expertise in Java or Python, OOP, Design Patterns, time and space-efficient algorithms\n",
      "858 Analyse large datasets with tools like jupyter notebooks, python and sql, and translate them into actionable insights for our client, or the larger public through white paper publications\n",
      "859 Proficient in SQL, Excel, Python\n",
      "860 GIS software (arcGIS, QGIS)\n",
      "861 Worked in AWS environment and development and operations\n",
      "862 Working knowledge of Kubernetes\n",
      "863 Expert knowledge of backend software development using Java spring to expose and consume RESTful web services, Async message Queues\n",
      "864 RestFul WebServices,AWS: 5 years (preferred)\n",
      "865 Kubernetes,Java spring: 3 years (preferred)\n",
      "866 In-depth understanding of TCP/IP and network security (SSL/TLS, VPN, Firewall)\n",
      "867 Experienced in managing and troubleshooting Linux or Unix based operating systems\n",
      "868 Good knowledge of authentication protocols and methods (LDAP, Kerberos)\n",
      "869 Knowledge of database maintenance and SQL\n",
      "870 C, C++, Java, Python, or Go)\n",
      "871 You will be at the forefront as we work together to design and build the next generation BI platform based on the Google Cloud Platform using technologies and tools that will include SQL, Python, Bigquery, Looker, and Github.\n",
      "872 Architecting and implementing next generation data and analytics platforms on Google Cloud Platform\n",
      "873 Knowledge of SQL including writing, debugging and tuning T-SQL queries, creating SQL tables, views and stored procedures and a strong understanding of relational databases\n",
      "874 4+ years of experience working in iOS development.\n",
      "875 Nice to have: Experience building ways to measure user behavior on iOS applications.\n",
      "876 Experience administering and supporting Windows OS (both workstations and server) and one of the following: Apple or Linux-based operating systems (e.g\n",
      "877 XP, Windows 7, 2003, 2008, OS X)\n",
      "878 Strong understanding of Windows event log analysis\n",
      "879 Experience with SQL query construction\n",
      "880 Experience with OSQuery Programming and scripting skills - proficient knowledge of Powershell\n",
      "881 Develop firmware functions and features in C for embedded microcontrollers in CPU/GPU\n",
      "882 Excellent knowledge of C, C++ and a scripting language, experience with programming in assembly is an asset\n",
      "883 Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design\n",
      "884 Proficiency in, at least, one modern programming language such as C, C++, Java, or Perl\n",
      "885 We are managing massive scale streaming systems, applying machine learning and data science expertise using Hadoop, Elastic MapReduce, and Spark to drive optimizations and insights while building front-ends in ReactJS to help internal and external advertisers to deeply understand their customers and markets.\n",
      "886 You must be comfortable and confident working on Linux systems\n",
      "887 Experience with data visualization using Tableau, Quicksight, or similar tools\n",
      "888 Experience with SQL\n",
      "889 2+ years of experience with object-oriented languages such as Python and Scala · Experience with Machine Learning applications (feature generation/selection, supervised/unsupervised learning)\n",
      "890 o Strong understanding of different Java standards and enterprise framework.\n",
      "891 o RHEL/Unix, Java, Spring, SQL, Oracle, Weblogic, OSM/UIM, BPM\n",
      "892 o Configuring and supporting containerized applications (Redhat Openshift platform preferred, but Docker and Kubernetes is acceptable)\n",
      "893  NoSQL DB experience\n",
      "894  Apache Kafka experience\n",
      "895  Openshift service mesh (istio)\n",
      "896 Java, weblogic using the WLS operator or any other K8S operators)\n",
      "897 Dynatrace Managed, Prometheus/Grafana) tools in a DevOps or Application Support role\n",
      "898  JIRA\n",
      "899  Gitlab/ Github\n",
      "900  Jenkins and/or uDeploy\n",
      "901  Chef/Puppet/Ansible\n",
      "902 Experience using performance tools such as Ixia\n",
      "903 Proficiency in Python required.\n",
      "904 strong knowledge of Linux\n",
      "905 Experience with setting up and testing using virtual machines, ESXI/Hyper-V/KVM as VM\n",
      "906 Automation experience using Selenium and Robot a plus\n",
      "907 Python) and advanced SQL skills.\n",
      "908 5+ years of SQL experience\n",
      "909 Knowledge and direct experience with AWS technologies\n",
      "910 Write high quality SQL code to retrieve and analyze data from database tables (primarily Redshift), and learn and understand a broad range of Amazon’s data resources and know how, when, and which to use and which not to use.\n",
      "911 Experience with AWS services (Redshift, S3)\n",
      "912 Experience with Python\n",
      "913 3 - 15 years experience writing large scale systems in C/C++\n",
      "914 Tens of thousands of enterprise customers use Redshift to crunch through exabytes of data in the cloud to make business critical decisions every day\n",
      "915 We are actively hiring talented software engineers in the query processing team of Redshift\n",
      "916 Query processing is at the heart of Redshift data plane and is responsible for query analysis, query optimization and the massive parallel execution engine\n",
      "917 Design and implement new SQL language features which add to the rich functionalities Redshift provides to the end users such as analysts, data engineers and data scientists.\n",
      "918 Work on integration between Redshift and other AWS services in the AWS ecosystem, including data ingestion, federation, machine learning and many more.\n",
      "919 Proficient in C++, C or Java.\n",
      "920 Proficiency with Java, Scala, or Python\n",
      "921 Experience with data processing (such as Hadoop, Spark, Pig, Hive, MapReduce, etc);\n",
      "922 Proficiency with SQL (Relational, Redshift, Hive, Presto, Vertica);\n",
      "923 Experience with GCP (BigQuery, BigTable, DataFlow) or AWS.\"\n",
      "924 Experience with real-time streaming (Apache Kafka, Apache Beam, Heron, Spark Streaming);\n",
      "925 Experience with Kubernetes;\n",
      "926 Work with public cloud services including Amazon Web Services, Microsoft Azure and google Cloud Platform for use with our platform execution environment\n",
      "927 Design, implement, and refine NoSQL database models for the application\n",
      "928 Knowledge of Linux-based operation system fundamentals\n",
      "929 Proficiency in multiple general purpose programming languages, such as Python, Go, Roby, JavaScript, Rust, Java, C/C++, etc.\n",
      "930 Experience with Java Microservices, ELK and RDS/Postgres.\n",
      "931 Experience with Kafka.\n",
      "932 Experience with large complex data environments, including experience in database management, varied data infrastructures – including relational (MS SQL Server, Postgres) and unstructured databases (Hadoop/Hive), data cubes, multidimensional and tabular, data analytics, data processing, ETL, data ingestion and API development or similar role using development skills in common programming languages (SQL, R, Python, etc.) to drive business recommendations and BI/visualization products such as Power BI or Tableau.\n",
      "933 Designing large scale distributed Kubernetes based systems\n",
      "934 Managing bare-metal and cloud Kubernetes clusters\n",
      "935 Experienced with Unix/Linux operating systems internals as well as with networking\n",
      "936 Experienced with containers and container orchestration tools (Docker, Kubernetes)\n",
      "937 Experienced programmer in one or more of: python, Golang, C/C++, javascript\n",
      "938 Experienced with automation tools like Ansible\n",
      "939 Is able to install a Kubernetes cluster\n",
      "940 Experienced with rook and/or Ceph\n",
      "941 Familiar with MS Excel and Word\n",
      "942 3+ years experience in Python and SQL, including using libraries like Pandas, Scikit-learn, MatPlotLib\n",
      "943 Knowledge of hardware design practices, schematic capture(Orcad), PCB Layout(Allegro), thermal management\n",
      "944 Knowledge of optical communication systems, Python test scripting\n",
      "945 Python development experience\n",
      "946 Golang or Java also preferred\n",
      "947 Experience with Google cloud, Azure or AWS alternatively\n",
      "948 Python), data warehouse (NoSQL, logging, columnar, Redshift, etc.), big data (e.g Hadoop, Spark, etc.), and analytics (e.g\n",
      "949 MATLAB and/or Python)\n",
      "950 Has working knowledge of Microsoft Word, PowerPoint & Excel\n",
      "951 Strong SQL/Data Warehousing experience\n",
      "952 Strong backend development skills using languages such as Java, Python, Kotlin, Go, etc.\n",
      "953 Query optimization, resource allocation and management, and Data Lake performance tuning (Parquet, Delta, Spark)\n",
      "954 Building robust Data pipelines using open-source Data frameworks such as Spark, Beam, Airflow, etc.\n",
      "955 Experience in one or more major cloud vendors (AWS, GCP, Azure)\n",
      "956 Experience with Databricks ecosystem.\n",
      "957 Experience with streaming technologies such as Kafka, Pulsar, Flink etc.\n",
      "958 Experience and strong Java/J2EE/Oracle DB/Unix Scripting skills.\n",
      "959 Experience working in Linux or Unix environment\n",
      "960 Python/Machine Learning - Good to have.\n",
      "961 Experience using MKS or GIT or Clear Case or another code repository\n",
      "962 Bachelor degree in Science program or equivalent experience 2+ years experience in commercial software testing in one or more of the following roles: Performance Engineer, Automation Engineer, Software Developer, SDET Solid background in coding - JAVA is a must Knowledge of at least 2 of the following: Javascript/Node.js, Python, Bash Experience writing and debugging SQL queries Extensive REST API testing Experience with Code Coverage tools Collaborate with Software Engineers on technical design and implementation, as well as on developing test scenarios and test cases\n",
      "963 Knowledge of AWS (S3, ECS, Lambda)\n",
      "964 Bachelor degree in Science program or equivalent experience 2+ years experience in commercial software testing in one or more of the following roles: Performance Engineer, Automation Engineer, Software Developer, SDET Solid background in coding - JAVA is a must Knowledge of at least 2 of the following: Javascript/Node.js, Python, Bash Experience writing and debugging SQL queries Extensive REST API testing Experience with Code Coverage tools Collaborate with Software Engineers on technical design and implementation, as well as on developing test scenarios and test cases\n",
      "965 Knowledge of AWS (S3, ECS, Lambda)\n",
      "966 Strong Experience with Python (strong emphasis on pandas, numpy, plotting)\n",
      "967 Strong Professional Experience with MySQL / BigQuery\n",
      "968 Experience with data visualization / dashboarding tools like Tableau\n",
      "969 Experience with distributed computation systems like Spark or Dask\n",
      "970 Experience on AWS or Google Cloud\n",
      "971 Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design\n",
      "972 Proficiency in at least one modern programming language such as C, C++, C#, Java\n",
      "973 Knowledge of Core Java/Scala\n",
      "974 Expertise in Data Architecture, ETL, SQL\n",
      "975 Expertise in Azure, Azure Data Bricks, Azure SQL, Spark\n",
      "976 Expertise developing dataflows using NiFi/ADF, Databricks\n",
      "977 Advanced, hands-on experience in Spark architecture and implementation using several methods\n",
      "978 Experience in working with Distributed Message Systems like Kafka.\n",
      "979 Hands on experience on Python, Pyspark Or R.\n",
      "980 Expert in creating and analyzing complex SQL queries and procedures.\n",
      "981 Knowledge of security measures like HTTPS and Kerberos\n",
      "982 Experience using NoSQL databases.\n",
      "983 Knowledge in Graph Databases, preferably Neo4J, Cypher and cosmos DB.\n",
      "984 Azure Data Lake Store, Databricks Delta lakes.\n",
      "985 3+ years of experience supporting or building AWS solutions\n",
      "986 Dive deep into AWS technologies, such as Machine Learning, Big Data, Web Applications, Security, Networking, High Performance Computing, Storage, Databases, Enterprise Applications, Migration Strategies or other solutions areas to understand the services and develop effective training for our customers.\n",
      "987 Experience with e-Learning video creation tools such as Vyond, Photoshop, Gimp, or Camtasia\n",
      "988 You have professional experience working with web technologies such as React and Ruby\n",
      "989 A validated understanding of ES6 and modern JavaScript for the web.\n",
      "990 At least 2-5 years of career experience writing code within a React.js framework.\n",
      "991 Experience with version control tools like Git.\n",
      "992 Experience in web development, and the basics of HTML and CSS and the semantic meaning of these tags\n",
      "993 Professional experience with AngularJS 1.4\n",
      "994 Experience with other web frameworks and libraries such as Vue, Angular, etc.\n",
      "995 Knowledge of AWS, and infrastructure as code using technologies such as Terraform.\n",
      "996 Evaluate, adopt, and document any new processes, tools, or updates to improved builds and release processes or existing Jira, Confluence page, and TestRail.\n",
      "997 5+ years of experience supporting & maintaining AWS, and Testing/ Staging environment builds\n",
      "998 Proficient with monitoring/ data collection tools, configuration management, and automation tools (Puppet or Chef) & container management technology (Docker).\n",
      "999 Expertise with strong knowledge of Source Code Management, Continuous Integration/Delivery solutions (Git/Stash, GitLab, Maven, and UDeploy).\n",
      "1000 Familiarity in supporting and maintaining, scalable enterprise-class applications in public cloud (AWS) or private cloud solutions.\n",
      "1001 Excellent competencies with BI tools like Power BI and Tableau;\n",
      "1002 As an Algolux C++/GPGPU Software Developer, you will contribute to Deep Learning based Computer Vision applications on a variety of platforms and hardware\n",
      "1003 Leverages the power of existing Neural Network inferencing frameworks like TensorRT, OpenVINO, CoreML, TensorFlow, etc.\n",
      "1004 Implement or port machine learning and image processing algorithms to NVIDIA Drive AGX, Intel Movidius Myriad VPU, etc.\n",
      "1005 Write application software on automotive DNN platforms, such as NVIDIA, Movidius, Qualcomm, and Renesas.\n",
      "1006 Excellent C++ development skills:\n",
      "1007 Mastery of modern C++ standards (C++11 or more recent).\n",
      "1008 Familiarity with object-oriented software design patterns, and their implementation in C++.\n",
      "1009 Experience with debugging and using tools such as gdb, lldb, valgrind, etc.\n",
      "1010 Familiarity with cross-platform build systems, like CMake.\n",
      "1011 Comfortable using collaborative development tools such as Git and Jira.\n",
      "1012 Experience with GPGPU programming, in CUDA, OpenCL, Metal, etc.\n",
      "1013 Experience with Neural Network inference frameworks, such as TensorRT, OpenVINO, CoreML, TensorFlow, etc.\n",
      "1014 CI/CD tools and pipelines, like GitLab.\n",
      "1015 Virtualization and deployment tools like Docker.\n",
      "1016 Expertise in Java or Python, OOP, Design Patterns, time and space-efficient algorithms\n",
      "1017 Hands on experience with Deep Learning frameworks like PyTorch, TensorFlow.\n",
      "1018 Proficiency in programming languages like Python and C/C++\n",
      "1019 Experience with runtime environments (OpenVINO, ONNX runtime, TVM etc.) would be a huge plus.\n",
      "1020 Our technologies include Ruby on Rails, React, Typescript, GraphQL, Aerospike, Redis, Elasticsearch, Amazon Redshift, and others\n",
      "1021 Experience with AWS and other cloud providers\n",
      "1022 Experience in Ruby, Go, and Terraform Hands-on scripting experience (e.g\n",
      "1023 Python, Perl, JavaScript, JQuery, etc.)\n",
      "1024 ITIL, Zachman, TOGAF, etc.)\n",
      "1025 Experience with AWS, GCP, Azure, or other cloud environment\n",
      "1026 You will have the opportunity to learn the Tableau Analytics Platform offerings, the descriptive and predictive (AI/ML) use cases that best leverage them and the IT environments with which our platform integrates\n",
      "1027 Supports the sales team’s readiness in the use of Tableau products.\n",
      "1028 3+ years’ experience using Tableau Software (inclusive of both Tableau and Tableau CRM) or other business intelligence solutions.\n",
      "1029 Proficiency in technologies complimentary to Tableau software such as the following: Enterprise software architectures, Salesforce, cloud technologies (e.g., AWS, Azure, Google), ETL (e.g., Informatica, Alteryx), SQL or MDX (e.g., MySQL, Snowflake, PostgresSQL, Oracle, SQL.\n",
      "1030 Proficient in R or Python\n",
      "1031 Excellent SQL/Spark skills\n",
      "1032 Experience with AWS\n",
      "1033 Hands-on experience building models with deep learning frameworks (Tensorflow or similar)\n",
      "1034 Experience in Ruby, Go, and Terraform Hands-on scripting experience (e.g\n",
      "1035 Python, Perl, JavaScript, JQuery, etc.)\n",
      "1036 ITIL, Zachman, TOGAF, etc.)\n",
      "1037 Experience with AWS, GCP, Azure, or other cloud environment\n",
      "1038 Monitor work and ensure optimal utilization of all SQL scripts and document all database requirements and analyze data anomalies and prepare reports for cycle.\n",
      "1039 Experience and Proficiency in writing SQL queries.\n",
      "1040 Good understanding of Java scripts usage in Cognos.\n",
      "1041 Be proficient in at least one high-level programming language such as Python or Ruby\n",
      "1042 Be comfortable working with AWS services\n",
      "1043 The selected candidate will have prior experience with ML deployment, Python, and have used Linux or Git\n",
      "1044 Prior SQL knowledge is also desired.\n",
      "1045 Expertise in using machine learning libraries in Python, or similar.\n",
      "1046 Experience with complex SQL using PostgreSQL, or similar.\n",
      "1047 Experience in consuming and building APIs in Node.js, Python, or similar.\n",
      "1048 An understanding of Linux systems\n",
      "1049 A high level of comfort using Git and Github\n",
      "1050 Experience with agile tooling (e.g., Jira, Confluence)\n",
      "1051 Strong understanding of Windows, macOS, and Linux operating systems\n",
      "1052 Experience with programming or scripting languages such as PowerShell, Python, and Bash\n",
      "1053 Experience with large scale cloud platforms such as AWS, Azure, GCP, etc.\n",
      "1054 Manage the Azure Synapse environments ensuring stability, good performance, and proper security controls.\n",
      "1055 Deploy and modify Azure resources using Terraform scripting.\n",
      "1056 Manage user access to all cloud resources deployed for Data and Analytics like ADLS, Azure Synapse, Azure Machine Learning, and Azure Data factory.\n",
      "1057 Cloud Data warehousing on Microsoft Azure (preferable Synapse Analytics).\n",
      "1058 Azure Development and DevOps processes\n",
      "1059 Implement and monitor Azure infrastructure (Storage accounts, VMs, VNets, Ads, etc)\n",
      "1060 Manage workloads in Azure\n",
      "1061 Role Based Access Controls for Azure resources\n",
      "1062 Implement and configure SQL pools, SQL Databases, and DB Schemas\n",
      "1063 Terraform scripting to deploy infrastructure as code (IaC)\n",
      "1064 Proven experience deploying and managing Azure Synapse environments.\n",
      "1065 3+ years of relevant work experience in data science, business analytics, business intelligence (BI), or comparable experience in big data environments.3+ years of experience in data mining and data-set preparation using SQL.\n",
      "1066 3+ years of experience with Tableau Desktop or other relevant data visualization software.\n",
      "1067 Proficient with Python or other relevant scripting language\n",
      "1068 He/she is an expert with data modeling, ETL design and business intelligence tools, has hand-on knowledge on columnar databases such as Redshift and other related AWS technologies\n",
      "1069 Familiarity with Amazon's AWS services including Glue, EC2, S3 and Redshift.\n",
      "1070 You have strong command of Python, SQL and can write production ready codes\n",
      "1071 You have experience with visualization tools like Matplotlib, Seaborn, Plotly, Tableau\n",
      "1072 working with DataFrames in Python;\n",
      "1073 writing complex SQL queries;\n",
      "1074 Big Data technologies — Spark, Cloud AI platforms, containerization (desired);\n",
      "1075 data visualization tools — Tableau, Plotly, etc\n",
      "1076 3+ years of experience with data scripting languages (e.g SQL, Python, R etc.) or statistical/mathematical software (e.g\n",
      "1077 R, SAS, or Matlab)\n",
      "1078 Utilize code (python or another object oriented language) for data analyzing and modeling algorithms.\n",
      "1079 iOS swift, iOS objective C\n",
      "1080 Buck/Bazel\n",
      "1081 Cross-platform (iOS and Android)\n",
      "1082 You will work with product managers, customers, and your team to deliver AWS Solutions, software assets and build an open-source community that drives AI/ML innovation on AWS.\n",
      "1083 Participate in deep architectural discussions to ensure solutions are designed for successful deployment in the AWS cloud.\n",
      "1084 Applies and generates best practices in multiple technical domains using AWS and third-party technology products and services.\n",
      "1085 Build deep relationships with senior technical individuals within AWS.\n",
      "1086 Participate in deep architectural discussions to ensure solutions are designed for successful deployment in the AWS cloud.\n",
      "1087 Applies and generates best practices in multiple technical domains using AWS and third-party technology products and services.\n",
      "1088 Build deep relationships with senior technical individuals within AWS.\n",
      "1089 Experience with AWS management, governance, security, and serverless services\n",
      "1090 Mastery of the tools of the trade, including familiarity with modern programming languages (Java, JavaScript, C/C++, Python) and open-source technologies\n",
      "1091 We use Typescript front to back using NextJS/React and NodeJS\n",
      "1092 You have great experience with automation tools, infrastructure-as-code (Terraform, GitHub actions, etc).\n",
      "1093 Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design\n",
      "1094 Proficiency in at least one modern programming language such as C++, C#, Java, or Perl\n",
      "1095 Familiarity with Linux\n",
      "1096 Experience with Relational and No SQL Databases\n",
      "1097 Experience with Spring, MVC frameworks, REST/RPC API design and development\n",
      "1098 ReactJS\n",
      "1099 Python\n",
      "1100 Proficiency with front-end languages such as HTML, CSS, and JavaScript\n",
      "1101 Familiarity with multiple JavaScript frameworks such as Vue, Angular, and React\n",
      "1102 Proficiency with server-side languages such as Python, Java, and PHP\n",
      "1103 PostgreSQL, MongoDB), web servers (e.g\n",
      "1104 Apache) and UI/UX design\n",
      "1105 Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design\n",
      "1106 Familiarity with the syntax and basic concepts of programming languages such as Java, C/C++ or Python\n",
      "1107 Java, Guice\n",
      "1108 Ruby on Rails, Ember\n",
      "1109 AWS Suite, including S3, Lambda, EC2, Sagemaker, and DynamoDB\n",
      "1110 MySQL, jOOQ\n",
      "1111 The incumbent will also work on programming and integration assignments utilizing PC based Server Systems and data related applications while delivering the Eclipse Vision and the Eclipse Entrepreneurial Culture.\n",
      "1112 Design and develop software programs (PC based) specific to customer and project requirements based on standard Eclipse programming methods\n",
      "1113 IIoT, PC based HMI\n",
      "1114 Strong understanding of the public cloud platform competitive landscape, including AWS, Azure, Google Cloud Platform and the Data & AI services and capabilities of each\n",
      "1115 Leverage data analyses, modeling, and visualization tools such as R and/or Python, Oracle SQL, BigQuery, MySQL, Tableau, and others\n",
      "1116 Experience in Python and/or R along with their associated ML/AI Libraries.\n",
      "1117 BigQuery/GCP, Tableau, and Excel experience are nice to have.\n",
      "1118 Popular Cloud Platforms (e.g., AWS, Azure, GCP)\n",
      "1119 A minimum of 3 years of working as a Data Governance consultant or directly with clients leveraging popular tools like Informatica, Collibra, IBM, ASG etc.\n",
      "1120 We make extensive use of AWS, Docker, and Kubernetes to ensure our system continues to scale with the addition of millions of users.\n",
      "1121 Deploy, test, monitor and improve microservices in a Kubernetes cluster to enable a culture of continuous deployment\n",
      "1122 Experience with message-passing systems such as RabbitMQ\n",
      "1123 Experience with Cloud services such as AWS, Google Cloud or Azure\n",
      "1124 Knowledgeable in using and developing with Docker containers, including orchestrating them (preferably using K8s)\n",
      "1125 Proven track record of collaborative development with git\n",
      "1126 Expert knowledge of one or more of the popular systems development languages such as Go, JavaScript, C/C++, etc.\n",
      "1127 Knowledgeable about both SQL and NoSQL databases such as PostgreSQL and MongoDB\n",
      "1128 Advanced knowledge of object-oriented JavaScript; HTML & HTML5, CSS3 (SASS) and Typescript\n",
      "1129 Experienced developing single page applications (SPAs) with at least one of React, Ember, Angular 2+, or Vue.js\n",
      "1130 Worked with state management patterns such as Redux, Flux, Vuex, etc.\n",
      "1131 Experience with managing a team programming in Go\n",
      "1132 Experience with Kubernetes clusters and ecosystem\n",
      "1133 Help business applications globally maintain technology currency on their Windows and Unix computing platforms (perform server patching, operating system upgrades, server hardware renewals, etc.) with keen eye on automation opportunities to improve efficiency and reduce human error\n",
      "1134 Experience in a variety of SRE-based tools (Ansible, Dynatrace, Moog, PagerDuty, ServiceNow, Elastic, Logstash, Kibana)\n",
      "1135 Experience with data visualization tools such as Grafana, Kibana or Tableau.\n",
      "1136 Proficiency in Microsoft Office.\n",
      "1137 Basic scripting/programming skills in any of the following: J-script, Python, C#, VB, C++\n",
      "1138 Experience with data modeling, data warehousing, and building ETL pipelines and SQL\n",
      "1139 Manage AWS resources including EC2, RDS, Redshift, Kinesis, EMR, Lambda etc.\n",
      "1140 Experience in design and optimization of data-processing systems using AWS services (S3, EMR, Lambda, Glue, Athena, SNS, Cloud Watch, Redshift, Aurora/RDS)\n",
      "1141 Experience with Java and experience with scripting languages like Perl, Python, Unix shell scripts, VBA and MS Excel\n",
      "1142 Working experience with TM1Py, REST API\n",
      "1143 Proficiency with Microsoft Project, Visio, and SharePoint\n",
      "1144 Knowledge of machine learning frameworks (TensorFlow, PyTorch, etc) is a plus\n",
      "1145 Knowledge of CUDA, OpenCL, SYCL, LLVM is a plus.\n",
      "1146 Computer knowledge, MS-Office (Excel, Word, PowerPoint, Outlook), Computer Aided Design software, ERP environment, preferably SAP\n",
      "1147 Experts dans une ou plusieurs de ces technologies ou domaines : Kubernetes, Istio, passerelles d'API, HANA Cloud, MongoDB, Kafka, ElasticSearch.\n",
      "1148 Expérience approfondie dans l'utilisation professionnelle de services gérés ou d'un fournisseur de services Cloud comme AWS ou Azure\n",
      "1149 : Chef, Puppet, Ansible, Jenkins, Rundeck) et de l'écriture de scripts (ex\n",
      "1150 : Python, Shell)\n",
      "1151 Bonne compréhension des systèmes de gestion de base de données relationnelle (SGBDR), tels que SAP HANA et MSSQL et MySQL, en particulier dans le domaine de l'optimisation des performances\n",
      "1152 Solutions Cloud publiques AWS, Azure, GCP, AliCloud\n",
      "1153 Compréhension de l'optimisation, du réglage et du débogage de la machine virtuelle Java (JVM)\n",
      "1154 Optimisation des performances des applications et outils APM tels que Dynatrace\n",
      "1155 Optimisation des performances des bases de données pour SAP HANA et/ou Microsoft SQL Server\n",
      "1156 Hands-on experience and highly advanced knowledge of SQL, Data Modeling, ETL Development, and Data Warehousing.\n",
      "1157 Solid experience using big data technologies (Redshift, Hadoop, Hive, Hbase, Spark, EMR, etc.).\n",
      "1158 Although SQL is a strong requirement, being flexible enough to work in a scripting environment is a must\n",
      "1159 Experience working with AWS big data technologies (Redshift, S3, EMR, Glue).\n",
      "1160 Languages include: Java, C and C++\n",
      "1161 Experience in the software development and analysis of simulations (knowledge of simulation environments and tools like MATLAB would be an asset)\n",
      "1162 Strong programming skills in Python and knowledge of Bash / Linux command line\n",
      "1163 Experience with industry tools used to build scalable machine learning systems, such as SQL, NoSQL, Elastic Search, and/or Spark\n",
      "1164 Airflow)\n",
      "1165 DevOps experience, and knowledge of common industry tools like Git, Kubernetes and Jenkins\n",
      "1166 Ability to write robust code in C/C++, Python\n",
      "1167 1+ programming experience in Python (or R) with good grasp of software engineering standard methodologies such as code-reusability, modularity, use of repos, etc.\n",
      "1168 Proficiency with SQL (any flavor of SQL)\n",
      "1169 Kubeflow, MLflow is a bonus.\n",
      "1170 Hadoop) and AWS is an asset.\n",
      "1171 A high level of comfort using Git\n",
      "1172 Experience with Python, C++ and good programming practice\n",
      "1173 Experience using Linux, shell scripting, and ROS\n",
      "1174 Cloud Experience: you have deep experience deploying apps and services to the cloud (AWS or otherwise), and maintaining and evolving them.\n",
      "1175 Modern backend expertise: You've built backend services and systems with languages like Python, Rust, or Go, and you understand the complexities and nuances of CRUD, Graph API, and microservices.\n",
      "1176 Working knowledge in one or more of: Java, C#, C, C++, JQuery, Javascript.\n",
      "1177 Strong knowledge of QA methodology and tools such as Selenium and TestNG.\n",
      "1178 Deep knowledge of at least one modern programming language (Java and/or Python preferred)\n",
      "1179 Experience with data processing technologies such as Kafka/Kinesis, Spark, Storm\n",
      "1180 Experience with Django, or similar server framework, or with Java microservice frameworks like Spring Boot or Quarkus\n",
      "1181 Knowledge of multi-tier architectures across multiple technology stacks .net, Java, J2EE, web servers, caching, application servers, RDBMS/NoSQL: Postgres, Dynamo DB\n",
      "1182 Experience designing and deploying dynamically scalable, highly available, fault tolerant and reliable cloud applications (AWS preferred)\n",
      "1183 Experience with Cordova, Android, iOS development\n",
      "1184 Technologies We Use: Python, Java, Javascript, Typescript, Fast.io, Quarkus, Vue, React Native, Kotlin, Redis, Postgres, Kubernetes, Docker, Jenkins, AWS, GCP, Azure\n",
      "1185 Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design\n",
      "1186 Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design\n",
      "1187 Experience with Big Data technologies such as AWS, Hadoop, Spark, Pig, Hive, Lucene/SOLR or Storm/Samza\n",
      "1188 Strong proficiency with Java, Python, Scala\n",
      "1189 Have software engineering experience with proficiency in Python based development\n",
      "1190 Have detailed experience of Agile software development methodologies using tools such as GIT, Jira, and Confluence\n",
      "1191 Demonstrate experience with UNIX/Linux operating systems and cloud hosting such as AWS, Kubernetes, EKS, containers and microservices\n",
      "1192 Python: 5 years (preferred)\n",
      "1193 GIT, Jira, and Confluence: 5 years (preferred)\n",
      "1194 UNIX/Linux: 5 years (preferred)\n",
      "1195 AWS, Kubernetes, EKS, containers and microservices: 5 years (preferred)\n",
      "1196 5+ years of server-side programming experience in Java\n",
      "1197 2+ years of hands-on professional Machine Learning and Python experience\n",
      "1198 Experience with AWS (S3, Elastic Beanstalk, EKS, Sagemaker, ELK, etc) or similar cloud services\n",
      "1199 Hands-on experience with open source technologies such as: Spring, MySQL, Hibernate, Solr, Maven, Git, Jenkins, Mockito, Tomcat, Linux, Vagrant, Docker, Kubernetes\n",
      "1200 Hands-on experience with one or more ML frameworks such as Tensorflow, MXNet, Scikit-Learn\n",
      "1201 We have opportunities for developing code on macOS and Windows platforms\n",
      "1202 Experience writing software using Swift, Objective-C, C++ or similar\n",
      "1203 Scripting using Python\n",
      "1204 Experience in Unix/Linux environments with a good understanding of operating systems internals\n",
      "1205 Experience with state configuration tools (Ansible, Puppet, Chef, etc.)\n",
      "1206 Proficiency with any infrastructure automation tool (Terraform, CloudFormation, Serverless, CDK)\n",
      "1207 Experience with distributed logging and monitoring( ELK, DataDog, SumoLogic, CloudWatch, Prometheus)\n",
      "1208 Practical knowledge of caching technologies (Redis, Varnish) with the ability to identify opportunities for improvement.\n",
      "1209 Experience with RDBMS (MySql, Postgres) and NoSQL (DynamoDB, MongoDB)\n",
      "1210 Ability to use container based environments and tools such as Kubernetes, Docker, Helm\n",
      "1211 Amazon EKS, ECS experience is an asset\n",
      "1212 Java, Kotlin\n",
      "1213 MySQL, Dynamo, ElasticSearch\n",
      "1214 gRPC and Protocol Buffers\n",
      "1215 Amazon Web Services (AWS)\n",
      "1216 DataDog, Prometheus, SignalFx\n",
      "1217 Experience with git version control, docker, agile methodology, MS 365, and other common software tools\n",
      "1218 Python including data processing modules NumPy, Pandas, SciPy\n",
      "1219 Python Machine Learning modules such as Keras, TensorFlow, PyTorch\n",
      "1220 SQL (MySQL and Postgres)\n",
      "1221 TimeSeries database (InfluxDB)\n",
      "1222 Cloud computing specifically AWS (VPC, S3, Aurora, RDS, EC2, Step Functions, Lambda, SageMaker)\n",
      "1223 APIs: REST, GraphQL\n",
      "1224 Development tools: PyCharm, Docker, GIT, Jira, Confluence\n",
      "1225 Programming skills using SQL & Python\n",
      "1226 Hands-on experience and expertise with different AI/ML frameworks such as Keras, Pytorch, Tensor Flow, Scikit-Learn\n",
      "1227 Experience with Dataiku, Snowflake, Tableau, Microstrategy is considered an asset\n",
      "1228 Oracle Marketing Cloud\n",
      "1229 Extensive experience in Automation Frameworks like Cucumber, testNG, Junit\n",
      "1230 Experience with build management tools Jenkins, Maven, Ant and continuous integration of automation suites\n",
      "1231 Familiarity and/or Expertise with tools like Jmeter, OEM (Oracle Enterprise Manager), CURL, PostMan, Oracle SQL Developer, JIRA, Zephyr, Selenium\n",
      "1232 Some experience with JavaScript and/or Typescript\n",
      "1233 Familiarity with testing cloud/SaaS solutions using microservices and Docker with Kubernetes\n",
      "1234 Experience in a Linux based environment gained through university subjects or work experience\n",
      "1235 Linux knowledge including the installation, troubleshooting and basic configuration of recent Ubuntu Desktop releases\n",
      "1236 Basic desktop Linux usage (desktop tools for editing files, browsing the Web, managing Internet connectivity, setup of printers/services/packages/external storage devices/etc\n",
      "1237 Understanding of Gmail, Google Calendar, Google Applications and Single Sign-On.\n",
      "1238 Some knowledge of programming (bash, Perl, Ruby, Javascript, C or C++, Go)\n",
      "1239 Basic troubleshooting of Mac and Windows operating systems.\n",
      "1240 Experience supporting virtualized environments (KVM, OpenStack, Virtual Box, VMWare)\n",
      "1241 Experience with containers (LXD/LXC, Docker, Kubernetes)\n",
      "1242 · Excellent Microsoft Office, including Excel, Word, and Outlook skills.\n",
      "1243 3 year experience in Python and SQL\n",
      "1244 Familiar with AWS machine learning technologies such as SageMaker.\n",
      "1245 Strong program skills in C/C++, Java\n",
      "1246 Javascript, Ember, Sass, and other web-app frameworks\n",
      "1247 Java\n",
      "1248 Ruby on Rails\n",
      "1249 MySQL\n",
      "1250 Computer knowledge, MS-Office (Excel, Word, PowerPoint, Outlook), ERP environment, preferably SAP\n",
      "1251 Demonstrated strong programming skills in C++/C and Python.\n",
      "1252 5+ Experience in Azure / AWS / GCP in implementations and maintaining solutions\n",
      "1253 5+ experience in the infrastructure as code development in Terraform.\n",
      "1254 3+ years Kubernetes experience with GKE, EKS, AKS, clusters.\n",
      "1255 Design and implementation of Continuous Delivery and/or DevOps solutions / pipelines or architecture patterns using tools like CircleCI, GitLab, Jenkins, Teamcity.\n",
      "1256 Experience with code repository management, code merge and quality checks, continuous integration, and automated deployment & management using tools like Jenkins, SVN, Git, Ansible, Artifactory, Service Now, Sonar, Selenium.\n",
      "1257 Design of alerts, metrics, log aggregation in tools like Datadog, Cloudwatch, ELK, or AppDynamics.\n",
      "1258 At least 3 years' experience in using one or more of the following languages: Perl, Ruby, Bash, or Python.\n",
      "1259 Database Administration Experience, relational and NoSQL.\n",
      "1260 Hands on development with JavaScript frameworks\n",
      "1261 Expert knowledge of JavaScript (ES6+)\n",
      "1262 Comfortable working with React\n",
      "1263 Experience with cloud platforms such as Amazon Web Services or Microsoft Azure\n",
      "1264 3+ years designing and developing in Simulink modeling, and embedded C programming\n",
      "1265 Development knowledge in another language (C++ preferred/Python)\n",
      "1266 Machine Learning, HUE, Jupyter, PowerBI, Hadoop/SQL/NoSQL)\n",
      "1267 Experience with Azure Data Factory, IoT Hub, Functions, Databricks, Synapse, Spark\n",
      "1268 Experience with AWS Lambda and Amazon Redshift\n",
      "1269 JavaScript, Python)\n",
      "1270 Message oriented architectures, AMQP, RabbitMQ, and Kafka are a plus\n",
      "1271 3-5 years Splunk Search Language, Python, Curl, or similar.\n",
      "1272 Knowledge of automation-related activities using scripting languages like Python, Perl, Ruby and Bash\n",
      "1273 Hands-on experience with enterprise tools like AppDynamics, Grafana, Splunk, Dynatrace\n",
      "1274 CloudFormation, CodeCommit, CodeBuild, CodeDeploy, CodePipeline or Azure DevOps.\n",
      "1275 Strong software development background preferably in Python or Java\n",
      "1276 4+ years of SQL experience (No-SQL experience is a plus)\n",
      "1277 Strong background in Microsoft Azure, particularly Azure data analytics offerings like Azure Data Factory, Azure Managed SQL, Azure Databricks, Azure Blob storage\n",
      "1278 Experience developing analytics driven solutions in Microsoft PowerBI\n",
      "1279 Past experience with Apache Airflow or similar workflow management system\n",
      "1280 Past experience with the Informatica platform\n",
      "1281 Exposure to Yandex Clickhouse or other column-oriented databases\n",
      "1282 Microsoft Azure Java Python Leadership\n",
      "1283 Solid knowledge of C/C++ and C# programming using Microsoft Visual Studio\n",
      "1284 4+ years’ experience in SQL/Spark, R, Python\n",
      "1285 Experience with modern TypeScript/JavaScript application development\n",
      "1286 Experience with HTML5, CSS, web frameworks (React, Vue, Angular, Node, Web Components)\n",
      "1287 Experience developing scalable and performant solutions with AWS\n",
      "1288 Responsible for embedded Linux software architecture and implementation.\n",
      "1289 Developing C/C++ software according to the company SDLC process.\n",
      "1290 10 + years of experience in developing real-time embedded and/or application software on Linux based platform.\n",
      "1291 In-depth knowledge of Ethernet switching, routing and application level protocols (L2/L3 protocols) – RSTP, LLDP, STP, IGMP, VRRP, RIP, OSPF, TCP/IP, HTTP, NAT, IGMP, QoS, VLAN, VPN etc.\n",
      "1292 Experience with UNIX/POSIX programming interface.\n",
      "1293 Experience developing any of the following is a plus: Firewall, VPN, IDS/IPS, SDN.\n",
      "1294 Experience with embedded Linux, Hypervisor, Deep Packet Inspection, DPDK is plus\n",
      "1295 Knowledge of SCADA communications protocols like DNP, Modbus etc\n",
      "1296 The successful candidate will have at least 3 years experience building complex applications using .NET technologies and will have experience with frameworks like Angular or React.\n",
      "1297 Experience working in an Agile/Scrum environment, along with Confluence, JIRA, Bitbucket, and Git or equivalents.\n",
      "1298 Experience in modern JavaScript front end frameworks such as Angular and React.\n",
      "1299 C# development experience.\n",
      "1300 Knowledge of SQL Server, Database structures and design.\n",
      "1301 The open-source platform is currently developed using Python/Django and deployed in the cloud\n",
      "1302 Building the data sharing and analysis application using Python/Django\n",
      "1303 Integrate the application with external apps using OAuth2\n",
      "1304 Experience using cloud provider services (e.g., AWS, MS Azure, GCP)\n",
      "1305 Advanced proficiency with MS Office Suite\n",
      "1306 Strong proficiency using Python; proficiency using Django or other Python web frameworks\n",
      "1307 Strong proficiency using SQL, relational databases (Postgres) and object relational mapping (ORM)\n",
      "1308 Proficiency using HTML, CSS, and Javascript\n",
      "1309 Proficiency using Linux\n",
      "1310 Proficiency using Git and GitHub\n",
      "1311 Experience using Docker\n",
      "1312 Experience integrating with other applications using OAuth2\n",
      "1313 Experiencing deploying Python web applications\n",
      "1314 Find, isolate, document, and track defects (in JIRA) through resolution.\n",
      "1315 Experience with defining quality strategy and testing Data-Intensive projects which utilize technologies such as MySQL/Postgres, Redshift, DynamoDB, GraphQL, and ElasticSearch\n",
      "1316 Familiarity with SQL database concepts and ability to analyze and write queries\n",
      "1317 Experience with agile development processes such as Lean/Scrum/Kanban\n",
      "1318 Experience with Performance testing tools such as Locust\n",
      "1319 Working knowledge of Python, Java, or other development experience\n",
      "1320 Experience with AWS Services such as S3, Step Functions, ECS, ECR\n",
      "1321 Familiarity with using frameworks for machine learning and data science like Scikit-learn, Keras, Pandas, NumPy, XGBoost, TensorFlow, PyTorch\n",
      "1322 Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design\n",
      "1323 Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design\n",
      "1324 Experience with AWS and data-oriented tools such as ElasticSearch, Spark, ElastiCache, and DynamoDB\n",
      "1325 You will develop custom code in Jenkins, Groovy, Python and Powershell to automate build and automate testing for the platform.\n",
      "1326 You will develop code using our agile JIRA tools to manage a backlog of enhancements and bug-fixes, managing source code in Stash and binaries in Nexus\n",
      "1327 You will also develop automated integration tests to run on our Jenkins CI (continuous integration) platform for test automation to help support bug free releases.\n",
      "1328 Strong programming skills with experience in API and Webhook development using Python, Ruby, PowerShell and Shell Scripting languages\n",
      "1329 Experience with automating and integrating serverless PaaS solutions such as Azure App Service, Azure Databricks, Azure Data Lake, Azure Machine Learning,\n",
      "1330 Write and use Azure RM templates and Terraform\n",
      "1331 Understand Azure security features (data protection, authentication, RBAC, etc)\n",
      "1332 Understanding of Public Key Infrastructure (PKI), handling public key and private key certificates in Azure environment for Paas services and applications\n",
      "1333 Strong network skills, with the ability to troubleshoot Azure, DNS, Azure connectivity, NSG, routing\n",
      "1334 Proficiency in cloud automation using native Azure CLI\n",
      "1335 1- 3 years of experience developing platform orchestration code in Azure Python SDK, Terraform and GitHub Runners\n",
      "1336 Experience in Azure RBAC and integration with Active Directory and PingFed\n",
      "1337 Strong Automation experience using Java\n",
      "1338 Understanding of Microsoft technologies like O365, Exchange server-mail delivery.\n",
      "1339 Experience working on Jenkins\n",
      "1340 Linux / Unix experience\n",
      "1341 Experience with other scripting like python, Shell scripting, groovy etc.\n",
      "1342 Linux / Unix experience\n",
      "1343 Experience with other scripting like python, Shell scripting, groovy etc.\n",
      "1344 Familiarity with end-to-end email delivery (IP addresses, DNS, SMTP, authentication, Spam, Quarantine etc.)\n",
      "1345 Practical coding experience in Verilog, Python, or C/C++, demonstrated in research projects or prior work experience.\n",
      "1346 Familiarity with at least one of these areas: digital logic design; data structures and algorithms; linear algebra; processor architecture; compiler tools (e.g., LLVM).\n",
      "1347 3+ years of programming experience with at least one modern language such as Java, C++, or C# including object-oriented design\n",
      "1348 You are a software engineer with experience in WPF and .Net core and C#\n",
      "1349 5+ years’ experience in software development with C#/.NET (Must Have)\n",
      "1350 Experience with SQL query language and database design.\n",
      "1351 Knowledge of source controls and automation in Git repositories, CI/CD and Jira issue tracking, Azure DevOps.\n",
      "1352 Experience of using Microsoft Azure Services\n",
      "1353 Significant experience writing quality code in Python, PyTorch\n",
      "1354 Bonus points for experience with MLOps and Kubernetes\n",
      "1355 You have extensive experience with .NET and web services.\n",
      "1356 Use .NET and SQL Server technologies to shore up existing royalties processes\n",
      "1357 Update existing systems and participate in design and implementation of a new service-based distributed royalties system, using a blend of .NET and AWS technologies.\n",
      "1358 Analyze existing SQL-based systems to infer rules and manage migrations\n",
      "1359 5+ years demonstrated ability with C#\n",
      "1360 2+ years of experience with Git\n",
      "1361 Skilled in SQL Server development with T-SQL\n",
      "1362 Some experience working in an environment that is cloud-based (such as AWS or Azure) or at least container-centric (such as Docker or Kubernetes)\n",
      "1363 Experience with Amazon Web Services\n",
      "1364 Experience with messaging services such as RabbitMQ, ActiveMQ, or Kafka\n",
      "1365 Experience with PostgreSQL and/or NoSQL databases like MongoDB or DynamoDB\n",
      "1366 Experience on automation framework and tools like Selenium\n",
      "1367 Knowledge of bug tracking tools such as Jira\n",
      "1368 Solid testing experience with SQL and database technologies (e.g., SQL Server, PostgreSQL, Oracle, etc.)\n",
      "1369 Experience in Hadoop, Cassandra, Kafka, RabbitMQ, Spark is a plus\n",
      "1370 Experience with Gitlab, Jenkins, Teamcity or similar systems\n",
      "1371 Experience testing software in Unix, Linux, and Windows systems\n",
      "1372 Experience working with Docker, Kubernetes and Helm\n",
      "1373 Ability to write, analyze, and debug SQL queries (MS SQL, Sybase, PostgreSQL).\n",
      "1374 Working knowledge of Python, and ability to design and work with Hadoop, Hive, Sqoop, and/or Apache Spark.\n",
      "1375 Working knowledge of DevOps, DataOps, and Git.\n",
      "1376 Working knowledge of cloud platforms, Microsoft Azure or similar cloud-hosted databases such as AWS Redshift, Snowflake.\n",
      "1377 Working knowledge of Tableau, PowerBI or similar BI tools.\n",
      "1378 Strong C/C++ or Java/Python programming skills a must\n",
      "1379 Azure Data Lake, Databricks, Snowflake)\n",
      "1380 Excellent proficiency with SQL programming to write complex queries\n",
      "1381 Experience with scripting, programming in Python, C# would be an asset\n",
      "1382 Experience working with stream processing solutions such as Spark is an asset\n",
      "1383 Experience with macOS or iOS development using Objective-C/Swift\n",
      "1384 Python, Bash\n",
      "1385 Jenkins, JIRA, Git\n",
      "1386 Experience with Unix/Linux command line\n",
      "1387 Experience deploying and maintaining cloud applications using AWS\n",
      "1388 Experience using Linux, Unix and macOS\n",
      "1389 Experience with Infrastructure automation tools (Terraform and/or CloudFormation), CI/CD, docker container implementation.\n",
      "1390 Experience using PostgreSQL, or another relational database\n",
      "1391 Experience using AWS S3, Redshift, Glue and Athena, or other serverless data engineering platforms.\n",
      "1392 Experience with monitoring tools (Datadog)\n",
      "1393 Excels when working with a small team using a lightweight agile process.\n",
      "1394 Understanding of modern data engineering and analytics including platforms such as Snowflake, Apache Airflow, Lambdas, SQS, and ETL tools and best practices.\n",
      "1395 Familiar w/ mobile application development on iOS and Android and React.js\n",
      "1396 Familiar w/ API development using GraphQL or REST\n",
      "1397 Experience with GitHub/GitHub Actions\n",
      "1398 Linux Device Driver Developer (Machine Learning)\n",
      "1399 The successful candidate will utilize their knowledge of machine learning and Linux device driver development to be a key contributor to the ongoing development of AMD drivers and future hardware\n",
      "1400 Linux GPU driver development in support of Machine Learning and Data Centre applications\n",
      "1401 Proficient in C and C++ programming\n",
      "1402 Strong general Linux systems administration, software development, and troubleshooting knowledge and experience.\n",
      "1403 Linux kernel development experience, either core kernel development or device driver development.\n",
      "1404 Experience with Linux containers kernel level implementation (cgroups, namespaces)\n",
      "1405 Familiarity with Linux networking and network/cluster management\n",
      "1406 Familiarity with Linux GPU driver development (kernel and user-mode), ideally on AMD hardware.\n",
      "1407 Familiarity with compute, graphics, or multimedia GPU application development using APIs such as OpenCL, OpenGL, and VAAPI.\n",
      "1408 Familiarity with Linux security subsystems such as selinux and/or AppArmor\n",
      "1409 Experience with modern Deep Learning software architectures and frameworks including Tensorflow, PyTorch or other Deep Learning Frameworks.\n",
      "1410 Programming experience with data science languages like Python, and/or HPC languages such as C/C++/Fortran.\n",
      "1411 CUDA/GPU optimization experience.\n",
      "1412 Experience with parallel deep learning frameworks, e.g., Horovod.\n",
      "1413 Experience with programming languages (SQL, R, etc.), reporting and data exploration tools such as Tableau, Power BI, or Excel for use in analytics and insights, and data technologies such as Postgres, Google Cloud Platform, Azure, MS SQL Server/Analysis Services\n",
      "1414 Python, R), database languages, and computing environments/tools\n",
      "1415 github, jupyter notebooks)\n",
      "1416 AWS, Apache Spark, Databricks)\n",
      "1417 Implement CI/CD pipelines using Azure DevOps with a focus on testing, code quality, and security.\n",
      "1418 Experience with containerization (Kubernetes, Docker).\n",
      "1419 Mastery of Python/Flask, relational databases (Azure Cosmos DB), blob storage, OIDC/OAuth2, version control and collaborative development.\n",
      "1420 Familiarity with Apache Airflow or Spark is preferred.\n",
      "1421 Familiarity with Infrastructure-as-code (Terraform, Ansible, etc.) is preferred.\n",
      "1422 Strong software development skills (Python) with an emphasis on data infrastructure development.\n",
      "1423 Hands on experience with python, and SQL.\n",
      "1424 Experience working with remote Linux VMs.\n",
      "1425 Experience administering and monitoring remote cloud infrastructure such as: Amazon EC2 and Microsoft Azure.\n",
      "1426 Proficiency with front-end languages such as HTML, CSS, and JavaScript\n",
      "1427 Familiarity with multiple JavaScript frameworks such as Vue, Angular, and React\n",
      "1428 Proficiency with server-side languages such as Python, Java, and PHP\n",
      "1429 PostgreSQL, MongoDB), web servers (e.g\n",
      "1430 Apache) and UI/UX design\n",
      "1431 Experience with statically typed languages (ideally C# or Java)\n",
      "1432 Experience working with large sets of data in an RDBMS like SQL Server or Oracle DB\n",
      "1433 Experience with JavaScript and JavaScript UI frameworks\n",
      "1434 GitHub, Gitlab (or similar) profile with open-source contributions\n",
      "1435 As a part of the RET supporting Cisco Security products, you will provide security research, detection content development and support assistance to our Cisco Secure Endpoint for Linux\n",
      "1436 You will work towards keeping yourself abreast of the latest attack techniques on Linux\n",
      "1437 You will research detection and prevention strategies to maintain Cisco’s leadership in Linux security\n",
      "1438 You will also develop domain expertise in Linux security and provide guidance and help protect our customers from breaches and cyber-attacks\n",
      "1439 You have scripting skills with knowledge of Python, Bash and PowerShell.\n",
      "1440 You have software development skills in C, C++ or Go.\n",
      "1441 Used red-teaming tools such as Metasploit\n",
      "1442 You'll be responsible for providing end user support in these key locations including configuration of machines for new hires, supporting Mac, Windows and Linux users\n",
      "1443 Experience with Linux and Powershell is an asset\n",
      "1444 PXE / MDT (Microsoft Deployment Toolkit) / FOG\n",
      "1445 MacOS, Windows, and Ubuntu\n",
      "1446 VMware\n",
      "1447 Jira\n",
      "1448 Powershell or Python knowledge\n",
      "1449 Development of scripts or applications (XML, Java, Java Script, Perl) to simulate various management activities and network scenarios\n",
      "1450 Strong programming skills (Java, Java Script, Perl, XML)\n",
      "1451 UNIX operating environment (RHEL or Solaris), Windows, Virtual Machines\n",
      "1452 OSPF, IS-IS, BGP, RIP), and MPLS\n",
      "1453 Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design\n",
      "1454 Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design\n",
      "1455 Experience developing in Amazon Web Services – AWS\n",
      "1456 Explore different technologies and develop applications in languages that might include: Java, .NET, Python, JavaScript, and SQL, Web technologies like React, Redux, Angular, Vue, Mobile technologies including iOS and Android, Cloud technologies like AWS, Azure, Google Cloud, and Data Driven solutions, IoT, Machine Learning, DevOps, and more\n",
      "1457 Experience analyzing and manipulating large data sets using SQL, Hive or other querying tools.\n",
      "1458 Programming skills and knowledge of Python or R.\n",
      "1459 Familiarity with C and Python\n",
      "1460 Experience working with external independent assessors (TUV, Exida, etc)\n",
      "1461 Previous experience as an embedded software developer and/or knowledge of graphics and compute framework is a plus (OpenGL SC 1.0, OpenGL SC 2.0, Vulkan 1.2).\n",
      "1462 Experience with embedded operating systems (VxWorks, Integrity, Linux, DEOS, etc.)\n",
      "1463 A successful candidate has the experience needed to design and develop new data solutions, from data ingestion, modelling/storage, and serving to analytical applications on either the Microsoft Azure or AWS cloud stack\n",
      "1464 Design ETL/ELT processes and orchestration pipelines on modern cloud platforms (Azure, AWS, or GCP) leveraging native or third-party services via a fit-for-purpose approach\n",
      "1465 Prior demonstrated expertise in building end-to-end data solutions using cloud native platforms and services (Azure, AWS, or GCP) – Azure & AWS preferred\n",
      "1466 Experience in data ingestion and data processing of structured and non-structured data (e.g., Functions, Airflow, Python)\n",
      "1467 SQL, Python, ETL/ELT and analytics tool/language experience\n",
      "1468 Experience in building batch and near-time data ingestion solutions (e.g., Kafka, Kinesis, etc.)\n",
      "1469 Experience with popular ISV/third-party data solutions (e.g., Snowflake, Databricks, Talend, etc.)\n",
      "1470 Experience visualizing data using Excel, Tableau, Power BI, Looker, or similar tools.\n",
      "1471 At least a basic understanding of SQL with a desire to learn more.\n",
      "1472 Have experience with DBT, Python and Jupyter notebooks.\n",
      "1473 Design and optimize pipelines for model deployments in production environments using containers (Docker or Azure Kubernetes), Azure implement DevOps and/or MLOps and Azure Data Factory\n",
      "1474 Extensive programming experience in Python and/or R with knowledge of Object-Oriented Programming such as C#, Java or C++\n",
      "1475 Experience in Azure DevOps & Azure Cloud Services (e.g\n",
      "1476 Azure Blob, Azure Key Vault, Azure Data Factory) or similar experience with AWS or Google\n",
      "1477 Spark, Hadoop)\n",
      "1478 Docker containers on Kubernetes-based platforms with data orchestration in Azure Data Factory\n",
      "1479 Exposure to DevOps (Terraform, Github, Jenkins) and DevSecOps tools & Security Automation frameworks\n",
      "1480 Exposure on Microservices architecture and containerized technologies (Docker, Kuberentes, EKS)\n",
      "1481 Agile & Shift Left Methodologies, along with exposure to environments that actively used threat modelling methodologies in the SDLC\n",
      "1482 Experience in building Security automation integration to JIRA and Service now\n",
      "1483 Scripting - Python, Bash\n",
      "1484 Experience in SQL\n",
      "1485 We are managing massive scale streaming systems, applying machine learning and data science expertise using Hadoop, Elastic MapReduce, and Spark to drive optimizations and insights while building front-ends in ReactJS to help internal and external advertisers to deeply understand their customers and markets.\n",
      "1486 You must be comfortable and confident working on Linux systems\n",
      "1487 Experience working with AWS big data technologies (EMR, Redshift, S3)\n",
      "1488 Proficiency in R and/or Python\n",
      "1489 You have at least 2+ years of hands-on technical working experience with SQL Data Definition or Data Description Language (DDL); Data Manipulation Language (DML) scripting & creating SQL queries with any relational database.\n",
      "1490 You have at least 3+ years of hands-on technical experience working with UNIX scripting to automate & navigate.\n",
      "1491 You can demonstrate a strong technical understanding of RESTful Services, and the ability to read Java code to troubleshoot & debug.\n",
      "1492 Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design\n",
      "1493 2+ years of programming experience with at least one modern language such as Java, C++, Python, or C# including object-oriented design.\n",
      "1494 1+ years Experience building software for deployment to AWS\n",
      "1495 In depth knowledge of programming language (C, C++, C#, etc.) | Connaissance approfondie du langage de programmation (C, C++, C#, etc.)\n",
      "1496 Has working knowledge of Microsoft Word, PowerPoint & Excel\n",
      "1497 signal processing, algorithm design, and machine learning methods including proficiency with MATLAB or Python, OR\n",
      "1498 Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design\n",
      "1499 AWS Glue simplifies and automates the difficult and time consuming data discovery, conversion, mapping, and job scheduling tasks at massive scale\n",
      "1500 Fluency in C++ and Python\n",
      "1501 Experience developing embedded Linux firmware\n",
      "1502 Full understanding of Linux Kernel and toolchains\n",
      "1503 Has built and/or configured 3rd party Linux packages\n",
      "1504 Le centre d’excellence des solutions de gestion des ressources énergétiques distribuées (CoE DERMS) d’Eaton est à la recherche d’un(e) ingénieur(e) logiciel en chef pour faire partie de son équipe multidisciplinaire et mondiale afin de concevoir des solutions propres à l’intégrateur en langage C++ à partir des trousses de communication d’Eaton basées sur Linux, compatibles Ethernet et multi-protocoles\n",
      "1505 Maîtrise des langages C++ et Python\n",
      "1506 Expérience en conception de micrologiciels Linux embarqués\n",
      "1507 Compréhension complète de Linux Kernel et des chaînes d’outils associées\n",
      "1508 Expérience en création ou configuration de paquets Linux de tiers\n",
      "1509 Proven and demonstrable skills developing embedded systems using the C++ programming language in a Linux or RTOS environment.\n",
      "1510 Experience with version control software (Git), requirements management tools (JAMA), defect tracking tools (JIRA)\n",
      "1511 Experience with C++ and Boost Libraries such as ASIO and Unit Test.\n",
      "1512 Experience with Industrial control protocols, such as Modbus, CANbus etd.\n",
      "1513 Experience using cloud computing platforms (Azure) and services\n",
      "1514 Experience with IoT security implementation - Linux network device security, developing with secure network protocols, participating in, and performing security audits.\n",
      "1515 Compétences solides en développement de systèmes embarqués à l'aide du langage de programmation C++ dans un environnement Linux ou autre système d’exploitation temps-réel.\n",
      "1516 Expérience avec les logiciels de contrôle de version (Git), les outils de gestion des exigences (JAMA) et les outils de suivi des bugs (JIRA)\n",
      "1517 Expérience avec les bibliothèques Boost en C++ telles que ASIO et Unit Test\n",
      "1518 Expérience avec des protocoles IP industriels (Modbus, CANbus, etc.)\n",
      "1519 Expérience dans l'utilisation de plateformes et de services de calcul de l’infonuagique (Azure)\n",
      "1520 Expérience de la mise en œuvre de la sécurité IdO - Sécurité des périphériques réseau Linux, développement de protocoles réseaux sécurisés, participation et réalisation d'audits de sécurité.\n",
      "1521 Experience on automation framework and tools like Selenium\n",
      "1522 Knowledge of bug tracking tools such as Jira\n",
      "1523 Solid testing experience with SQL and database technologies (e.g., SQL Server, PostgreSQL, Oracle, etc.)\n",
      "1524 Experience in Hadoop, Cassandra, Kafka, RabbitMQ, Spark is a plus\n",
      "1525 Experience with Gitlab, Jenkins, Teamcity or similar systems\n",
      "1526 Experience testing software in Unix, Linux, and Windows systems\n",
      "1527 Experience working with Docker, Kubernetes and Helm\n",
      "1528 As a Senior Software Engineer you will contribute to the development, implementation and support of SAP’s Service Mesh technologies for Kubernetes as well as Virtual Machine based workloads\n",
      "1529 SAP Concur runs thousands of microservices deployed in industry strength Kubernetes clusters in AWS as well as other infrastructure\n",
      "1530 Excellent development skills in Go, Node.js/JavaScript, Java or C/C++ and scripting languages in BASH or Python\n",
      "1531 Common understanding about Kubernetes and container technology (as a developer as well as around container networking)\n",
      "1532 Having experience with Envoy proxy or Nginx or Istio would be a huge bonus\n",
      "1533 You will have the opportunity to learn the Tableau Analytics Platform offerings, the descriptive and predictive (AI/ML) use cases that best leverage them and the IT environments with which our platform integrates\n",
      "1534 Supports the sales team’s readiness in the use of Tableau products.\n",
      "1535 3+ years’ experience using Tableau Software (inclusive of both Tableau and Tableau CRM) or other business intelligence solutions.\n",
      "1536 Proficiency in technologies complimentary to Tableau software such as the following: Enterprise software architectures, Salesforce, cloud technologies (e.g., AWS, Azure, Google), ETL (e.g., Informatica, Alteryx), SQL or MDX (e.g., MySQL, Snowflake, PostgresSQL, Oracle, SQL.\n",
      "1537 Experience in developing software using C/C++, and optionally Python, Perl\n",
      "1538 Experience working with commercial Linux-based products\n",
      "1539 Experience in Linux kernel development\n",
      "1540 Ideal candidates with 5+ years of experience in an Information Security domain with 2+ years of extensive work experience in AWS Security\n",
      "1541 Hands-on knowledge on DevOps methodologies and tools including CI/CD (Jenkins), IAC (Terraform, Ansible) and various monitoring/alerting tools (DataDog, CloudWatch, etc.)\n",
      "1542 Working experience and deep technical knowledge on Linux (CentOS, Amazon Linux) and Windows operating systems and AWS Cloud\n",
      "1543 Solid understanding of AWS Security Services - Security Hub, Guard duty, CloudTrail, Inspector, AWS Config, Trusted Advisor, KMS, Secrets Manager, Control Tower, etc.\n",
      "1544 Exposure to DevOps (Terraform, Github, Jenkins) and Security Automation frameworks\n",
      "1545 Exposure on Microservices architecture and containerized technologies (Docker, Kuberentes, EKS)\n",
      "1546 Agile & Shift Left Methodologies\n",
      "1547 Experience in building Security automation integration to JIRA and Service now\n",
      "1548 Proficient in AWS CLI and in at least one programming language such as Python, Golang, Bash\n",
      "1549 You will work on Tableau’s next-generation Visual Analytics and Collaboration suite\n",
      "1550 As a full stack developer you will be working on a Python and Java based backend platform with modern web technologies frontend\n",
      "1551 Build modern front-end consumer-friendly interfaces and their Java and Python backend services allowing people to answer complex questions about their data.\n",
      "1552 Solid development skills with Python and Java\n",
      "1553 Experience developing in web languages such as JavaScript, TypeScript, HTML/CSS\n",
      "1554 C++ skills are a plus.\n",
      "1555 Experience of working on Layer3 IP technologies (IPv4/IPv6, SNMP, IPSEC, VRRP, RIP, ISIS, OSPF, BGP, EIRGP, MPLS, PBR, ACL etc…).\n",
      "1556 Embedded U-boot and Linux knowledge an asset.\n",
      "1557 C programming skill an asset.\n",
      "1558 Experience in Automation Test Development (TCL/Perl/Python) an asset.\n",
      "1559 Java, Guice\n",
      "1560 Ruby on Rails\n",
      "1561 Javascript, Ember, React, Sass, and other web-app frameworks\n",
      "1562 MySQL\n",
      "1563 Hibernate, Guice, GRPC\n",
      "1564 The ideal candidate would have background in the following areas: machine learning, data mining, data preprocessing, data visualization, Python, statistical analysis, and model validation methods.\n",
      "1565 Experience with Python programming language and Python packages for data science\n",
      "1566 Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design\n",
      "1567 Experience with Big Data technologies such as AWS, Hadoop, Spark, Pig, Hive\n",
      "1568 Strong proficiency with Java, Python, Scala or C++\n",
      "1569 Experience with Big Data technologies such as AWS, Hadoop, Spark, Pig, Hive\n",
      "1570 Strong proficiency with Java, Python, Scala or C++\n",
      "1571 Write high quality code in Verilog, VHDL and C/ C++ code for embedded processors\n",
      "1572 Experience developing in VHDL or Verilog for FPGA.\n",
      "1573 Experience developing in embedded C/C++.\n",
      "1574 Experience working in Linux OS.\n",
      "1575 Familiarity with software version control systems like Git or SVN.\n",
      "1576 Basic knowledge of embedded processors such as ARM Cortex-M3 or RISC-V and familiarity with AMBA bus protocols such as APB, AHB, AXI, ACE and familiarity with commonly used peripherals such as SPI,12C, UART, Ethernet, PCle, HDMI and USB.\n",
      "1577 Experience in developing, working with Machine Learning/ Inference Engine for FPGAs.\n",
      "1578 Knowledge of OS, Firmware, SW stack, OpenGL, OpenCL, Java and/or Codec.\n",
      "1579 Experience with advanced SQL writing, building reporting, and statistical modeling.\n",
      "1580 Incorporate a variety of statistical and machine learning techniques on big data, using leading edge tools such as R (ggplot2) and Python (scikit-learn, tensor-flow), combined with IBM tools and AI application suites\n",
      "1581 Demonstrated programming proficiency and experience with at least one programming language, preferably Java or JavaScript\n",
      "1582 R, Python, Scala, SAS, SPSS, MATLAB)\n",
      "1583 AWS, Azure, Google Cloud, IBM Cloud) is an asset\n",
      "1584 Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design\n",
      "1585 Automate or create solutions to help resolve AWS customer issues as quickly as possible.\n",
      "1586 Kotlin, Go, Java\n",
      "1587 AWS, Docker, Kubernetes, Flux v2, Helm\n",
      "1588 gRPC, Envoy, Istio\n",
      "1589 SignalFx, DataDog, Prometheus\n",
      "1590 Experience with multiple cloud technologies (Azure is preferable).\n",
      "1591 Experience writing code (preferably node.js, python, and shell scripting).\n",
      "1592 Experience working with databases (Postgres, Mongo).\n",
      "1593 Docker & Kubernetes containerization experience.\n",
      "1594 Experience with Github actions is a bonus.\n",
      "1595 Use Azure Services (e.g., Synapse, Data Bricks), ML platforms, and frameworks (e.g., MXNet, TensorFlow, PyTorch, SparkML, scikit-learn) to help our customers build ML models\n",
      "1596 Experience writing code in Python, R, Scala, Java, C and creating documentation for reproducibility\n",
      "1597 Experience handling terabyte size datasets, diving into data to discover hidden patterns, using data visualization tools, writing SQL, and working with GPUs to develop models\n",
      "1598 unstructured logs, XML, JSON, flat files, image)\n",
      "1599 Python, R) and having practical experience with data science tools and libraries (eg\n",
      "1600 scikit-learn, Pandas, NumPy, Git etc.) is desirable.\n",
      "1601 You have experience with Big Data ecosystem tools (e.g., Hive, Pig, Sqoop, Spark, Google Cloud Platform) and are comfortable with creating large queries\n",
      "1602 You have experience using visualization tools like Power BI, Tableau or QlikView\n",
      "1603 You have experience leveraging digital analytics tools such as Adobe Analytics, Google Analytics or Splunk\n",
      "1604 At least 2 years of experience in the job offered or a related occupation must involve: designing and developing large-scale, distributed software applications, tools, systems and services using Java, Scala, Go, C#, or C++, and Object Oriented Design.\n",
      "1605 In this role you will contribute to a critical and highly-visible function within the AWS business\n",
      "1606 4+ years of experience working with Python.\n",
      "1607 Familiarity with open source software, especially the Python ecosystem.\n",
      "1608 Proficiency with Linux, Docker, and networking.\n",
      "1609 Experience with ROS, SCADA (e.g\n",
      "1610 EPICS, TANGO), or RPC frameworks (e.g\n",
      "1611 Working knowledge of lower-level programming languages such as C, C++, and/or hardware description languages such as Verilog.\n",
      "1612 Works in SQL, Python, R, scikit-learn, Google Cloud BigQuery, Java and C++ and are always prototyping new technologies\n",
      "1613 Experience using Python, SQL, databases, and visualization tools\n",
      "1614 Familiarity with GCP, AWS, Azure, Docker, or Kubernetes\n",
      "1615 Experience with Big Data technologies (such as Spark), and unstructured data\n",
      "1616 Build and manage microservices on AWS\n",
      "1617 Use Python to automate data processes and analyses to maximize efficiency\n",
      "1618 Perform spatial analyses with SQL\n",
      "1619 Web scraping unstructured data with Python\n",
      "1620 Knowledge and experience with Python (5+ years), SQL (5+ years), Docker, Terraform\n",
      "1621 Experience with enterprise databases (MS SQL, MySQL or PostgreSQL)\n",
      "1622 Experience with source code control frameworks (Git).\n",
      "1623 Knowledge and experience using NoSQL databases such as MongoDB or DynamoDB\n",
      "1624 Experience with administrating and working with enterprise database technologies such as Amazon Redshift\n",
      "1625 Experience with GIS Products (QGIS, ArcGIS Enterprise, ArcGIS Pro)\n",
      "1626 Knowledge and experience with ETL software such as FME Desktop and FME Server\n",
      "1627 Write performant Java and Database code to progress the project goals and initiatives.\n",
      "1628 5+ years Java development experience\n",
      "1629 2+ years SQL database experience\n",
      "1630 Experience with Cloud technologies (AWS, Azure, GCP)\n",
      "1631 Java application performance tuning techniques\n",
      "1632 Java application debugging (thread and heap analysis)\n",
      "1633 NoSQL database experience\n",
      "1634 Knowledge of AWS/No-/Go/Python/R/TensorFlow and CI-CD is a bonus.\n",
      "1635 JavaScript, CSS, Node.js)\n",
      "1636 Modern javascript\n",
      "1637 Proficient in programming (C++, C#) and scripting languages (Python, PowerShell, VB Script, Perl)\n",
      "1638 Experienced in .Net with development of Windows applications, Web services, Web-based applications/reports.\n",
      "1639 Programming device drivers under MS Windows OSs is an asset.\n",
      "1640 Knowledge of Relational databases and working experience with SQL is an asset.\n",
      "1641 Familiar with Linux distros and bash\n",
      "1642 Database Systems (SQL and NoSQL)\n",
      "1643 Apache Hadoop and Apache Spark (Python, Scala, Java, and R)\n",
      "1644 Databricks\n",
      "1645 Azure Cloud\n",
      "1646 Get an understanding of the iQ Data Platform (HVR, Databricks Bronze, Silver, and Gold Layers)\n",
      "1647 Identify costs concerns for the Databricks infrastructure\n",
      "1648 Computer programming experience, C++ and python, to install and interact with software based on manuals/documentations\n",
      "1649 Familiar with data streaming protocols, and APIs as well as bash/shell scripts on Linux OS\n",
      "1650 Demonstrable programming experience in Python\n",
      "1651 Highly proficient in Python (packages: pandas, scikit-learn, statsmodels) and SQL; experience working with AWS preferred\n",
      "1652 Experience building ETL & Data pipelines and familiarity with Git, Jira, etc\n",
      "1653 5+ years C/C++ experience, including C++11 (and up) features and principles | Plus de 5 ans d’expérience en C/C++, y compris les fonctionnalités et principes de C++11 (et supérieur)\n",
      "1654 GPGPU experience, such as CUDA, OpenCL or Direct Compute development | Expérience en développement GPGPU, tel que CUDA, OpenCL ou Direct Compute\n",
      "1655 5+ years of experience with one or more high-level graphics APIs, such as DirectX 11+ or OpenGL | Plus de 5 ans d'expérience avec une ou plusieurs API graphiques de haut niveau, telles que DirectX 11+ ou OpenGL\n",
      "1656 Experienced writing code for DirectX 12, Vulkan, DXR API | Expérience de l'écriture de code pour DirectX 12, Vulkan, DXR API\n",
      "1657 Support the software engineering team with embedded Linux software architecture and implementation.\n",
      "1658 Assisting with C/C++ software according to the company SDLC process.\n",
      "1659 Experienced with UNIX/POSIX programming interface.\n",
      "1660 Ability to implement ETL pipeline using Databricks, Azure ADF ETL pipeline .\n",
      "1661 Experience in migrating batch ,streaming data from On-Prem Hadoop/Oracle to Azure ADLS\n",
      "1662 Should have good hands on experience in Azure ADF ,Databricks pipelines ,functions ,ADLS(Gen2)\n",
      "1663 Expert in Hadoop, Hive, sqoop, python, Pyspark, Scala spark , Kafka and other related big data related technologies and have related project experience.\n",
      "1664 Deliver scalable and reliable Big Data solutions leveraging Hortonworks HDP Hadoop platform, RDBMS, SaaS platforms and APIs.\n",
      "1665 Apply concepts, industry research, best practices and agile methodologies and tools (Jira, Confluence) to implement Big Data solutions\n",
      "1666 Nice to Have knowledge of Machine Learning ,Python ,R and other Data science technologies\n",
      "1667 Knowledge of SAS language .\n",
      "1668 Experience driving the design of at least one mobile app for both iOS & Android\n",
      "1669 You will collaborate with customers and peers, develop content and enable the wider community to harness the power of AWS Cloud\n",
      "1670 As a trusted advisor with proven technical expertise developing full-stack solutions on AWS Cloud, you will share recommendations around system and application architectures, security and cost considerations, performance, reliability and operational efficiency to accelerate the customer’s challenging, mission-critical projects\n",
      "1671 C++, Go, Java, JavaScript, .NET, Node.js, Python, Ruby, Rust) and cloud-centric technology domains such as Serverless, Containers, Big Data, Analytics, Machine Learning, high-performance databases (SQL and NoSQL), complex networking implementations, and highly secured workloads.\n",
      "1672 You’ll be joining a team of senior software developers and machine learning researchers, working on standalone products as well as core Windows technologies\n",
      "1673 Write correct, efficient, and production-grade C++ and C# code.\n",
      "1674 Understand Windows UWP architecture.\n",
      "1675 The Senior Data Analyst role is responsible for Advanced Analytics/Machine Learning application development support executing in the Microsoft Azure Machine Learning (ML) Environment.\n",
      "1676 Define and manage application security setup using Active Directory/Azure security, including access audit and access clean-up.\n",
      "1677 A strong proficiency in querying and manipulating large data sets for analytical purposes using SQL-like languages (Hive / Hadoop experience preferred).\n",
      "1678 Proven proficiency in Python and R coding, including basic mathematical computing libraries such as NumPy, machine learning fundamentals, and data science fundamentals.\n",
      "1679 We use Typescript front to back using NextJS/React and NodeJS\n",
      "1680 You have great experience with automation tools, infrastructure-as-code (Terraform, GitHub actions, etc).\n",
      "1681 Experience and good understanding of AI-focused products like Virtual Agent Designer, NLU and AI Search (Cognitive Search).\n",
      "1682 Expertise with ServiceNow scripting (JavaScript) and Java\n",
      "1683 Experience with performing analysis using MS Excel or other analytical tools\n",
      "1684 You are confident in your programming proficiency in Java or JavaScript and enjoy thinking about business problems at a high level.\n",
      "1685 • Experience with Informatica or other related data Integration tools\n",
      "1686 Experience with Cloud Technologies (Data Lake, Azure, Google, AWS etc.) or experience with open source technologies (Spark, Kafka, Presto, Hive, Cassandra etc.)\n",
      "1687 Experience with SQL and/or NOSQL databases Preferred Skills and Qualifications: • Production implementation experience for all qualifications listed • Production experience in building real-time analytics applications • Experience in both batch and stream processing technologies\n",
      "1688 Experience with 2 of 3 - Java, Scala, and Python programming languages\n",
      "1689 Machine learning experience with Spark or similar\n",
      "1690 You’ll be joining a team of senior software developers and machine learning researchers, working on standalone products as well as core Windows technologies\n",
      "1691 Write correct, efficient, and production-grade C++ and C# code.\n",
      "1692 Understand Windows UWP architecture.\n",
      "1693 Demonstrated strengths in Python, Java, and SQL and NoSQL data stores\n",
      "1694 Proficient in at least one big data technology, preferably Spark\n",
      "1695 Deep experience with AWS technologies including S3, serverless functions, EMR, Redshift\n",
      "1696 Knowledge of Confluence or similar platform for documentation\n",
      "1697 Java 11 including JUnit, Hibernate, and Guice\n",
      "1698 MySQL, AWS Aurora, DynamoDB\n",
      "1699 Kafka & event-driven microservice architectures\n",
      "1700 Proficiency in, at least, one modern programming language such as Python, C/C++ or Java\n",
      "1701 Model development , validation and deployment using Internal Amazon tools and public services such as AWS Sage Maker for large-scale applications.\n",
      "1702 Experience with modeling tools such as R, scikit-learn, Spark MLLib, MxNet, Tensorflow, numpy, scipy etc.\n",
      "1703 Experience with large scale distributed systems such as Hadoop, Spark etc.\n",
      "1704 Contribute to the HCM ML codebase in Python\n",
      "1705 Experience with Python is a plus\n",
      "1706 React, is a plus\n",
      "1707 Optimization and integration through programming languages, e.g., python\n",
      "1708 Hands-on coding experience using scripting languages, e.g., python\n",
      "1709 Advanced proficiency with Python and Java code development; expertise with software development tools and frameworks such as Github, PostgreSQL, Kafka, Airflow, Jenkins, docker, Spark, Apigee etc.\n",
      "1710 Familiar with Linux, Openshift and public cloud (AWS and Azure)\n",
      "1711 Web Technologies (JavaScript, React, Redux, HTML5, CSS3, Webpack, REST/JSON)\n",
      "1712 Java and Spring\n",
      "1713 Redhat Linux, vagrant and virtualized networks\n",
      "1714 PostgreSQL Relation Database and Neo4j Graph Database\n",
      "1715 Strong programming skills in Java\n",
      "1716 Strong ability to plan and automate E2E test workflows in Java\n",
      "1717 Working knowledge with object-oriented programming in Java\n",
      "1718 Understanding of SQL and relational databases\n",
      "1719 Solid foundation in Unix/Linux environments\n",
      "1720 Experience in Git version control\n",
      "1721 Experience in developing automation frameworks and using tools like JMeter and Selenium\n",
      "1722 OSPF/ISIS, BGP), MPLS, IP VPN, VLAN, L2 and L3 VPN Services\n",
      "1723 Demonstrable programming experience in Python\n",
      "1724 If you are someone who loves modern C++ and wants to learn how to write high-performance data processing, rendering and image processing code, this is the role for you!\n",
      "1725 Developing a Data Analysis visualization software in C++.\n",
      "1726 Developing computer vision/image processing algorithms using Nvidia CUDA.\n",
      "1727 Implement docker-based image processing algorithms to run on the AWS cloud.\n",
      "1728 C++ programming experience.\n",
      "1729 Docker, Web Services and Database development\n",
      "1730 Linux and Windows development\n",
      "1731 5+ years software development experience with familiarity of at least one of OOP languages: C#/Java\n",
      "1732 Strong knowledge in C, Python, and any scripting languages\n",
      "1733 Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design\n",
      "1734 Apply big data technologies for data extraction transformation and loading (Spark, PySpark, Hadoop, MapReduce, etc)\n",
      "1735 Analyze data using analytics tools such as Redshift and ElasticSearch to develop hypothesis and design data driven solutions for our business\n",
      "1736 Experience with data technologies including EMR, S3, DynamoDB, ElasticSearch\n",
      "1737 Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design\n",
      "1738 We are looking for an experienced software engineer that can combine open source technologies such as Hadoop, Hive, Spark and Presto, as well as AWS services like EMR, Redshift, Kinesis and DynamoDB to build the next generation of our Traffic Ingestion and Application platform\n",
      "1739 Experience in big data technologies (Hadoop, Hbase, Pig, Spark).\n",
      "1740 Experience in XHTML, Javascript, CSS and modern web technologies\n",
      "1741 React.JS, AngularJS, Vue)\n",
      "1742 Every day, you will be coding in both Java and Javascript, as well as using many AWS products\n",
      "1743 Understanding of web services technologies such as SOAP, HTTP, WSDL, XSD, and REST\n",
      "1744 AWS, Azure, GCP)\n",
      "1745 SAS DataFlux ETL Tools\n",
      "1746 Expertise in using Hadoop, MapReduce, Spark, Pig, Hive technologies, Data Ingestion in Data Lake, Data Storage on key Cloud providers (AWS, Azure, GCP), Redshift, Data Retrieval on Big Data platforms and Interfacing Data Science and Data Visualization tools on Big Data platforms\n",
      "1747 Cloudera, Hortonworks, AWS, Talend, etc.), Data Migration and Quality (using ETL e.g Informatica), MySQL/NoSQL, CQRS Event Sourcing\n",
      "1748 Experience of working on Layer3 IP technologies (IPv4/IPv6, SNMP, IPSEC, VRRP, RIP, ISIS, OSPF, BGP, EIRGP, MPLS, PBR, ACL etc…).\n",
      "1749 Experience in Automation Test Development (TCL/Perl/Python) an asset.\n",
      "1750 Experience in software development using JavaScript and Angular.\n",
      "1751 Public cloud platforms (preferably AWS)\n",
      "1752 Angular and Javascript as well as the underlying API's for a great user experience as well as a secure session\n",
      "1753 Microchip is also a pioneer in embedding RiscV processors in FPGAs\n",
      "1754 Practical coding experience in Verilog, Python, or C/C++, demonstrated in research projects or prior work experience\n",
      "1755 Familiarity with at least one of these areas: digital logic design; data structures and algorithms; linear algebra; processor architecture; compiler tools (e.g., LLVM)\n",
      "1756 To thrive in this development career, you'll need to be an expert in Java (Java 8 preferred) and have a firm grasp on Spring Boot, Javascript, Angular and/or React\n",
      "1757 You'll need to be familiar with web services, RESTful APIs, and open source tools such as Apache KAFKA\n",
      "1758 Contributes to and enforces code standards as well as facilitates code reviews and GIT Flow processes.\n",
      "1759 Hands on experience with the JavaScript, TypeScript, React, AngularJS, Angular 5/6/7, HTML, CSS\n",
      "1760 Angular (Angular 5+) and/or React Experience\n",
      "1761 Strong Javascript Skills\n",
      "1762 Strong CSS (CSS3) skills, experience with SASS a CSS framework\n",
      "1763 Strong HTML (HTML5) skills\n",
      "1764 +1 Experience with developing software within a cloud-based environment (AWS, Azure, GCP) is a plus\n",
      "1765 Excellent knowledge of using medium resolution optical satellite data (e.g., Sentinel-2 or Landsat-7/8)\n",
      "1766 Good skills in at least one programming language (e.g Python, C++)\n",
      "1767 +1 for good knowledge of the Python scientific stack: Numpy, Scipy, OpenCV, Matplotlib, GDAL, etc\n",
      "1768 Experience with HTML and CSS, JavaScript, React, Angular, or Vue\n",
      "1769 Experience with RESTFull APIs, CMS\n",
      "1770 Experience developing distributed cloud application using C++, C#, Python, or other programming languages\n",
      "1771 Experience with AWS, Serverless, Microservice architectures, and other modern application paradigms\n",
      "1772 Knowledge of relational databases and NoSQL\n",
      "1773 Extensive hands-on experience with .Net, .Net Core, backend processing, and big data platform\n",
      "1774 Hands-on experience with AWS\n",
      "1775 Knowledge and experience of Python.\n",
      "1776 QuickSight is deeply integrated with AWS data sources, allowing companies to deploy secure and scalable BI with their data on AWS.In this role, you will build experiences for AWS QuickSight application on a wide variety of devices and form factors.\n",
      "1777 Experience in web technologies such as JavaScript, React and HTML5 is a plus\n",
      "1778 3+ years of experience with mobile application development (iOS and/or Android)\n",
      "1779 Knowledge of modern engineering practices like automated deployments with integrated quality gates and experience working with modern version control systems like Git\n",
      "1780 Spark knowledge is preferred\n",
      "1781 Must have: experience in writing requirements on projects using Agile Methodology and Tools (Epics, User Stories, Personas, Story mapping, Backlog refinement, JIRA, Confluence, and JTMF experience)\n",
      "1782 You bring to the team your senior-level knowledge of OOD, in particular with JavaEE 8+, microservices based architectures, Web 2.0 and JS frameworks using ECMAScript 6+ / TypeScript, and practical experience with relational and NoSQL databases.\n",
      "1783 5+ years of experience with Java EE; with emphasis on enterprise software development\n",
      "1784 1+ years experience building scalable web applications built around microservices architecture, including RESTful services in Node.JS, Java or Go.\n",
      "1785 Project experience that completed and deployed to production, using one or more of: Node.JS/Express, React, Vue.\n",
      "1786 Proficient at writing native HTML5, JavaScript/ECMAScript6+, CSS3.\n",
      "1787 Testing frameworks including JUnit 4/5, Mocha, Jest.\n",
      "1788 Cloud architecture experience in at least one of AWS, GCP, Azure.\n",
      "1789 Hands-on experience with relational databases such as Oracle, MSSQL, DB2.\n",
      "1790 NoSQL database experience with one of Mongo, Couchbase, Spark, Hbase.\n",
      "1791 Project experience with asynchronous languages with Node.JS and GoLang\n",
      "1792 Docker containerization\n",
      "1793 Kubernetes, container orchestration\n",
      "1794 Mobile web development targeting Android / iOS using React Native\n",
      "1795 Deep understanding of CSS and advance beyond off-the-shelf CSS frameworks\n",
      "1796 Familiarity with Linux or BSD\n",
      "1797 You have extensive experience with .NET and web services.\n",
      "1798 Use .NET and SQL Server technologies to shore up existing royalties processes\n",
      "1799 Update existing systems and participate in design and implementation of a new service-based distributed royalties system, using a blend of .NET and AWS technologies.\n",
      "1800 Analyze existing SQL-based systems to infer rules and manage migrations\n",
      "1801 5+ years demonstrated ability with C#\n",
      "1802 2+ years of experience with Git\n",
      "1803 Skilled in SQL Server development with T-SQL\n",
      "1804 Some experience working in an environment that is cloud-based (such as AWS or Azure) or at least container-centric (such as Docker or Kubernetes)\n",
      "1805 Experience with Amazon Web Services\n",
      "1806 Experience with messaging services such as RabbitMQ, ActiveMQ, or Kafka\n",
      "1807 Experience with PostgreSQL and/or NoSQL databases like MongoDB or DynamoDB\n",
      "1808 Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design\n",
      "1809 Programming experience with at least one modern language such as Python, Java, C++, or C# including object-oriented design\n",
      "1810 Do you want to contribute to the overall design, development, and maintenance of our back-end AWS product services? Do you excel in an agile software development environment? Then join our experienced and diligent back-end team! You will be held accountable to the design of key services such as analytics interpretation, data warehousing, ETL workflows, and inventory management systems\n",
      "1811 A minimum of 3 years of experience in a web applications back-end development or equivalent role using PHP/Python or another server side scripting language\n",
      "1812 A minimum of 3 years of experience working with SQL relational databases\n",
      "1813 A minimum of 2 years of experience working with NoSQL databases\n",
      "1814 Experience working with AWS services (Glue, Athena, Redshift, EMR, Kinesis, Lambda, etc.)\n",
      "1815 Experience with API development (Slim, Restlet, Falcon)\n",
      "1816 Experience using a version control system (Subversion or Git)\n",
      "1817 Experience working in a Mac OS X and/or Linux environment\n",
      "1818 Experience using ML Flow or similar tool to deploy operational models in Azure Cloud.\n",
      "1819 Experience in using Python and Pyspark for predictive supervised model building.\n",
      "1820 Experience in creating/implementing machine learning models using Python/R/SAS and integrating them into Batch Inference pipelines.\n",
      "1821 Expertise in working with machine learning related python packages - Scikit learn, XGBoost, matplot lib and proficient is data pre-processing using pandas.\n",
      "1822 Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design\n",
      "1823 Experience with big data technology stacks: SQL & NoSQL data stores, streaming & batch technologies such as Kafka, Kinesis, Spark, EMR\n",
      "1824 Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design\n",
      "1825 Proficiency in Java or any other object oriented programming is required, and the ideal candidate is an expert in at least one of these languages\n",
      "1826 Proficiency with software development using AWS technologies\n",
      "1827 Scalable web application development and experience using NoSQL databases like DynamoDB.\n",
      "1828 MapReduce or similar large scale distributed systems using AWS.\n",
      "1829 Large scale distributed systems development on Unix type platforms.\n",
      "1830 Strong experience working with Python, or R; working knowledge of SQL (familiarity with multiple languages considered an asset).\n",
      "1831 AWS, Microsoft Azure).\n",
      "1832 Apache Spark, Hadoop, etc.), natural language processing and deep learning frameworks (ex\n",
      "1833 Tensorflow, Pytorch) is an asset but not required.\n",
      "1834 3+ years of programming experience with at least one modern language such as Java, C++, or C# including object-oriented design\n",
      "1835 3 - 15 years experience writing large scale systems in C/C++\n",
      "1836 Amazon Redshift is a fast, scalable analytic service that makes it simple and cost-effective for our customers to analyze data across their data warehouse and data lakes\n",
      "1837 Redshift delivers faster performance than other analytics services by using machine learning, massively parallel query execution, and columnar distributed storage on cloud\n",
      "1838 Amazon Redshift is rapidly growing, fast and powerful, fully managed, petabyte-scale data analytic service in the cloud\n",
      "1839 It enables customers to dramatically increase their query performance when analyzing virtually any size data set using the same SQL-based business intelligence tools they use today\n",
      "1840 Amazon Redshift can elastically scale up and down the storage and compute to meet our customers demands, uses machine learning technology to auto-tune the database engine\n",
      "1841 It makes it easy for data analysts and database developers to create, train, and apply machine learning models using familiar SQL commands\n",
      "1842 Knowledge of programming language such as C, C++\n",
      "1843 Programming experience in C/Matlab/Python/tcl for algorithmic design exploration and testing\n",
      "1844 - Build, maintain and optimize data pipelines and repositories using Python, Spark, Databricks, SQL, Azure Data Lake, Delta Lake.\n",
      "1845 - Advanced experience with Databricks, Spark, Python and SQL development.\n",
      "1846 - Professional experience designing and developing cloud-based Data oriented PaaS solutions in Azure considered an asset.\n",
      "1847 - DevOps experience using Azure DevOps is considered an asset.\n",
      "1848 - Experience utilizing various BI tools (Tableau, PowerBi, D3.js) is considered an asset.\n",
      "1849 Strong skills in Microsoft applications (Word, Excel, PowerPoint and Visio)\n",
      "1850 Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design\n",
      "1851 Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design\n",
      "1852 Experience with deployment management tools such as Puppet, Chef, or Ansible\n",
      "1853 Experience with Android and iOS development\n",
      "1854 Knowledge of JavaScript frameworks e.g\n",
      "1855 JQuery, ReactJS\n",
      "1856 Knowledge of databases, SQL and No-SQL desired\n",
      "1857 You will be leveraging the AWS Platform to implement data pipelines, and have the opportunity to experiment with evolving tools and new data services.\n",
      "1858 Strong working knowledge of SQL.\n",
      "1859 Experience with cloud platforms and data pipelines in Azure or AWS as well as with ETL frameworks or tools (SSIS, Informatica, Kettle or similar)\n",
      "1860 Strong capability with shell scripting (bash, kshell, powershell)\n",
      "1861 Experience with working with REST APIs, flat files (csv and Excel)\n",
      "1862 (bonus) Working knowledge with NoSQL platforms (MongoDB, Cosmos)\n",
      "1863 We have opportunities for developing code on macOS and Windows platforms\n",
      "1864 Experience writing software using Swift, Objective-C, C++ or similar\n",
      "1865 Scripting using Python\n",
      "1866 Experience with Azure cloud technologies for creating data pipelines (Data Factory, Azure Synapse)\n",
      "1867 Databricks or Apache Spark experience\n",
      "1868 Possess in-depth understanding of SQL, database management systems, online analytical processing (OLAP) and ETL (Extract, transform, load) frameworks\n",
      "1869 SQL, PowerShell, Python)\n",
      "1870 Knowledge of the following tools and technologies: Power Pivot, Power Query, Visual Studio, SSMS, Azure Machine Learning\n",
      "1871 Expose endpoint such as a REST or GraphQL api\n",
      "1872 Azure build and deployment experience\n",
      "1873 3+ years of programming experience with at least one modern language such as Java, C++, or C# including object-oriented design\n",
      "1874 Experience developing production systems in JavaScript (Node.js, etc.) and using client-side technologies and frameworks (Vue.js, etc.)\n",
      "1875 TensorFlow, MXNet, scikit-learn)\n",
      "1876 Experience designing and implementing clean APIs following RESTful concepts and/or using GraphQL\n",
      "1877 5+ Experience with production engineering systems with SQL and python.\n",
      "1878 Experience with UX technologies such as Angular, React and RESTful APIs.\n",
      "1879 Experience with Spark, Hadoop, Spring Boot, Python, Java a plus\n",
      "1880 Experience working with Docker, Kubernetes and Helm in multiple cloud providers.\n",
      "1881 Experience with CI/CD automation and tools such as TeamCity and Jenkins.\n",
      "1882 Proficient in C++\n",
      "1883 Proficient in Microsoft Visual Studio\n",
      "1884 Jenkins or similar automation tool\n",
      "1885 Experience with XML\n",
      "1886 Proficiency with scripting languages (Python, Perl, Bash) and GUI automation frameworks\n",
      "1887 Experience with source control and issue tracking systems (SVN, JIRA)\n",
      "1888 Our tests are primarily written in C++ through Visual Studio on Windows and our automation ranges from simple shell scripts to more complex Python programs\n",
      "1889 Experience with a mainstream database (DBMS/DBaaS) such as (but not limited to): PostgreSQL, MySQL, Oracle, MongoDB, CouchDB, DynamoDB, Firebase, Parse/ParseServer\n",
      "1890 Experience in Python, Node.js or Scala\n",
      "1891 Bonus: Machine Learning, GraphQL, AWS\n",
      "1892 Advanced Microsoft Excel and overall Microsoft Office skills, with strong verbal and written communication skills, and demonstrated experience presenting to internal or external stakeholders.\n",
      "1893 Expertise inPython, R, SQL, or other business-relevant programming language.\n",
      "1894 Experience with one or more data visualization platforms (e.g.: Tableau, Domo, PowerBI, etc.).\n",
      "1895 Experience with ETL creation (Python, SQL) and automation thereof.\n",
      "1896 Understanding of one the following cloud stacks (AWS, GCP, Azure)\n",
      "1897 Technology stack includes Java, Go, Javascript, CSS, React JS.\n",
      "1898 Strong experience with coding and testing in JAVA.\n",
      "1899 Experience in developing with Javascript/HTML/CSS.\n",
      "1900 Validated knowledge of SQL and understanding of relational database schema design.\n",
      "1901 Development experience on Linux or Mac.\n",
      "1902 Languages: Go, Python, ES6, React.js\n",
      "1903 Experience in Docker orchestration and management.\n",
      "1904 Familiarity with Spark\n",
      "1905 H2O.ai, Spring, Jenkins.\n",
      "1906 In depth knowledge of Git\n",
      "1907 Advanced Knowledge in data analytic and visualization platform Microsoft Power BI\n",
      "1908 Experience with design tools such as Figma or Sketch.\n",
      "1909 Excellent understanding of the tools of the trade, including proficiency in a modern programming languages (Java, C/C++, Objective C) and open-source technologies\n",
      "1910 Experience building machine learning software utilizing AWS SageMaker.\n",
      "1911 Experience with Big Data technologies such as AWS, Hadoop, Spark\n",
      "1912 Create solutions aligned with the long-term architecture and technology strategy using Amazon Web Services(AWS) for Cloud development\n",
      "1913 Expert programming skills with professional programming experience with technologies such as Python,Scala, Java, and Angular6\n",
      "1914 Strong knowledge of software development best practices and patterns with familiarity building applications in an AWS environment\n",
      "1915 English: C1 Advanced\n",
      "1916  Hadoop, Hive, Cloudera, Talend, Diyotta, Data Stage, Infosphere\n",
      "1917  HFDS storage, network, and security resources of Azure and GCP\n",
      "1918  DevOps tools such as Git, Jenkins, Anthos, Terraform, Ansible\n",
      "1919  Monitoring & analysis tools such as ELK, Dynatrace, Splunk, SmartSense, PowerBI or BigQuery\n",
      "1920  Platforms built using Kubernetes\n",
      "1921 Architecting, designing, developing, and supporting the platform on both cloud and edge components (Golang, and Python), including the areas of: Data model and access, High-availability, Fault-tolerance, Scalability, IOT protocols, Edge computing, IaaS platforms, AI infrastructure, security consciousness\n",
      "1922 3 years of experience in Golang, Java, Scala, or equivalent\n",
      "1923 Experience with the databases (Relation and/or NoSQL) and query considerations with large amounts of data\n",
      "1924 We have opportunities for developing code on macOS and Windows platforms.\n",
      "1925 Experience writing software using C, C++ or similar\n",
      "1926 Scripting using Python\n",
      "1927 You are skilled at many of the tools we currently use (Power BI, SQL, SSIS, C#, Excel VBA) and may introduce (python, SharePoint …).\n",
      "1928 You have an advanced understanding of ETL and a track record in designing solid solutions using SSIS, Python.\n",
      "1929 You have 2+ years experience and are proficient in creating meaningful reports on MS Excel, PowerBI, DAX, Power Query.\n",
      "1930 Your technology stack includes strong experience with most of the following: C#, SQL / SQL Server, SSIS, SSAS (SQL Server Analysis Services), SSRS, SSMS (SQL Server Management Studio), Visual Basic, Power BI, XL Macros, and other scripting languages\n",
      "1931 Python, Hadoop, Hive and R are assets.\n",
      "1932 You have experience with code repository, version control and code promotion tools such as Git/bitbucket and Jenkins\n",
      "1933 o Experience with open-source data integration platforms like Airflow, NiFi\n",
      "1934 o Experience in storing, manipulating and integrating NoSQL data to BI reporting.\n",
      "1935 o Experience with Azure cloud platform.\n",
      "1936 CDA, DALSM, DASM) (an asset)\n",
      "1937 Knowledge of Agile practices and frameworks such as: Kanban, JIT, Lean principles, Disciplined Agile, XP, SAFe, Nexus, etc.\n",
      "1938 Jenkins, CircleCI, GitLab) (an asset)\n",
      "1939 Kotlin and Java 11 (including JUnit, Hibernate, and Guice)\n",
      "1940 MySQL, TiDB\n",
      "1941 C/C++ programming skills\n",
      "1942 Experience writing test scripts using Perl/bash/python\n",
      "1943 Familiarity with storage networking concepts and protocols (PCIe, SAS and SATA, SCSI, 10/100/1000 Ethernet, TCP/IP)\n",
      "1944 Past work with Unix & Wintel drivers and experience in FW development with light weight embedded kernels (ThreadX, VxWorks, eCos, etc.)\n",
      "1945 Strong debugging skills and experience with kernel (Windbg), JTAG, serial port\n",
      "1946 Expertise in Javascript, Java or Python, OOP, Design Patterns, and time and space-efficient algorithms\n",
      "1947 Experience performing customer data analysis using MS Excel or other analytical tools\n",
      "1948 Experience in software development using JavaScript and Angular.\n",
      "1949 Public cloud platforms (preferably AWS)\n",
      "1950 Angular and Javascript as well as the underlying API's for a great user experience as well as a secure session\n",
      "1951 Special Skills: C++, JavaScript, Python, Java,\n",
      "1952 OOP development experience (C++ and JavaScript)\n",
      "1953 C#, python, bash and JAVA\n",
      "1954 Sencha EXTJS 4.2, Qt 4+\n",
      "1955 React, Angular, jQuery, NodeJS\n",
      "1956 Redis / Redis Streams\n",
      "1957 Kubernetes, Docker\n",
      "1958 MongoDB, PostgreDB, MySQL\n",
      "1959 RedHat, CentOS\n",
      "1960 Azure, Hadoop\n",
      "1961 Elasticsearch\n",
      "1962 Understanding of machine learning concepts (e.g., Tensorflow)\n",
      "1963 Understanding of protocols such as Modbus, DNP3, OPC UA/DA, SNMP, and others\n",
      "1964 Experience with Virtualization, Containers and Container Orchestration (Docker, Kubernetes)\n",
      "1965 strong Python skills;\n",
      "1966 strong Django skills (or Flask); and\n",
      "1967 Linux\n",
      "1968 Jenkins CI/CD Pipelines\n",
      "1969 Angular\n",
      "1970 HTML5\n",
      "1971 CSS3\n",
      "1972 Node.js\n",
      "1973 Nginx\n",
      "1974 Docker & Kubernetes\n",
      "1975 SQL\n",
      "1976 Kafka\n",
      "1977 Hadoop\n",
      "1978 Elasticsearch\n",
      "1979 3+ years of programming experience with at least one modern language such as Java, C++, or C# including object-oriented design\n",
      "1980 Experience with Java, Python, Scala\n",
      "1981 Skill performing data deep-dives, writing and debugging complex SQL queries, and ingesting data from a variety of different data sources and in a variety of different formats.\n",
      "1982 Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design\n",
      "1983 Programming experience with at least one modern language such as Java, C++, or C#.\n",
      "1984 Working knowledge of relational and NoSQL databases.\n",
      "1985 Advanced SQL and Hadoop expertise\n",
      "1986 Experience with Excel and some dashboarding/data visualization (i.e\n",
      "1987 Tableau, Mixpanel, Looker, Google Data Studio etc.)\n",
      "1988 Familiarize yourself with the multi-cloud environment and existing distributed domain controllers within VMware platform\n",
      "1989 Experience in Python, Go, C++, or similar scripting and programming languages\n",
      "1990 Expertise in using python libraries for data science and machine learning such as: pandas, NumPy, scikit-learn, TensorFlow, etc.\n",
      "1991 Our visualization stack is a Go server driving an Electron application, primarily written in TypeScript, though we are increasingly using Rust for high-speed algorithms\n",
      "1992 You should expect to be writing mostly Go out of the gate, but you will have the opportunity to write more front-end code, or even Rust, should you choose\n",
      "1993 Significant experience writing application-level logic within the web stack, in one or more of the following: Go, Python, Node/Express, Django, Flask or Ruby on Rails.\n",
      "1994 Hands-on experience writing applications in Go or Rust a significant plus\n",
      "1995 Front-end development (React, TypeScript, Vue, Angular, etc.) and/or visualization tool (D3, Plotly, regl, three.js, etc.) experience using modern web technologies a plus\n",
      "1996 As an Embedded Systems Developer your key area of responsibility will be designing, writing, and testing C, C++, and Rust code for Geotab’s GO telematics devices\n",
      "1997 Perform firmware development in the required area of expertise (modem, GPS, vehicle data, security, etc) using C, C++ and Rust as per the development standards.\n",
      "1998 Write SQL queries and Python scripts on data from Google BigQuery to determine device health and effectiveness of new functionality.\n",
      "1999 Strong knowledge of programming languages (C/C++/C# ) in an embedded software context.\n",
      "2000 Exposure and/or experience with RTOS and Linux.\n",
      "2001 Experience with SQL.\n",
      "2002 bash, Python, TCL, etc.) is highly valued.\n",
      "2003 Experience programming in Rust is highly valued.\n",
      "2004 Proven experience and knowledge of the following tools: Python (Pandas Library, specifically), SQL Server, SAS, Power BI\n",
      "2005 Programming skills in SQL (e.g., PLSQL / T-SQL)\n",
      "2006 Teradata, Oracle)\n",
      "2007 Informatica, DataStage)\n",
      "2008 Experience with Microsoft Azure and Azure DevOps\n",
      "2009 Experience with UX technologies such as Angular, React and RESTful APIs.\n",
      "2010 Experience with Spark, Hadoop, Spring Boot, Python, Java a plus\n",
      "2011 Experience working with Docker, Kubernetes and Helm in multiple cloud providers.\n",
      "2012 Experience with CI/CD automation and tools such as TeamCity and Jenkins.\n",
      "2013 Consistent track record of delivering products with Unity and C#.\n",
      "2014 Experience with iOS, Android or Windows.\n",
      "2015 Experience with ARFoundation, ARKit or ARCore.\n",
      "2016 Experience with game console development Nintendo, PlayStation, Xbox).\n",
      "2017 AWS CloudFormation provides an easy declarative way to create, deploy and manage applications and infrastructure in the AWS cloud\n",
      "2018 Demonstrated experience in executing on complex projects, extracting, cleansing, and manipulating large, diverse structured and unstructured data sets on relational – SQL, NOSQL databases\n",
      "2019 5+ years of hands-on experience with programming languages such as Python (preferred), R and common machine learning packages such as dplyr, xgboost, glmnet, randomForest, H2o, Numpy, Pandas,scikit-learn, keras, tensorflow, etc.\n",
      "2020 Experience in Spark environment is a plus\n",
      "2021 Hands-on experience in developing and productionizing solutions using tools in AWS, data aggregation platforms such as Snowflake or similar.\n",
      "2022 Responsible for embedded Linux software architecture and implementation.\n",
      "2023 Developing C/C++ software according to the company SDLC process.\n",
      "2024 Experienced with embedded LINUX, U-Boot, BSP.\n",
      "2025 In-depth knowledge of Ethernet switching, routing and application level protocols (L2/L3 protocols) – RSTP, LLDP, STP, IGMP, VRRP, RIP, OSPF, TCP/IP, HTTP, NAT, IGMP, QoS, VLAN, VPN etc.\n",
      "2026 Experienced with UNIX/POSIX programming interface.\n",
      "2027 Strong experience with low level device drivers (I2C, SPI Master/Slave, Serial/HCI, GPIO, USB, SD, NAND, NOR, RAM).\n",
      "2028 Able to read schematic diagrams, experience with debug and test tools such as Oscilloscope, Logic Analyzer, Multi-meter, JTAG debugger.\n",
      "2029 You will work on Tableau’s next-generation Visual Analytics and Collaboration suite\n",
      "2030 As a full stack developer you will be working on a Python and Java based backend platform with modern web technologies frontend\n",
      "2031 Build modern front-end consumer-friendly interfaces and their Java and Python backend services allowing people to answer complex questions about their data.\n",
      "2032 Solid development skills with Python and Java\n",
      "2033 Experience developing in web languages such as JavaScript, TypeScript, HTML/CSS\n",
      "2034 C++ skills are a plus.\n",
      "2035 Mainly in C and Python but knowledge of C++/Java/Java Script/Bash Scripting/Visual Basic and others are considered an asset\n",
      "2036 Experience with Linux distributions such as Ubuntu, Yocto and OpenWRT\n",
      "2037 Support of Linux and RTOS BSPs\n",
      "2038 Terraform, GIT, CI/CD\n",
      "2039 Internet of Things (IoT) experience: interfacing with sensors and moving that data into the cloud (AWS IOT Greengrass experience is especially an asset)\n",
      "2040 A minimum of 3 years experience writing and optimizing SQL queries\n",
      "2041 A minimum of 3 years experience with Apache Spark for big data processing\n",
      "2042 Extensive knowledge of Python programming language and its data manipulation libraries (Pandas and Numpy)\n",
      "2043 Expertise with RDBMS and NoSQL databases at scale\n",
      "2044 Experience with Apache Airflow or other similar data pipelining and workflow scheduling framework (Luigi, Azkaban)\n",
      "2045 Ability to use containers, orchestration frameworks, and other DevOps tools (Kubernetes, Terraform, Giant Swarm, etc.)\n",
      "2046 Proficiency with cloud resources (AWS/Google Cloud/Azure) with the ability to operate them for the components owned\n",
      "2047 Knowledge of the AWS services (Redshift, Glue, Athena, S3, etc.) an asset\n",
      "2048 Knowledge of big data technology (Databricks, Hadoop, Hive, Pig, Presto) an asset\n",
      "2049 Familiarity with continuous integration and automated pipeline tools (Jenkins, Travis, etc.)\n",
      "2050 Proficiency in Git\n",
      "2051 Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design\n",
      "2052 You will be applying the latest AWS technologies (Lambda, SageMaker, Fargate, ECS, Kinesis, API Gateway, Glue, Step Functions, EMR, Elasticsearch, etc.) and leveraging the most appropriate solutions (data mining, machine learning, statistical modelling, natural language processing, etc.) to develop the best advertising experience for our customers while maximizing the return on our marketing investments.\n",
      "2053 Scalable web application development and experience using NoSQL databases like Dynamo DB.\n",
      "2054 Familiarity with cloud computing platforms (e.g., Microsoft Azure, AWS).\n",
      "2055 Experience with writing SQL queries and familiarity with Power BI is a strong asset.\n",
      "2056 Advanced skills in Excel, PowerPoint, Word.\n",
      "2057 To thrive in this development career, you'll need to be an expert in Java (Java 8 preferred) and have a firm grasp on Spring Boot, Javascript, Angular and/or React\n",
      "2058 You'll need to be familiar with open source tools such as Apache KAFKA and web technologies\n",
      "2059 develop and build unit testing for Java RESTful APIs\n",
      "2060 Strong UI development with React, Angular or JS Framework\n",
      "2061 Strong development of RESTful Java APIs for Microservices Architecture\n",
      "2062 Strong SQL coding skills with Java & Spring\n",
      "2063 Understanding of Microsoft Azure Data & AI products\n",
      "2064 Expertise in one or more technologies like Teradata, Oracle Exadata, IBM Netezza, SAP (HANA, BW), HDInsight, Hadoop, Cloudera/Hortonworks, Apache Spark, Snowflake, MapR, AWS (Redshift, Glue), Google (BigQuery) preferred\n",
      "2065 5 years experience developing single-page JavaScript applications (SPAs) in a Data Analytics context\n",
      "2066 Deep understanding of vanilla JavaScript, HTML, and CSS (you use libraries but you don’t NEED to)\n",
      "2067 2 years backend experience NodeJS, or equivalent\n",
      "2068 Experience with CSS preprocessors (i.e\n",
      "2069 Experience building features end-to-end from UI to DB schema (without ORMs like Hibernate)\n",
      "2070 IPSec VPN Client Development experience on any one of the following platform would be big plus - iOS/Mac, Windows, Linux and Android\n",
      "2071 Strong Programming skills in Objective C, C/C++ or Java\n",
      "2072 TCP, UDP, IP, HTTP, DHCP/DNS,TLS, Active Directory/LDAP, SAML)\n",
      "2073 Experience in few of these technologies - Intel DPDK, Strongswan, IKE, Deep Packet Inspection (DPI)\n",
      "2074 Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design\n",
      "2075 Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design\n",
      "2076 In this role you will contribute to a critical and highly-visible function within the AWS business\n",
      "2077 You will include machine learning model building in Python using scikit-learn/Tensorflow and leveraging software engineering experience to develop and deploy scalable data engineering and model inference pipelines.\n",
      "2078 Computing: Software engineering, data science, machine learning engineering, data engineering, Python, Tensorflow, SQL\n",
      "2079 Specific Experience with: Linux, Kubernetes, Cloud\n",
      "2080 Azure Synapse Analytics\n",
      "2081 Azure Data Factory\n",
      "2082 Azure Machine Learning\n",
      "2083 Azure Databricks\n",
      "2084 5+ years of software engineering experience with Scala\n",
      "2085 Will also consider Java, C# or Python experience.\n",
      "2086 2+ years of experience with Kafka and/or Spark\n",
      "2087 An understanding of high-performance, scalable distributed systems (i.e., Apache Spark, Apache Mesos, Kubernetes, Hadoop/YARN)\n",
      "2088 Experience with AWS: EC2, MSK, DynamoDB, Terraform, Kinesis, etc.\n",
      "2089 Experience working with and orchestrating containers (Docker)\n",
      "2090 Experience with Elastic Search, Logstash, Kibana and/or Flume\n",
      "2091 Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design\n",
      "2092 Hands-on experience in cloud-based distributed software design and development, especially utilizing AWS services.\n",
      "2093 5 years experience developing single-page JavaScript applications (SPAs) in a Data Analytics context\n",
      "2094 Deep understanding of vanilla JavaScript, HTML, and CSS (you use libraries but you don’t NEED to)\n",
      "2095 2 years backend experience NodeJS, or equivalent\n",
      "2096 Experience with CSS preprocessors (i.e\n",
      "2097 Experience building features end-to-end from UI to DB schema (without ORMs like Hibernate)\n",
      "2098 Storing the data, using specialized technologies that are optimized for the particular use of the data, such as a relational database, a NoSQL database, Hadoop, or Amazon S3.\n",
      "2099 Excellent programming skills, particularly in one or more of SQL, R, Python,\n",
      "2100 Experience with SQL and NoSQL (e.g., SQLServer, Postgres, Aurora, Hadoop, HBase and/or Neo4j) databases\n",
      "2101 EMR, AWS Glue, AWS Step Functions, Kafka etc.)\n",
      "2102 XP, Scrum)\n",
      "2103 Solid knowledge of modern cloud architectures (e.g., microservices, serverless, event driven architectures) and technologies specifically AWS.\n",
      "2104 Proven knowledge of continuous delivery and approaches to continuous integration (Jenkins, Docker, Cloudformation/Terraform)\n",
      "2105 Experience in a Linux based environment gained through university subjects or work experience\n",
      "2106 Linux knowledge including the installation, troubleshooting and basic configuration of recent Ubuntu Desktop releases\n",
      "2107 Basic desktop Linux usage (desktop tools for editing files, browsing the Web, managing Internet connectivity, setup of printers/services/packages/external storage devices/etc\n",
      "2108 Understanding of Gmail, Google Calendar, Google Applications and Single Sign-On.\n",
      "2109 Some knowledge of programming (bash, Perl, Ruby, Javascript, C or C++, Go)\n",
      "2110 Basic troubleshooting of Mac and Windows operating systems.\n",
      "2111 Experience supporting virtualized environments (KVM, OpenStack, Virtual Box, VMWare)\n",
      "2112 Experience with containers (LXD/LXC, Docker, Kubernetes)\n",
      "2113 Proficiency in Python or R\n",
      "2114 Ability to write complex SQL queries\n",
      "2115 Experience with data visualization tools — Tableau, Power BI, etc\n",
      "2116 Technology stack includes Java, Go, Javascript, CSS, React JS.\n",
      "2117 Strong experience with coding and testing in JAVA.\n",
      "2118 Experience in developing with Javascript/HTML/CSS.\n",
      "2119 Validated knowledge of SQL and understanding of relational database schema design.\n",
      "2120 Development experience on Linux or Mac.\n",
      "2121 Languages: Go, Python, ES6, React.js\n",
      "2122 Experience in Docker orchestration and management.\n",
      "2123 Familiarity with Spark\n",
      "2124 H2O.ai, Spring, Jenkins.\n",
      "2125 In depth knowledge of Git\n",
      "2126 Advanced working SQL knowledge and experience working with relational databases, unstructured data storage, query engines, and message queues such as Apache Kafka and Apache Pulsar.\n",
      "2127 Experience implementing large scale, fault tolerant ETL pipelines using tools like Apache Flink, Apache Spark, and Apache Beam.\n",
      "2128 Solid knowledge of at least two programming languages like Scala, Java, Python, C++, or Go.\n",
      "2129 Experience working with at least one cloud platform like AWS, Azure or GCP.\n",
      "2130 Experience with MLOps and a machine learning platform like MLFLow or Kubeflow is a plus.\n",
      "2131 Experience developing and debugging complex distributed software deployed within a cloud-based environment (AWS, Azure, GCP)\n",
      "2132 Excellent knowledge in at least one high level programming language (e.g., Java, C++, Python, etc)\n",
      "2133 Excellent knowledge in RDBMS and/or NoSQL database technologies\n",
      "2134 Working knowledge of AWS or other cloud services\n",
      "2135 Working knowledge of Docker, ECS/EKS, lambda and microservice, serverless design paradigm\n",
      "2136 Ability to demonstrate competency in development languages and tools including .NET Framework, .NET Core, C#, & Cross Platform development.\n",
      "2137 Experience with Docker & Kubernetes is an asset.\n",
      "2138 Cloud Development (AWS, Azure or comparable).\n",
      "2139 Foundational knowledge of Python and SQL\n",
      "2140 Cloud knowledge and expertise of leading cloud providers (AWS, GCP, Azure)\n",
      "2141 Programming languages such as C++/C#/JavaScript/Assembly\n",
      "2142 Evolve our JavaScript platform.\n",
      "2143 Strong SQL experience and experience with ETL methodologies\n",
      "2144 Source control (Git) and familiarity with Unix command line\n",
      "2145 React)\n",
      "2146 Proficiency in Python or R\n",
      "2147 Ability to write complex SQL queries\n",
      "2148 Experience with data visualization tools — Tableau, R Shiny, etc\n",
      "2149 Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design\n",
      "2150 Strong experiences in containers, Kubernetes, RESTful services\n",
      "2151 Experiences using IaaS and/or PaaS (AWS, Google Cloud, Azure, vCloud Air); and virtualization environment (ESXi, Xen, Hyper-V, Docker, etc.).\n",
      "2152 Proficient in one or more of the following languages: GoLang, C/C++, Java, Javascript\n",
      "2153 Experience/exposure in React, AngularJS or Vue; HTML5, CSS, D3, Loopback, REST/JSON\n",
      "2154 Database experience must be familiar with RDBMS and NoSQL databases\n",
      "2155 Experiences with automation/configuration management using Jenkins, Puppet, Chef or equivalent technologies; and software configuration tools; build script and CI/CD\n",
      "2156 Experience with macOS or iOS development using Objective-C/Swift\n",
      "2157 Python, Bash\n",
      "2158 Jenkins, JIRA, Git\n",
      "2159 Experience with Unix/Linux command line\n",
      "2160 Work on our JavaScript platform to help launch new clients and improve current partnerships and toolsets\n",
      "2161 Deep understanding of JavaScript, including experience and knowledge of its standards and best practices.\n",
      "2162 Experience and skill with HTML and CSS\n",
      "2163 Source control (Git) and familiarity with unix command line\n",
      "2164 Experience with modern JS libraries and frameworks, such as jQuery, Coffeescript, SASS, Ember, Angular, React, Gulp, Grunt, WebPack, or others\n",
      "2165 Experience working with Tag Management Systems such as Google Tag Manager, Tealium and Signal\n",
      "2166 Server side technologies, especially Ruby / Ruby on Rails, SQL, Redis, Hadoop\n",
      "2167 · Excellent Microsoft Office, including Excel, Word, and Outlook skills.\n",
      "2168 Experience developing and software systems deployed within a cloud-based environment (AWS, Azure, GCP)\n",
      "2169 Excellent knowledge in front end development languages and frameworks including javascript, html5, css, typescript, react\n",
      "2170 Working knowledge of AWS or other cloud services\n",
      "2171 Write performant Java and Database code to progress the project goals and initiatives.\n",
      "2172 5+ years Java development experience\n",
      "2173 2+ years SQL database experience\n",
      "2174 Experience with Cloud technologies (AWS, Azure, GCP)\n",
      "2175 Java application performance tuning techniques\n",
      "2176 Java application debugging (thread and heap analysis)\n",
      "2177 NoSQL database experience\n",
      "2178 A minimum of 3 years experience writing and optimizing SQL queries\n",
      "2179 A minimum of 3 years experience with Apache Spark for big data processing\n",
      "2180 Extensive knowledge of Python programming language and its data manipulation libraries (Pandas and Numpy)\n",
      "2181 Expertise with RDBMS and NoSQL databases at scale\n",
      "2182 Experience with Apache Airflow or other similar data pipelining and workflow scheduling framework (Luigi, Azkaban)\n",
      "2183 Ability to use containers, orchestration frameworks, and other DevOps tools (Kubernetes, Terraform, Giant Swarm, etc.)\n",
      "2184 Proficiency with cloud resources (AWS/Google Cloud/Azure) with the ability to operate them for the components owned\n",
      "2185 Knowledge of the AWS services (Redshift, Glue, Athena, S3, etc.) an asset\n",
      "2186 Knowledge of big data technology (Databricks, Hadoop, Hive, Pig, Presto) an asset\n",
      "2187 Familiarity with continuous integration and automated pipeline tools (Jenkins, Travis, etc.)\n",
      "2188 Proficiency in Git\n",
      "2189 The successful Full Stack Web Developer candidate will have at least 3 years experience building complex applications using .NET technologies and will have experience with frameworks like Angular or React.\n",
      "2190 C# development experience.\n",
      "2191 Experience in modern JavaScript front end frameworks such as Angular and React.\n",
      "2192 Experience working in an Agile/Scrum environment, along with Confluence, JIRA, Bitbucket, and Git.\n",
      "2193 Knowledge of SQL Server, Database structures and design.\n",
      "2194 VMware data & analytics ecosystem includes Big Data Analytics tools (Hadoop, HDFS, Apache Spark), DWH (SAP HANA, AWS Redshift), Marketing Data Hub, Analytics Hub (AI/ML/Data Science) with data pipelines across 500+ applications & services shipping terabytes of data\n",
      "2195 Experience in one or many of these cloud platforms such as Snowflake, AWS Redshift, BigQuery and Azure Synapse.\n",
      "2196 Work with Business Analytics and data visualization teams to generate KPI using Tableau, Salesforce Einstein Analytics, Microsoft Power BI, etc.\n",
      "2197 Platform Optimisation across the ecosystem HDFS, Hadoop and Apache Spark.\n",
      "2198 5+ years of experience with data scripting languages (e.g SQL, Python, R etc.) or statistical/mathematical software (e.g\n",
      "2199 R, SAS, or Matlab)\n",
      "2200 Utilize code (python or another object oriented language) for data analyzing and modeling algorithms.\n",
      "2201 Ability to implement ETL pipeline using Databricks, Azure ADF ETL pipeline .\n",
      "2202 Experience in migrating batch ,streaming data from On-Prem Hadoop/Oracle to Azure ADLS\n",
      "2203 Should have good hands on experience in Azure ADF ,Databricks pipelines ,functions ,ADLS(Gen2)\n",
      "2204 Expert in Hadoop, Hive, sqoop, python, Pyspark, Scala spark , Kafka and other related big data related technologies and have related project experience.\n",
      "2205 Deliver scalable and reliable Big Data solutions leveraging Hortonworks HDP Hadoop platform, RDBMS, SaaS platforms and APIs.\n",
      "2206 Apply concepts, industry research, best practices and agile methodologies and tools (Jira, Confluence) to implement Big Data solutions\n",
      "2207 Nice to Have knowledge of Machine Learning ,Python ,R and other Data science technologies\n",
      "2208 Knowledge of SAS language .\n",
      "2209 Hands-on technical skills in Python, SQL, Map/Reduce, RegEx, and Linux scripting\n",
      "2210 Experience with big data platforms such as Hadoop, MapReduce, Spark, Hive, and Pig\n",
      "2211 Knowledge and experience working with Google Analytics, Tableau, Amplitude, and Treasure Data\n",
      "2212 3+ years of professional experience in operationalizing cloud-based (AWS, Azure, GCP) software solutions with a proven track record of delivering complex or algorithmically sophisticated functionality\n",
      "2213 Good skills and knowledge of best practices in at least one programming language (e.g Python, C++)\n",
      "2214 +1 for good knowledge of the Python scientific stack: Numpy, Scipy, OpenCV, Matplotlib, GDAL, etc\n",
      "2215 +1 for JupyterLab or JupyterNotebook\n",
      "2216 Growth and performance-oriented: It doesn’t matter if it’s Gradle, Groovy, Docker, Python, Ansible, Java or shell script - you know it or you can swiftly pick it up\n",
      "2217 Manage code repositories using GitHub and GitLab.\n",
      "2218 Familiarity with container orchestration services (Docker, Kubernetes).\n",
      "2219 Experience with infrastructure-as-code using Ansible, Terraform or CloudFormation.\n",
      "2220 Experience administering and deploying development CI/CD tools (GitLab, Jenkins, etc.)\n",
      "2221 Experience with Docker, and microservice architectures is preferred.\n",
      "2222 Experience with relational as well as non-relational data stores, such as MongoDB, Cassandra, HBase, etc.\n",
      "2223 Experience and good understanding of AI-focused products like Virtual Agent Designer, NLU and AI Search (Cognitive Search).\n",
      "2224 Expertise with ServiceNow scripting (JavaScript) and Java\n",
      "2225 Experience with performing analysis using MS Excel or other analytical tools\n",
      "2226 You are confident in your programming proficiency in Java or JavaScript and enjoy thinking about business problems at a high level.\n",
      "2227 Our main development technology is Python along with some of its frameworks, such as Django\n",
      "2228 We also use Docker to speed up our developments and deployments and the application code runs on Amazon Web Services.\n",
      "2229 Proficiency in Python.\n",
      "2230 Experience developing with Django and Django REST Framework.\n",
      "2231 And the obvious… Git and testing.\n",
      "2232 Experience developing with Vue.js or other JS Web Frameworks.\n",
      "2233 Basic knowledge of Docker.\n",
      "2234 Hands-on experience with relational DBs (e.g.: Postgres).\n",
      "2235 Experience with Linux.\n",
      "2236 Proficiency in Python or R\n",
      "2237 Ability to write complex SQL queries\n",
      "2238 Experience with data visualization tools — Tableau, Power BI, etc\n",
      "2239 Solid working knowledge of design tools (such as Figma or Sketch)\n",
      "2240 Excellent data visualization skills and working knowledge of data visualization and reporting tools (such as PowerBI or Tableau)\n",
      "2241 As a senior frontend engineer, you’ll use latest web standards in HTML, CSS and JavaScript and collaborate closely with our engineering, product, sales and customer success teams to build incredible and responsive modules that scale and perform well on all devices and provide a world-class experience for our customers and their shoppers.\n",
      "2242 Become an integral contributor to the frontend JavaScript SDK that runs on hundreds of millions of browsers worldwide\n",
      "2243 Experience with a broad range of web technologies and frameworks including modular JavaScript, HTML and CSS (7+ years)\n",
      "2244 Loving Git or other modern source control paradigms (we use Git + GitHub)\n",
      "2245 Experience with Angular, RxJS\n",
      "2246 Experience with React\n",
      "2247 Our tech stack and tools include Ruby, Python, Node, Typescript, Couchbase, Postgresql, Redis, Heroku, AWS, CircleCi, and more (and lots of bash scripts!)\n",
      "2248 Expert level programming experience in Node, Python and/or Ruby.\n",
      "2249 Expert level experience with building and optimizing data layers and pipelines using nosql databases (preferably Couchbase and Redis) sql (preferably Postgresql) and OOP models in Node/Ruby.\n",
      "2250 Strong experience in deploying web application and services in AWS and Heroku\n",
      "2251 Strong skills with Bash, Linux, and containers using Docker and Kubernetes.\n",
      "2252 Experience with integrating error tracking and logging systems like Sentry.\n",
      "2253 Experience with integrating system and application monitoring tools like New Relic, MixPanel, etc using transaction tracing across multiple services.\n",
      "2254 Built distributed infrastructure to support a variety of sql and nosql databases\n",
      "2255 Solid Experience with Apache Hadoop / Spark platforms like Hortonworks or Cloudera\n",
      "2256 Solid experience and background with Python and pySpark\n",
      "2257 Experience and expertise working with relational/non-relational databases and understanding of storage technologies (like MySQL, Sybase, MongoDB, InfluxDB, Cassandra or HBase)\n",
      "2258 Familiarity with monitoring and log management tools like Splunk, App Dynamics, App Insights, ELK\n",
      "2259 Robust object-oriented design pattern knowledge and implementation experience using one or more languages like Java, Scala or Python\n",
      "2260 Experience with web technologies like Angular 2+ (or React/Vue), TypeScript, RxJS\n",
      "2261 Experience in deployment, maintenance, and administration tasks related to Cloud (Azure, AWS, GCP or Private Cloud), OpenStack, Docker, Kafka, Airflow, Nifi and Kubernetes\n",
      "2262 Proficiency in, at least, one modern programming language such as Python, C/C++ or Java\n",
      "2263 Model development , validation and deployment using Internal Amazon tools and public services such as AWS Sage Maker for large-scale applications.\n",
      "2264 Experience with modeling tools such as R, scikit-learn, Spark MLLib, MxNet, Tensorflow, numpy, scipy etc.\n",
      "2265 Experience with large scale distributed systems such as Hadoop, Spark etc.\n",
      "2266 Experience with GCP cloud and deep understanding of cloud native and fundamentals of GCP\n",
      "2267 Experience designing and building SOA, microservices, web services, API based architectures\n",
      "2268 Languages/Tools: JavaScript, Node.JS, Kubernetes, Docker, Apigee,\n",
      "2269 Advanced working SQL knowledge and experience working with relational databases, unstructured data storage, query engines, and message queues such as Apache Kafka and Apache Pulsar.\n",
      "2270 Experience implementing large scale, fault tolerant ETL pipelines using tools like Apache Flink, Apache Spark, and Apache Beam.\n",
      "2271 Solid knowledge of at least two programming languages like Scala, Java, Python, C++, or Go.\n",
      "2272 Experience working with at least one cloud platform like AWS, Azure or GCP.\n",
      "2273 Experience with MLOps and a machine learning platform like MLFLow or Kubeflow is a plus.\n",
      "2274 Fluency in C++ and Python\n",
      "2275 Experience developing embedded Linux firmware\n",
      "2276 Full understanding of Linux Kernel and toolchains\n",
      "2277 Has built and/or configured 3rd party Linux packages\n",
      "2278 Le centre d’excellence des solutions de gestion des ressources énergétiques distribuées (CoE DERMS) d’Eaton est à la recherche d’un(e) ingénieur(e) logiciel principal(e) pour faire partie de son équipe multidisciplinaire et mondiale afin de concevoir des solutions propres à l’intégrateur en langage C++ à partir des trousses de communication d’Eaton basées sur Linux, compatibles Ethernet et multi-protocoles\n",
      "2279 Maîtrise des langages C++ et Python\n",
      "2280 Expérience en conception de micrologiciels Linux embarqués\n",
      "2281 Compréhension complète de Linux Kernel et des chaînes d’outils associées\n",
      "2282 Expérience en création ou configuration de paquets Linux de tiers\n",
      "2283 Proven and demonstrable skills developing embedded systems using the C++ programming language in a Linux or RTOS environment.\n",
      "2284 Experience with version control software (Git) and defect tracking tools (JIRA)\n",
      "2285 Experience with C++ and Boost Libraries such as ASIO and Unit Test.\n",
      "2286 Experience with Industrial control protocols, such as Modbus, CANbus etc.\n",
      "2287 Experience using cloud computing platforms (Azure) and services\n",
      "2288 Experience with IoT security implementation - Linux network device security, developing with secure network protocols, participating in, and performing security audits.\n",
      "2289 Compétences solides en développement de systèmes embarqués à l'aide du langage de programmation C++ dans un environnement Linux ou autre système d’exploitation temps-réel.\n",
      "2290 Expérience avec les logiciels de contrôle de version (Git) et les outils de suivi des bugs (JIRA)\n",
      "2291 Expérience avec les bibliothèques Boost en C++ telles que ASIO et Unit Test\n",
      "2292 Expérience avec des protocoles IP industriels (Modbus, CANbus, etc.)\n",
      "2293 Expérience dans l'utilisation de plateformes et de services de calcul de l’infonuagique (Azure)\n",
      "2294 Expérience de la mise en œuvre de la sécurité IdO - Sécurité des périphériques réseau Linux, développement de protocoles réseaux sécurisés, participation et réalisation d'audits de sécurité.\n",
      "2295 1+ years of professional experience in developing cloud-based (AWS, Azure, GCP) software solutions with a proven track record of delivering complex or algorithmically sophisticated functionality\n",
      "2296 Good skills and knowledge of best practices in at least one programming language (e.g Python, C++)\n",
      "2297 +1 for good knowledge of the Python scientific stack: Numpy, Scipy, OpenCV, Matplotlib, GDAL, etc\n",
      "2298 +1 for JupyterLab or JupyterNotebook\n",
      "2299 Familiarize yourself with the multi-cloud environment and existing distributed domain controllers within VMware platform\n",
      "2300 Experience in Python, Go, C++, or similar scripting and programming languages\n",
      "2301 Expertise in using python libraries for data science and machine learning such as: pandas, NumPy, scikit-learn, TensorFlow, etc.\n",
      "2302 Ability to demonstrate competency in development languages and tools including .NET Framework, .NET Core, C#, & Cross Platform development.\n",
      "2303 Experience with Docker & Kubernetes is an asset.\n",
      "2304 Cloud Development (AWS, Azure or comparable).\n",
      "2305 Designing, architecting, and implementing secure AWS cloud solutions by understanding client business needs and requirements then aligning technical solutions to business outcomes\n",
      "2306 8+ years in industry working as a subject matter expert in 4 or more cloud computing technology areas, with a high focus on AWS\n",
      "2307 ZScaler with ZScaler Private Access (ZPA)\n",
      "2308 Linux/Unix Multiplatform understanding\n",
      "2309 HashiCorp Terraform, Vault, and Boundary\n",
      "2310 Our tech stack and tools include Ruby, Python, Node, Typescript, Couchbase, Postgresql, Redis, Heroku, AWS, CircleCi, and more (and lots of bash scripts!)\n",
      "2311 Expert level programming experience in Node, Python and/or Ruby.\n",
      "2312 Expert level experience with building and optimizing data layers and pipelines using nosql databases (preferably Couchbase and Redis) sql (preferably Postgresql) and OOP models in Node/Ruby.\n",
      "2313 Strong experience in deploying web application and services in AWS and Heroku\n",
      "2314 Strong skills with Bash, Linux, and containers using Docker and Kubernetes.\n",
      "2315 Experience with integrating error tracking and logging systems like Sentry.\n",
      "2316 Experience with integrating system and application monitoring tools like New Relic, MixPanel, etc using transaction tracing across multiple services.\n",
      "2317 Built distributed infrastructure to support a variety of sql and nosql databases\n",
      "2318 Experience with developing software within a cloud-based environment (AWS, Azure, GCP)\n",
      "2319 Excellent knowledge in at least one high level programming language (e.g., Java, C++, Python, etc)\n",
      "2320 Excellent knowledge in RDBMS and/or NoSQL database technologies\n",
      "2321 Working knowledge of AWS or other cloud services\n",
      "2322 Working knowledge of Docker, ECS/EKS, lambda and microservice, serverless design paradigm\n",
      "2323 Highly proficient in 2+ analytical programming languages (Python, R, SAS, etc.), SQL (Teradata, Oracle, DB2, SQL Server), and multiple environments (Unix & Windows)\n",
      "2324 2+ years of experience with big data platforms / integration (Hadoop, Spark, Hive, Avro)\n",
      "2325 Word & Excel power user with demonstrated experience writing professional business cases, memos and presentations\n",
      "2326 Experience working with FICO / TSYS / CGI decision systems (TRIAD, OM, ACE, CACS)\n",
      "2327 Advanced big data administrative / optimization experience (Databricks, Min.io, YARN)\n",
      "2328 Deep knowledge of competing on-premise and public cloud platforms (Azure, Google, AWS)\n",
      "2329 Experience with traditional RDBMS databases (SQL Server, DB2) and XML schema\n",
      "2330 Comfortable with development ops platforms & tools (Kubernetes, Docker, Jenkins, Puppet)\n",
      "2331 Experience with business intelligence and visualization tools (PowerBI, Tableau)\n",
      "2332 Familiar with both traditional SDLC and agile development processes & tools (Jira, Confluence)\n",
      "2333 Good skills and knowledge of best practices in at least one programming language (e.g Python, C++, MATLAB)\n",
      "2334 +1 for good knowledge of the Python scientific stack: Numpy, Scipy, OpenCV, Matplotlib, GDAL, etc\n",
      "2335 +1 for JupyterLab or JupyterNotebook\n",
      "2336 Experience developing and debugging complex distributed software deployed within a cloud-based environment (AWS, Azure, GCP)\n",
      "2337 Excellent knowledge in at least one high level programming language (e.g., Java, C++, Python, etc)\n",
      "2338 Excellent knowledge in RDBMS and/or NoSQL database technologies\n",
      "2339 Working knowledge of AWS or other cloud services\n",
      "2340 Working knowledge of Docker, ECS/EKS, lambda and microservice, serverless design paradigm\n",
      "2341 You will also have the opportunity to use many cutting-edge technologies including Go, Kubernetes, GKE, HBase, Kafka, and Hadoop.\n",
      "2342 Knowledge of one or more of Go, C, C++, Python, Java\n",
      "2343 Familiar with, or have a strong desire to learn, the latest tools and technologies, including Kubernetes, Kafka, HBase, and more\n",
      "2344 DAL is based on Cosmos DB\n",
      "2345 Deliver scalable and reliable data solutions leveraging AKS, Docker, Kafka, Kibana/Elastic Search, Scala/AKKA framework/SPARK\n",
      "2346 Hypervisors such as VMware , Hyper-V\n",
      "2347 Networking and Cloud Networks\n",
      "2348 Experience with Confluence, Jira, Experience with Unreal Engine, Unreal Editor, and Blueprints\n",
      "2349 Development experience with Python\n",
      "2350 Knowledge of Linux and bash\n",
      "2351 Experience administrating Hadoop or Spark\n",
      "2352 2+ years of experience with AWS stack (VPC, EC2, S3, KMS, ECR, IAM, Lambda, CloudWatch)\n",
      "2353 5+ years of hands on experience with Java\n",
      "2354 Experience in distributed systems and big data technologies (Hadoop, ZooKeeper, etc.)\n",
      "2355 Strong debugging skills in Linux environment for solving performance issues.\n",
      "2356 o Flink and / or Spark Streaming\n",
      "2357 o AWS\n",
      "2358 o Terraform\n",
      "2359 Proficient in MS Office Software\n",
      "2360 Experience writing secure and efficient restful APIs (NodeJS / ExpressJS)\n",
      "2361 Experience creating frontends with a modern frontend JS Framework (VueJS, Angular or React)\n",
      "2362 Must love HTML 5, CSS 3, and beautiful, logical UIs\n",
      "2363 Proficient and quick with CSS/SASS/SCSS/LESS\n",
      "2364 Experience with Bootstrap or other UI frameworks\n",
      "2365 Knowledge of Google Cloud Platform components\n",
      "2366 Understanding of NoSQL DBs, Firebase/store, BigQuery\n",
      "2367 Previous experience with Conversational AI tools: DialogFlow, RASA NLU, Microsoft LUIS, Amazon Lex\n",
      "2368 Node.js: 2 years (Preferred)\n",
      "2369 Vue.js: 2 years (Preferred)\n",
      "2370 React.js: 2 years (Preferred)\n",
      "2371 Autonomous Systems: C/C++, MAVLINK, PX4, ROS/ROS2, and knowledge of control theory including the extended Kalman filter;\n",
      "2372 Low Level Optimization: Bash, C/C++, CUDA, Gstreamer, and knowledge of the Linux kernel, including camera and other device drivers;\n",
      "2373 Machine Vision: C/C++, CUDA, cuDNN, OpenCV, Python, ROS/ROS2, and knowledge of machine vision, including visual inertial odometry\n",
      "2374 Web Services: Django, Python, and knowledge related to information security, network optimization, and Internet of Things.\n",
      "2375 Managing private deployments of GitLab, Mayan EDMS, Wagtail, and more;\n",
      "2376 Configuration management and automation tools, such as Ansible\n",
      "2377 Databases, particularly MySQL and PostgreSQL\n",
      "2378 CUDA\n",
      "2379 Linux kernel configuration and hacking\n",
      "2380 Postgres (v10+) ( >1yr experience) – mandatory requirement\n",
      "2381 Competent programming skill with either Python or R – mandatory requirement\n",
      "2382 Familiarity with AWS ecosystem\n",
      "2383 Familiarity with Linux (any distribution)\n",
      "2384 Experience with git and docker\n",
      "2385 Postgres administration experience\n",
      "2386 Familiarity with PostGIS\n",
      "2387 Experience with AWS services: RDS, Lambda, CloudFormation, Athena\n",
      "2388 Linux system administration experience\n",
      "2389 Bash scripting\n",
      "2390 Postgres (v10+): 1 year (Required)\n",
      "2391 Python or R: 1 year (Required)\n",
      "2392 · 5 years proven commercial Javascript experience\n",
      "2393 · Strong understanding of Node.JS\n",
      "2394 · Experienced with Express, Passport, Socket.IO, Jest and jsDoc\n",
      "2395 · Working knowledge of SQL and NonSQL (ideally PostgreSQL and MongoDB)\n",
      "2396 · Working experience with versuib /cibtrik (Giblab, GIT, etc)\n",
      "2397 Thorough understanding of HTML5\n",
      "2398 Basic understanding of CSS\n",
      "2399 Experience with LeafletJS and / or GoogleMaps\n",
      "2400 Ability to show examples of prior work, or have working projects on Git, Gitlab, etc.\n",
      "2401 commercial javascript: 5 years (Preferred)\n",
      "2402 Ideally, (basic) programming skills (HTML5 / CSS, Obj-C, Swift, Java, C++)\n",
      "2403 Developing comprehensive (Web, iOS, Android) intuitive user experiences\n",
      "2404 Development of cross-platform, intuitive user experiences for our products (Web, iOS, Android).\n",
      "2405 2 years minimum experience UX/UI design work on native iOS apps\n",
      "2406 You are familiar with tools such as Sketch or Figma and the Adobe classics\n",
      "2407 Build Senior and C-level relationships by establishing contact, nurture and develop relationships with senior leaders and executives within target accounts and industries\n",
      "2408 3 years experience with AWS Cloud services, including ECS, ECR, RDS, IAM, etc.\n",
      "2409 Experience working with at least one of the following languages: Python, JavaScript/TypeScript, Go or R.\n",
      "2410 Good hands-on knowledge of Configuration Management and Deployment tools like Terraform, CloudFormation and Ansible\n",
      "2411 Clear understanding of networking technologies including CDNs, Routers, Load Balancers, Firewalls, WAF and DNS.\n",
      "2412 Proficient in scripting Git/GitLab workflows\n",
      "2413 AWS Cloud Services, including ECS, ECR, RDS, IAM: 3 years (Required)\n",
      "2414 Experience Developing with Python;\n",
      "2415 Comfort using Scikit_learn, TensorFlow, NumPy, Matplotlib;\n",
      "2416 Knowledge of C or C++, Dask, and/or Spark will be considered assets;\n",
      "2417 Experience with Python and Google Cloud Platform\n",
      "2418 3+ years of leading automation delivery lifecycles with IA tools like BluePrism, UiPath, Automation Anywhere, Workfusion, Hyperscience, ABBY\n",
      "2419 Experience with Python web frameworks such as Django, Django Rest Framework\n",
      "2420 Experience with Google Cloud Platform\n",
      "2421 Experience with automation using either Shell scripting, Python or other similar languages\n",
      "2422 Google Cloud Platform: 2 years (Preferred)\n",
      "2423 python: 5 years (Preferred)\n",
      "2424 Experience working in SharePoint\n",
      "2425 Understanding of Machine Learning theory (an asset)Knowledge of Python or R programming languages\n",
      "2426 Knowledge of Big Data / relational db tools: Spark, Hadoop, Snowflake, Oracle (an asset)\n",
      "2427 Knowledge of Qgis and Arcgis online, or similar tools (asset)\n",
      "2428 Experience working with Epic\n",
      "2429 4+ years’ experience building software solutions in a corporate or start up engineering environment using any or all of the following: full-stack Java, Python, JavaScript, PHP, Ruby, C++, or related technologies\n",
      "2430 2+ years’ experience developing web and mobile applications (iOS or Android)\n",
      "2431 2+ years’ of front end technologies ranging from HTML, CSS, React / Ember / Angular, etc\n",
      "2432 Experience with client-side JavaScript frameworks such as Angular or React\n",
      "2433 Experience with web frameworks such as Django\n",
      "2434 Software engineering experience in Python\n",
      "2435 Experience with data processing engines such Spark or Beam\n",
      "2436 Programming knowledge (VBA/Python) would be an asset\n",
      "2437 You would harness key IA platforms such as ABBYY, AWS, Automation Anywhere, Blue Prism, Celonis, GCP, Microsoft, UiPath and others, to address the challenges and automation ambitions of our clients and deliver results\n",
      "2438 Who has leveraged at least 3 out of these 2 components: Azure Data Factory, Azure Event Hub, Databricks\n",
      "2439 With 1+ years of hands-on experience with data ingestion on Azure\n",
      "2440 Ability to interact with all levels of an organization (from C-level to technical specialists);\n",
      "2441 3+ years of hands-on experience with Python.\n",
      "2442 Experience building software solutions in a corporate or start up engineering environment using any or all of the following: Python, Java, JavaScript, PHP, Ruby, C++, or related technologies\n",
      "2443 Experience developing web and mobile applications (iOS or Android)\n",
      "2444 Experience with end technologies ranging from HTML, CSS, React / Ember / Angular, etc\n",
      "2445 Experience with SAP or Navision\n",
      "2446 Hands-on experience with big data technologies (e.g., Hadoop/Spark) and scalable realtime systems that process stream data\n",
      "2447 Strong knowledge in Java, Scala or Python\n",
      "2448 Frontend development with React.js.\n",
      "2449 Programming Languages: Javascript, HTML, CSS, Java.\n",
      "2450 Experience with any RDBMS, MySQL preferred.\n",
      "2451 Experience with git.\n",
      "2452 Experience in building applications with React and Spring.\n",
      "2453 Computer skills (Microsoft Office suite, Salesforce, SAP, Google suite)\n",
      "2454 Knowledge of SQL, VBA languages\n",
      "2455 Knowledge of BI tools (Power BI and Tableau)\n",
      "2456 Excellent knowledge of Microsoft Office suite (PowerPoint, Word, Excel)\n",
      "2457 Proficient knowledge of Microsoft Office tools Excel, Word, PowerPoint, and Outlook\n",
      "2458 Experience with one or more general purpose programming languages including but not limited to: Python, Scala, Java, C, C++\n",
      "2459 Experience with one or more frameworks such as Tensorflow, Keras, Apache Beam, Spark\n",
      "2460 Python proficiency\n",
      "2461 python: 5 years (Required)\n",
      "2462 Fluency in one of the following general-purpose programming languages: JavaScript/TypeScript, Python, or Go\n",
      "2463 Fluency in open-source analytics tools (Pandas, scikit-learn, R-Studio, TensorFlow, etc.)\n",
      "2464 Fluency in one of the following interface design tools: AdobeXD, Figma, or Sketch\n",
      "2465 Advanced skills in data analysis, report authoring, and supporting enterprise tools (SSMS, SSAS, Tableau, Alteryx, Power BI, SQL Server, Excel, etc.)\n",
      "2466 Software development experience in C++ or C.\n",
      "2467 Technically proficient in the computer environment and a working knowledge of various applications (programming knowledge in Python and R, and knowledge of applications of data analytics, machine learning, and artificial intelligence in finance are highly desirable).\n",
      "2468 Scripting skill and experience using languages such as Tcl, Python, and/or Perl.\n",
      "2469 Hive / Hadoop/ Spark) & cloud technologies (e.g\n",
      "2470 AWS Sagemaker, AzureML).\n",
      "2471 SQL, Python, R, SAS, SPSS, , Perl) and machine learning /deep learning algorithms/packages (e.g\n",
      "2472 XGBoost, H2O, SparkML).\n",
      "2473 Programming experience with at least one modern language such as , C++, or including object-oriented design\n",
      "2474 Expert knowledge of one of the following programming languages: , C, and C++\n",
      "2475 Experience using Salesforce.com, ZoomInfo, and other relevant tools\n",
      "2476 Understanding of Machine Learning theory (an asset)Knowledge of Python or R programming languages\n",
      "2477 Knowledge of Big Data / relational db tools: Spark, Hadoop, Snowflake, Oracle (an asset)\n",
      "2478 Love and hate for at least 2 client-side JavaScript framework jQuery, Angular, React, Vue\n",
      "2479 Expertise in ReactJS\n",
      "2480 Experience in microservices architecture and patterns, container technology, Kubernetes is a plus\n",
      "2481 Strong skills in using modern software practice and tools such as git, Jenkins, containers\n",
      "2482 Strong expertise in at least 2 languages such as Java, Python, Go-lang, Javascript, Rust\n",
      "2483 RX, TX, PLL, etc…)\n",
      "2484 Verification tools: ICV, Calibre, Star-RCXT, PERC\n",
      "2485 Experience in working with Jira/Atlassian (or other such) tools\n",
      "2486 TCL, PERL, etc…)\n",
      "2487 PMI, Agile/Scrum/Kanban), proficiency using Project Management Tools including MS Office products (Excel, Work, PowerPoint), JIRA, Confluence and MS Project and strong understanding of Product/Project/Software Development Life Cycle\n",
      "2488 Familiarity with 3rd & 4th generation scripting languages & platforms (R, JavaScript, Python etc) and Big data will be considered assets\n",
      "2489 Familiarity with Google Cloud Platform (GCP) frameworks a plus\n",
      "2490 Good understanding of the current mobile ecosystem and mobile technology (Android/iOS development)\n",
      "2491 Development experience in iOS and/or Android platforms\n",
      "2492 Knowledge of OAuth 2.0, OIDC, SAML, JWT, API Keys\n",
      "2493 Exceptional communication and presentations skills that build confidence and credibility with C and VP-level executives.\n",
      "2494 RX, TX, PLL, etc…)\n",
      "2495 Verification tools: ICV, Calibre, Star-RCXT, PERC\n",
      "2496 Experience in working with Jira/Atlassian (or other such) tools\n",
      "2497 TCL, PERL, etc…)\n",
      "2498 NodeJS (Typescript), Python, C++\n",
      "2499 Kubeflow: a scalable machine-learning toolkit\n",
      "2500 Distributed SQL, PostgreSQL, Redis, Azure-managed databases\n",
      "2501 Container builds on Docker, deployments to Kubernetes and Serverless Compute\n",
      "2502 CI/CD process built around Gitlab and code analysis tools like SonarQube\n",
      "2503 ReactJS, NodeJS (Typescript)\n",
      "2504 3+ years experience with one or more programming or scripting languages such as Python, C++, NodeJs\n",
      "2505 3+ years experience with SQL and NoSQL Databases\n",
      "2506 Familiarity with messaging tools and platforms such as Kafka, Kinesis, EventHub, RabbitMQ\n",
      "2507 Expertise and hands-on experience with containers and container orchestration technologies such as Docker and Kubernetes\n",
      "2508 Use of infrastructure as code tools such as Terraform a plus\n",
      "2509 Experience with one of AWS, Azure, or Google Cloud\n",
      "2510 Very significant experience designing, building and maintaining enterprise applications with Python (or other common backend language) and browser-side Javascript.\n",
      "2511 Avigilon, a Motorola Solutions company, designs, develops, and manufactures advanced AI, video analytics, network video management software and hardware, surveillance cameras, and access control solutions that help change the way people interact with their security systems.\n",
      "2512 Developing and maintaining our automated build, configuration management and deployment / installation tools supporting support multiple product lines – Windows, Linux and Cloud.\n",
      "2513 5+ years of experience with Python or equivalent scripting languages (shell scripts, Python, PowerShell, etc.)\n",
      "2514 Proven experience with source code management tools C++ development environment using gcc and Visual Studio\n",
      "2515 Experience with scripting in Python, Bash, Powershell\n",
      "2516 Experience with version control systems (Mercurial, or similar)Git, etc.) and build tools (Make, or similar)\n",
      "2517 Experience with the following tools would be considered an asset: Atlassian tool suite (Jira, Bamboo, Confluence, BitBucket), Incredibuild, Mercurial Artifactory, Buildbot, Bitbucket / Jenkins, Azure DevOps, Docker\n",
      "2518 Experience with open source automation frameworks such as JUnit, Selenium or others.\n",
      "2519 Black Box / Grey Box testing experience in testing product API (Java)\n",
      "2520 Knowledge of Jenkins/Team City, Git/Bitbucket and Artifactory a plus.\n",
      "2521 Testing experience with XML technologies (XML, XSL, XSD, DOM, SAX)\n",
      "2522 Testing experience with SQL and database technologies (e.g., SQL Server, MySQL, Oracle, etc.\n",
      "2523 Experience testing software in both Unix, Linux, and Windows systems\n",
      "2524 Knowledge of Jira is desirable\n",
      "2525 Experience with Linux and Windows scripting is a plus\n",
      "2526 Experience with SOA, Web Services and SOAP is desirable\n",
      "2527 Prior experience using Selenium is a plus\n",
      "2528 Someone who can take an UX design or wireframes and turn it into fully functional applications utilizing standards compliant HTML, CSS, and JavaScript.\n",
      "2529 Someone who can take an UX design or wireframes and turn it into fully functional applications utilizing standards compliant HTML, CSS, and JavaScript.\n",
      "2530 You will develop web applications for customers, partners and our employees, utilizing current JavaScript frameworks like React\n",
      "2531 You know JavaScript and CSS inside out.\n",
      "2532 Deep knowledge of React and related libraries\n",
      "2533 You know Docker and/or Kubernetes\n",
      "2534 Perform analytics by gathering and analyzing available data from CMMS (SAP Plant Maintenance) and other sources in Excel and other tools using bigdata and data science principles; develop automated Key Performance Indicator (KPI) dashboards and tracking tools using Microsoft PowerBI\n",
      "2535 Advanced software skills in Word, Excel, PowerPoint, Visio and programming languages such as VBA/SQL/Python is required\n",
      "2536 Experience with Microsoft PowerBI is an asset\n",
      "2537 As the Technical Lead for our Cloud Platform Team you will lead the design, and implementation of these cloud-based data processing frameworks, running on AWS, leveraging Kubernetes, and use the Spark data processing platform.\n",
      "2538 Deep knowledge of data processing applications and have used Spark (AWS EMR, Databricks)\n",
      "2539 Experience with the AWS Cloud Data Services (Kinesis, DynamoDB, S3, Athena,...)\n",
      "2540 You have programmed in Python and preferably in Java too\n",
      "2541 Knowledge of containerized apps and deployment orchestration (Kubernetes)\n",
      "2542 As a Principle Software Developer on the Avigilon Cloud Services team, you will help us architect and build new features, enhance our existing software, tools, and experiences to help delight our customers by extending our application capabilities and enhancing the existing AI technologies we use\n",
      "2543 If you’re someone who has developed Microsoft .NET applications, and is also comfortable working with other technology platforms such as JavaScript and React – come join our team!\n",
      "2544 This role is part of the Engineering platform organization where we work with the latest cloud and networking technologies, such as Azure / Docker / Kubernetes / Terraform / Microservices etc\n",
      "2545 We contribute to Avigilon Cloud's success by producing software, services and API's that are robust, reliable and scalable\n",
      "2546 If you’re someone who has developed cloud applications, are an expert in .NET and have a firm grasp of micro-services – come join our team!\n",
      "2547 7+ years of software design and development experience in at least one of the following languages: C#, .Net Core, Java.\n",
      "2548 Computer skills - Email: Outlook and MSN, Intranet/Internet, Microsoft Excel, Microsoft Word\n",
      "2549 Your customers leverage state-of-the-art technologies on AWS to innovate and become the next disrupters, like today’s AirBnB, Slack, DoorDash, and Lyft\n",
      "2550 Create & articulate compelling value propositions around AWS services.\n",
      "2551 Vos clients tirent parti des technologies de pointe sur AWS pour innover et devenir les prochains perturbateurs, comme AirBnB, Slack, DoorDash et Lyft\n",
      "2552 Your daily life will involve python programming (Flask, Tensorflow serving) along with some SQL and devops operations (GCP, Kubernetes)\n",
      "2553 As part of the artificial intelligence team, if you want to learn about Tensorflow, machine learning and how to apply it to sport, we’ll be more than happy to teach you!\n",
      "2554 Skills in Python (Flask, Tensorflow Serving), bash script and bonus points if you have previous experience in java or scala\n",
      "2555 Experience in SQL, postgresql and big data\n",
      "2556 Experience with cloud computing, such as AWS or GCP and container tools like Docker and Kubernetes\n",
      "2557 Bonus point if you are familiar with frontend techniques, such as HTML, CSS, JavaScript and jQuery.\n",
      "2558 MS Excel - Prepare cost spreadsheets\n",
      "2559 Mettre en œuvre de nouveaux algorithmes, recettes et prototypes, en utilisant Python/Lua et des outils d'apprentissage profond standard (TensorFlow, Fairseq, ou similaire)\n",
      "2560 Excellentes compétences en programmation Python avec connaissance des structures de données et des algorithmes standard\n",
      "2561 Expérience significative de l'utilisation d'Unix/Linux et des scripts shell\n",
      "2562 Connaissance du travail avec des conteneurs (Docker/Singularity)\n",
      "2563 Développement de logiciels avec le GitLab\n",
      "2564 Expertise en matière de boîtes à outils d'apprentissage approfondi, telles que TensorFlow ou Fairseq\n",
      "2565 Implement new algorithms, recipes, and prototypes, utilizing Python/Lua and standard deep learning toolkits (TensorFlow, Fairseq, or similar)\n",
      "2566 Excellent Python programming skills with knowledge of standard data structures and algorithms\n",
      "2567 Significant experience using Unix/Linux and shell scripting\n",
      "2568 Knowledge of working with containers (Docker/Singularity)\n",
      "2569 Software development with GitLab\n",
      "2570 Expertise with deep learning toolkits, such as TensorFlow or Fairseq\n",
      "2571 Expérience avec un cadre d'apprentissage approfondi comme Tensorflow ou PyTorch\n",
      "2572 Bonnes compétences en programmation ; expérience avec Python\n",
      "2573 Travailler confortablement sous Unix/Linux\n",
      "2574 Experience with a deep learning framework like Tensorflow or PyTorch\n",
      "2575 Good programming skills; experience with Python\n",
      "2576 Comfortable working in Unix/Linux\n",
      "2577 Do you have experience with SQL, Microsoft Azure and Python? Are you an experienced Business Intelligence Specialist and/or Data Warehouse Specialist? The Provincial Health Services Authority (PHSA) is seeking a collaborative Business Intelligence Data Developer to collaborate with the supply chain team, which handles provincial procurement data amounting to $1.7 billion in annual spending.\n",
      "2578 Experience with Microsoft cloud technologies is a plus.\n",
      "2579 Experience using computerized financial applications and systems such as PeopleSoft, Oracle, SAP, Unit4 and Cerner as well as Power BI and Data Visualization tools.\n",
      "2580 UiPath, BluePrism, Pega experience is nice to have\n",
      "2581 · 5+ years’ experience in any of the programming languages like C/C++, Python, VB Script, Ruby, Java, JS, .Net.\n",
      "2582 · Basic programming knowledge on HTML, Python, JavaScript (or any scripting language).\n",
      "2583 · Experience with Databases (SQL or NoSQL) often preferred.\n",
      "2584 Experience developing data-driven Analytics models using at least one of the following programming languages: Python, R, or equivalent.\n",
      "2585 Familiarity with machine learning frameworks (like Keras or PyTorch) and libraries (like sci-kit-learn).\n",
      "2586 You have hands-on experience with AI or ML pipelines (AirFlow, Kafka, etc...).\n",
      "2587 Clearly document issues and remediation of requests in our service desk software (JIRA).\n",
      "2588 Installation, configuration and maintenance of third-party tools such as Anti-Virus, Windows OS updates, web browsers and Adobe products.\n",
      "2589 Manage mobile devices in an Office 365 environment (iPhones, iPads, Samsung devices).\n",
      "2590 Knowledge of Microsoft Operating Systems and services (Windows 10, MS Office Suite)\n",
      "2591 Knowledge of Discord, Zoom, Devpost, Github, and Slack\n",
      "2592 Experience using Python and/or R\n",
      "2593 Knowledge of SparkML\n",
      "2594 Knowledge and experience of writing and tuning SQL\n",
      "2595 Understand the customer’s business need and guide them to a solution using our AWS AI Services, AWS AI Platforms, AWS AI Frameworks, and AWS AI EC2 Instances .\n",
      "2596 Use Deep Learning frameworks like MXNet, Caffe 2, Tensorflow, Theano, CNTK, and Keras to help our customers build DL models.\n",
      "2597 Use SparkML and Amazon Machine Learning (AML) to help our customers build ML models.\n",
      "2598 Good skills with programming languages, such as Java or C/C++\n",
      "2599 Experience with AWS technologies like Redshift, S3, EC2, Data Pipeline, & EMR\n",
      "2600 Experience programming in Python, C++ and using popular machine learning frameworks\n",
      "2601 Experience in CUDA/OpenCL.\n",
      "2602 Experience working with GPUs/FPGAs.\n",
      "2603 Expertise in one of the trending search technologies such as Elastic Search/ SOLR/ Lucene / Coveo / Algolia or other related technologies\n",
      "2604 6 to 10 years of software development experience using Java/.NET/JavaScript/Python and/or other core languages across the technology industry\n",
      "2605 Strong skills managing Search Tool, integrating data collection, visualization, analysis, logging and storage\n",
      "2606 Stronghold on SQL & No-SQL databases\n",
      "2607 The in-depth technical expertise of any of Elastic Search, Apache Solr, Coveo, Algolia or Apache Lucene or similar trending search technologies is nice to have\n",
      "2608 Hands-on experience in Logstash, Kibana, Machine Learning, Kafka & Grafana will be a great asset.\n",
      "2609 Front-end & Server-side programming technologies\n",
      "2610 Working experience or fundamental knowledge of Angular/Reactjs or similar frontend technologies is much appreciated.\n",
      "2611 Managing code and changes in a team environment to include experience with source control utilities, such as Git/ Microsoft TFS/ Perforce\n",
      "2612 Experience with XML/JSON processing and transformations (XPath, XSLT, etc.)\n",
      "2613 Cloud technology experience: AWS, Azure\n",
      "2614 Working experience of Docker is good to have\n",
      "2615 Helping build machine learning models and deploy them to solve business problems using cloud platforms like Azure and Databricks\n",
      "2616 Writing clean and concise code in languages such as Python/R\n",
      "2617 Proficiency in programming languages especially Python/R\n",
      "2618 Preference is for Python\n",
      "2619 Working knowledge of creating dashboards using Power BI\n",
      "2620 Knowledge of Slack, Discord, and Zoom\n",
      "2621 Angular JS/React\n",
      "2622 Java\n",
      "2623 Spring/Hibernate\n",
      "2624 Spring boot, Microservices\n",
      "2625 Oracle/SQL,\n",
      "2626 Json, XML, GIT\n",
      "2627 CPU: Intel i5 or higher (or its AMD equivalent)\n",
      "2628 Our application is built using Python/Django, Typescript/Angular, and we leverage Docker in all environments from development through to production (AWS ECS/ECR).\n",
      "2629 Experience building RESTful APIs and have experience with Python.\n",
      "2630 Angular, React, etc.).\n",
      "2631 Comfort and preference for working in a Linux environment.\n",
      "2632 Experience using Docker is an advantage.\n",
      "2633 Experience with and knowledge of SQL (PostgreSQL a plus).\n",
      "2634 Utilisateur expérimenté de l'informatique, capable de se familiariser rapidement avec les nouveaux outils MS Windows.\n",
      "2635 Familiarité avec Linux et les scripts Shell.\n",
      "2636 Familiarité avec Jira et Confluence.\n",
      "2637 Experienced computer user, able to quickly become familiar with new MS Windows tools.\n",
      "2638 Familiarity with Linux and shell scripting.\n",
      "2639 Familiarity with jira and confluence.\n",
      "2640 Utilisation et gestion de Jira et Sharepoint.\n",
      "2641 Use and management of Jira and Sharepoint.\n",
      "2642 Familiarity with MS Office and G-Suite, especially Excel/Google Sheets\n",
      "2643 Compétences en programmation avec au moins un des langages suivants : Python/Java/Perl ;\n",
      "2644 Unix/Linux\n",
      "2645 Programming skills with at least one of following languages: Python/Java/Perl;\n",
      "2646 Unix/Linux\n",
      "2647 Travailler avec une boîte à outils interne de modélisation linguistique basée sur TensorFlow et Fairseq et l'étendre si nécessaire\n",
      "2648 Expérience avec des outils d'apprentissage approfondi tels que TensorFlow et Fairseq\n",
      "2649 Bonnes compétences en programmation ; expérience avec Python\n",
      "2650 Expérience de travail dans un environnement informatique Unix/Linux avec des emplois distribués\n",
      "2651 Work with an internal TensorFlow and Fairseq-based language modeling toolkits and extend as necessary\n",
      "2652 Experience with deep learning toolkits such as TensorFlow and Fairseq\n",
      "2653 Good programming skills; experience with Python\n",
      "2654 Experience working in a Unix/Linux computing environment with distributed jobs\n",
      "2655 Demonstrated ability to work in a computerized environment using Word, Excel, Outlook, Banner (FIS), Minerva, POPS and Crystal Reports\n",
      "2656 Experience with Java, JavaScript, J2EE, CSS and related technologies\n",
      "2657 Working knowledge and understanding of the following: Apache, App server logs, RESTful web services, Javascript and jQuery\n",
      "2658 Experience with cross-browser and cross-platform issues (IE, Firefox, Safari, etc.)\n",
      "2659 Familiarity with basic Linux or Unix concepts and commands\n",
      "2660 Develop APIs for applications built on top of TAC™ in Python frameworks\n",
      "2661 Implement best practices for code quality assurance and automated testing of our applications using, for example, pytest, mypy, flake, black, pre-commit, and related libraries\n",
      "2662 Support the integration and deployment of backend microservices by using tools, such as, Docker, Terraform, and Ansible\n",
      "2663 Experience using web development frameworks such as Django to develop RESTful APIs\n",
      "2664 Exposure to the following a plus: Django, Tornado, Flask, FastAPI, SQLAlchemy, databases (SQL/non-SQL), Docker/docker-compose, IT automation (Ansible), Celery, Plotly, Terraform, RabbitMQ, Authentication standards such as OAuth2, Poetry, Conda\n",
      "2665 Experience and knowledge in Python language (C++ as a bonus)\n",
      "2666 Working knowledge of source control systems, PyQt or other GUI toolkit\n",
      "2667 Experience in, Ziva, Maya, Mari, Nuke, XSI considered a bonus\n",
      "2668 Experience with UX tools such as Figma and/or Sketch\n",
      "2669 Versatile designer, who has ability to execute a variety of deliverables, even using out of non-traditional design tools such as Microsoft PowerPoint and Word\n",
      "2670 Monitor pests and diseases on greenhouse crops, such as Spider mites, Aphids, Thrips, Botrytis, Pythium, Fusarium, etc.\n",
      "2671 Excellent computer skills including experience using MS Office, MS Project or other scheduling and project management software\n",
      "2672 Experience working with Confluence/Jira and associated apps\n",
      "2673 Strong computer skills in Microsoft Office suite specifically Excel.\n",
      "2674 Ability to clean, transform, and merge your own data in a procedural language like Python or R\n",
      "2675 Experience developing software in traditional programming languages (C++, Java, etc..)\n",
      "2676 Développer et mettre à jour notre application web React\n",
      "2677 Documenter et tester avec Jest, Enzyme et Cypress.\n",
      "2678 Solides connaissances en Javascript, le DOM et le CSS\n",
      "2679 Solides connaissances de l’écosystème React\n",
      "2680 Expérience avec des solutions CSS-in-JS telles que styled-components\n",
      "2681 Expérience avec Redux\n",
      "2682 Familiarité avec Git et le développement Agile.\n",
      "2683 Document and test using Jest, Enzyme and Cypress.\n",
      "2684 Deep knowledge of Javascript, the DOM & CSS\n",
      "2685 Deep knowledge of the React ecosystem\n",
      "2686 Experience with CSS-in-JS solutions such as styled-components\n",
      "2687 Experience with Redux\n",
      "2688 Familiarity with Git and Agile development\n",
      "2689 Basic/Intermediate graphic design skills and video experience, using Adobe Creative Suite (Illustrator, Photoshop, Spark, After Effects, Media Encoder) and Canva\n",
      "2690 Advanced knowledge of Microsoft Office (Word, Excel, PowerPoint, Outlook), and Google GSuite, and Google AdWords\n",
      "2691 Familiar with social listening tools such as Hootsuite, Asana and Zoho Social\n",
      "2692 Working knowledge of CSS and & HTML\n",
      "2693 Experience with TCL, Perl, C, Python, MATLAB, or other scripting languages is desired.\n",
      "2694 Connaissance avancée de Microsoft Excel et capacité à communiquer des données et des idées complexes au moyen de présentations Microsoft PowerPoint\n",
      "2695 Excel : connaissance avancée d'Excel et capacité à utiliser Excel comme outil d'analyse, de modélisation, de visualisation et de statistiques des données.\n",
      "2696 JIRA : capacité à utiliser des systèmes de gestion de projet comme JIRA pour conduire des demandes de gestion de changement, y compris la capacité à rédiger un ticket technique, à fournir des exigences et des étapes de validation, à fournir une direction et une clarté tout au long du processus de développement, et à valider que les changements effectués répondent aux exigences initiales.\n",
      "2697 PowerPoint : compétences avancées en PowerPoint et capacité à utiliser l'outil pour créer des documents de données élégants, robustes et visuellement attrayants qui seront utilisés comme méthode clé pour communiquer les performances et les opportunités du programme à différents niveaux des parties prenantes du client.\n",
      "2698 MS Office avancé, y compris PowerPoint et Excel\n",
      "2699 Intermédiaire JIRA\n",
      "2700 Intermédiaire Google/Adobe Analytics\n",
      "2701 Advanced knowledge of Microsoft Excel and the ability to communicate complex data and ideas through Microsoft PowerPoint presentations\n",
      "2702 Excel: advanced Excel knowledge and ability to utilize Excel as a data analysis, modeling, visualization and statistical tool.\n",
      "2703 JIRA: ability to utilize project management systems like JIRA to drive change management requests, includes the ability to write a technical ticket, provide requirements and validation steps, provide direction and clarity throughout the development process, and validate that changes made meet initial requirements.\n",
      "2704 PowerPoint: advanced PowerPoint skills and the ability to utilize the tool to create elegant, robust, and visually appealing data-driven materials to be used as the key method of communicating program performance and opportunities to various levels of client stakeholders.\n",
      "2705 Advanced MS Office including PowerPoint and Excel\n",
      "2706 Intermediate JIRA\n",
      "2707 Intermediate Google/Adobe Analytics\n",
      "2708 Programmation en Python ou Perl\n",
      "2709 Programmation C/C\n",
      "2710 Python or Perl programming\n",
      "2711 C/C++ programming\n",
      "2712 Experience with Angular 2+, JQuery and Bootstrap, .NET 3.5/4.6 Framework, including Visual Studio 2017 C#, ASP.NET, MVC, WCF Web Services, ADO.NET, LINQ and Entity Framework.\n",
      "2713 Progress and issue tracking and assigning tasks in JIRA\n",
      "2714 Proficiency with Altium Designer (preferred), OrCAD, PADS\n",
      "2715 FW development in C/assembly.\n",
      "2716 Utilisation et gestion de Jira et Sharepoint.\n",
      "2717 Use and management of Jira and Sharepoint.\n",
      "2718 Experience with PLM Software such as Omnify\n",
      "2719 Experience with high-speed interfaces such as PCI Express Gen3, 3G-SDI, DisplayPort, GigE or 10GigE LAN.\n",
      "2720 Knowledge of Linux operating systems.\n",
      "2721 Familiarity with design software (Cadence, Solidworks, Vivado) an asset\n",
      "2722 Experience with SAP Business one or other logistics software.\n",
      "2723 Experience with NVIDIA, AMD, CUDA or OpenCL.\n",
      "2724 Ability to navigate, manipulate files and use tools in a linux environment considered an asset\n",
      "2725 Previous experience using WFM tools (Aspect, Avaya, etc.)\n",
      "2726 Proficiency in creating reports with SQL, SSRS/SSIS/SSAS\n",
      "2727 Ability to create reports with MS Access, SAS, business intelligence tools, PowerBI, Crystal Report, etc.\n",
      "2728 Previous experience using design tools like Botmock, Botsociety, MS Visio, Lucid chart is a benefit.\n",
      "2729 Previous experience in deploying Voice Assistants on Actions on Google, Amazon Alexa,or creating conversational IVR experiences via common IVR systems (Amazon Connect, Nuance, Genesys PureCloud, Genesys PureConnect, Avaya,NICE inContact, etc.)\n",
      "2730 Knowledge of the Microsoft Office, particularly Word, Excel, Outlook and PowerPoint.\n",
      "2731 Domain-knowledge: High-Speed serial communication standards like USB, PCI-Express, SATA, XAUI, etc.., with full understanding of functional partitioning between protocol layers.\n",
      "2732 Analog design/simulation, Matlab\n",
      "2733 Solid experience working with data science cloud solutions and cloud infrastructures (AWS, Azure, GCP)\n",
      "2734 Proficient in deep learning frameworks like Tensorflow, PyTorch, etc\n",
      "2735 and scientific computing packages like NumPy\n",
      "2736 Proficient in Python and/or C/C++, with an interest in learning new languages.\n",
      "2737 Familiarity with source control (Git) and Unix systems, including shell scripting.\n",
      "2738 Experience in using cloud solutions, preferably AWS.\n",
      "2739 An active GitHub repository.\n",
      "2740 Advanced level of proficiency in Microsoft Office (Word, Excel, Outlook, PowerPoint)\n",
      "2741 Knowledge and experience with Microsoft .Net Core and C#\n",
      "2742 Knowledge and experience with MS SQL and other relational and non-relational databases\n",
      "2743 Practical experience with React, HTML5, CSS3, JavaScript, TypeScript\n",
      "2744 Experience with source code control frameworks (Git).\n",
      "2745 Develop APIs for applications built on top of TAC™ in Python frameworks\n",
      "2746 Implement best practices for code quality assurance and automated testing of our applications using, for example, pytest, mypy, flake, black, pre-commit and related libraries\n",
      "2747 Support the integration and deployment of backend microservices by using tools, such as, Docker, Terraform and Ansible\n",
      "2748 Experience using web development frameworks such as Django to develop RESTful APIs\n",
      "2749 Exposure to the following a plus: Django, Tornado, Flask, FastAPI, SQLAlchemy, databases (SQL/non-SQL), Docker/docker-compose, IT automation (Ansible), Celery, Plotly, Terraform, RabbitMQ, Authentication standards such as OAuth2, Poetry, Conda\n",
      "2750 Have a working knowledge if various deep learning models and techniques including neural-networks, Random Forrest, Gradient Boost, Euclidean Distance, etc.\n",
      "2751 Proficient with Microsoft Office Suite (Outlook, Word, Excel, PowerPoint)\n",
      "2752 Your team will be leading different projects including a migration from AWS to GCP and Kubernetes.\n",
      "2753 Proven experience with Cloud Infrastructure (AWS, GCP, or Azure)\n",
      "2754 Experience with Linux environments and scripting languages\n",
      "2755 Experience with Infra as Code tools such as Terraform and provisioning/configuration management tools such as Ansible or Chef\n",
      "2756 Familiar with Docker and/or Kubernetes\n",
      "2757 Experience with version control tools like Git\n",
      "2758 Programming skills and especially in PHP\n",
      "2759 Experience with different kinds of architectures and their respective pros/cons: microservices, SOA, monolithics etc.\n",
      "2760 Maîtrise totale des outils de productivité numérique (PowerPoint, Excel, Word)\n",
      "2761 Expérience des boîtes à outils Cloud Native pour l'optimisation des architectures basées sur les micro-services (Kubernetes, Prometheus, Helm, Grafana, etc.)\n",
      "2762 Expérience en matière de JIRA, AHA et Confluence\n",
      "2763 Full control of digital productivity tools (PowerPoint, Excel, Word)\n",
      "2764 Experience with Cloud Native toolkits for optimizing microservice-based architectures (Kubernetes, Prometheus, Helm, Grafana, etc.)\n",
      "2765 Experience in JIRA, AHA, and Confluence\n",
      "2766 Expertise in PPC strategies, tools, and platforms (e.g., Google AdWords and Google Analytics)\n",
      "2767 Up-to-date with the latest trends, tools (e.g., HubSpot, Wordpress, CrazyEgg), and best practices in web marketing\n",
      "2768 Computer-Basic, MS Word, MS Excel\n",
      "2769 PowerPoint\n",
      "2770 MS Word\n",
      "2771 MS Excel\n",
      "2772 Mettre en œuvre de nouveaux algorithmes, recettes et prototypes, en utilisant Python et des outils d'apprentissage profond standard (TensorFlow, Fairseq, ou similaire)\n",
      "2773 Excellentes compétences en programmation (Python) avec connaissance des structures de données et des algorithmes standard\n",
      "2774 Expérience significative de l'utilisation d'Unix/Linux et des scripts Shell\n",
      "2775 Expertise en matière de boîtes à outils d'apprentissage approfondi, telles que TensorFlow ou Fairseq\n",
      "2776 Implement new algorithms, recipes, and prototypes, utilizing Python and standard deep learning toolkits (TensorFlow, Fairseq, or similar)\n",
      "2777 Excellent programming skills (Python) with knowledge of standard data structures and algorithms\n",
      "2778 Significant experience using Unix/Linux and shell scripting\n",
      "2779 Expertise with deep learning toolkits, such as TensorFlow or Fairseq\n",
      "2780 Build and manage microservices on AWS\n",
      "2781 Use Python to automate data processes and analyses to maximize efficiency\n",
      "2782 Perform spatial analyses with SQL\n",
      "2783 Web scraping unstructured data with Python\n",
      "2784 Knowledge and experience with Python (5+ years)\n",
      "2785 Knowledge and experience with SQL (5+ years)\n",
      "2786 Knowledge and experience with Docker\n",
      "2787 Knowledge and experience with Terraform\n",
      "2788 Experience with enterprise databases (MS SQL, MySQL or PostgreSQL)\n",
      "2789 Experience with source code control frameworks (Git).\n",
      "2790 Knowledge and experience using NoSQL databases such as MongoDB or DynamoDB\n",
      "2791 Experience with administrating and working with enterprise database technologies such as Amazon Redshift\n",
      "2792 Experience with GIS Products (QGIS, ArcGIS Enterprise, ArcGIS Pro)\n",
      "2793 Knowledge and experience with ETL software such as FME Desktop and FME Server\n",
      "2794 Artificial Intelligence (AI), Data & AI, Program Manager, Azure, Azure Cloud & AI, Azure, Digital Transformation, Big Data, Solutions, Industry, Go-to-Market,\n",
      "2795 You will get your hands on experience with many tools in our stack for our Closing Folders solution with a strong focus on AWS and Terraform.\n",
      "2796 Strong knowledge of Linux, Networking and System trouble shooting\n",
      "2797 Good scripting knowledge (Bash or Python)\n",
      "2798 Strong knowledge of AWS ecosystem including EC2, Cloudwatch, S3, CodeDeploy, CodePipeline, S3, Lambda, DynamoDB, X-Ray, GuardDuty, and AWS Config\n",
      "2799 Working experience with Infrastructure as a Code (Terraform)\n",
      "2800 Good knowledge of automation tools (Ansible)\n",
      "2801 Experience scaling relational databases (Postgres)\n",
      "2802 Experience with CI/CD solutions like Gitlab Runners or BitBucket Pipelines\n",
      "2803 Experience with managing and using Git-repositories (Gitlab, Bitbucket)\n",
      "2804 Fully proficient in Microsoft Office Suite\n",
      "2805 Build deploy and manage CI/CD workflows which leverage GitOps practices\n",
      "2806 Expert knowledge and experience configuring and managing modern cloud based systems, particularly Microsoft Azure and Amazon AWS\n",
      "2807 MS SQL, MongoDB), ETL pipelines and cloud native storage products\n",
      "2808 Design, develop, document, test and support mobile applications for Android, iOS and Windows devices and/or enterprise web applications in the Cloud\n",
      "2809 Excellent development skills with four or more of the following: Angular, Django, Python/JavaScript, C#/Java, SQL, REST, Android, iOS and Windows mobile devices\n",
      "2810 Experience with Cloud orchestration, automation, monitoring, CI/CD and Kubernetes\n",
      "2811 Experience with Xamarin and Azure an asset\n",
      "2812 Familiarity and strength in any of the following: Java Script (Angular, Node, React), HTML/CSS, Python, MongoDB, SQL, RESTful Web Services, .NET, VBA, XML, HTTP, WSDL, Linux, Unix, Oracle, Windows, Adobe Photoshop/Premiere Pro/After Effects\n",
      "2813 We exclusively use Kotlin, even though some older parts of the codebase are in Java\n",
      "2814 We also use a shared C++ core with the iOS app\n",
      "2815 But don’t worry, we won’t ask you to write C++ (except if you want to).\n",
      "2816 A previous experience, personal or professional, in mobile app development, if possible on Android, is appreciated\n",
      "2817 Any knowledge of Java/Kotlin is a big plus\n",
      "2818 Not being afraid of C++ is a good thing\n",
      "2819 Utilize reusable templates and common HTML elements while leveraging centralized JQuery/JavaScript libraries and global CSS.\n",
      "2820 Expertise in AEM and associated technologies such as Sling, OSGI, Felix, Jackrabbit, JCR, CRX highly desired\n",
      "2821 Experience with Java technologies and frameworks mainly Spring, Hibernate\n",
      "2822 Experience with at least one Ajax/JavaScript framework (Jquery, ExtJS)\n",
      "2823 Experience to other web technologies like Search, XML, XSL etc.\n",
      "2824 Should have strong knowledge on Responsive Web Design, HTML5, CSS3, JavaScript, Object Oriented JavaScript, JQuery, CSS Frameworks like Bootstrap/PureCSS etc, any MVC framework like AngularJS/BackboneJS/KnockoutJS, SASS, NodeJS, unit testing frameworks like Jasmine/Chai/Mocha/Karma, JS based templating engines like Mustache/Handlebars, performance evaluation using Chrome dev tools/ PageSpeed / YSlow etc, W3C standards\n",
      "2825 Experience with Content Management Services like AEM, Sitecore, Drupal is a strong plus\n",
      "2826 Over 7+ year experience developing JEE web applications and very strong concepts of OSGi, Apache Sling, Apache Sightly, Apache Oak and Adobe Dispatcher\n",
      "2827 Experience with Java technologies and frameworks mainly Spring, Hibernate.\n",
      "2828 Experience with at least one Ajax/JavaScript framework (Jquery, ExtJS)\n",
      "2829 Experience to other web technologies like Search, XML, XSL etc.\n",
      "2830 Maîtrise totale des outils de productivité numérique (PowerPoint, Excel, Word)\n",
      "2831 Expérience en matière de JIRA, AHA et Confluence\n",
      "2832 Full control of digital productivity tools (PowerPoint, Excel, Word)\n",
      "2833 Experience in JIRA, AHA, and Confluence\n",
      "2834 MS Office\n",
      "2835 En utilisant Docker, Kubernetes, Azure et d'autres outils natifs du cloud, participer et améliorer le cycle de vie des services - conception, déploiement, exploitation et gestion\n",
      "2836 Expérience de développement avec une réelle force en matière de débogage - connaissance de Java / JavaScript / Golang / C++ / Python / Bash\n",
      "2837 Maîtrise exceptionnelle (connaissances et expérience professionnelle) de Linux et Windows\n",
      "2838 Capacité d'assistance pour les pipelines de l'IC GitLab (construction/promotion d'artefacts et scanners de sécurité)\n",
      "2839 Excellente connaissance et expérience pratique des Kubernetes, docker et autres technologies Cloud Native\n",
      "2840 Avoir créé une automatisation en utilisant les API d'Azure ou d'AWS\n",
      "2841 Expérience en matière de configuration / gestion de paquets : Terraform, Helm\n",
      "2842 Expérience en matière de suivi des services cloud (impliquant Prometheus par exemple)\n",
      "2843 AKS, Envoyé, Ambassadeur, Harnais\n",
      "2844 Sécurité : Calico\n",
      "2845 Stockage : Rook, Azure File/Disk/Blob, Min.io\n",
      "2846 Nuages : Azur, GCP, AWS\n",
      "2847 Suivi : Grafana, FluentD, ElasticStack, Prométhée, SumoLogic\n",
      "2848 Traçage : OpenTracing, Jaeger\n",
      "2849 Gestion des incidents : PagerDuty, AlertManager\n",
      "2850 Linux : Debian, Ubuntu, CentOS,\n",
      "2851 Communication : MSTeams\n",
      "2852 Utilizing Docker, Kubernetes, Azure, and other cloud native tools, engage in and improve the lifecycle of services – design, deployment, operation and management\n",
      "2853 Development background with a real strength in debugging - knowledge among Java / JavaScript / Golang / C++ / Python / Bash\n",
      "2854 Cloud experience - ideally Azure, consider AWS\n",
      "2855 Exceptionally proficient (knowledge and work experience) in Linux\n",
      "2856 Excellent Knowledge and hands on experience with Kubernetes, docker and other Cloud Native technologies\n",
      "2857 Have created automation using APIs from Azure or AWS\n",
      "2858 Configuration / package management experience: Terraform, Helm\n",
      "2859 Experience with Cloud service monitoring (involving Prometheus for example)\n",
      "2860 Monitoring: Grafana, FluentD, ElasticStack, Prometheus, SumoLogic\n",
      "2861 AKS, Envoy, Ambassador, Harness\n",
      "2862 Security: Calico\n",
      "2863 Storage: Rook, Azure File/Disk/Blob, Min.io\n",
      "2864 Clouds: Azure, GCP, AWS\n",
      "2865 Tracing: OpenTracing, Jaeger\n",
      "2866 Incident Management: PagerDuty, AlertManager\n",
      "2867 Linux: Debian, Ubuntu, CentOS,\n",
      "2868 Windows experience\n",
      "2869 Communication: MSTeams\n",
      "2870 Design, develop, document, test and support mobile applications for Android, iOS and Windows devices and/or enterprise web applications in the Cloud\n",
      "2871 Strong development skills with four or more of the following: Angular, Django, Python/JavaScript, C#/Java, SQL, REST, Android, iOS and Windows mobile devices\n",
      "2872 Cloud orchestration, automation, monitoring, CI/CD and Kubernetes experience an asset\n",
      "2873 Experience with Xamarin and Azure an asset\n",
      "2874 Java,\n",
      "2875 Expérience avec les cadres JavaScript\n",
      "2876 JavaScript\n",
      "2877 HTML\n",
      "2878 CSS\n",
      "2879 jQuery\n",
      "2880 Akka, Scala\n",
      "2881 ScalaJS\n",
      "2882 NoSQL Database\n",
      "2883 Java,\n",
      "2884 Experience with JavaScript frameworks\n",
      "2885 JavaScript\n",
      "2886 HTML\n",
      "2887 CSS\n",
      "2888 jQuery\n",
      "2889 Akka, Scala\n",
      "2890 ScalaJS\n",
      "2891 NoSQL Database\n",
      "2892 DevOps: Linode & CentOs, Ngnix\n",
      "2893 DB: MySQL\n",
      "2894 Server Side: PHP & Laravel\n",
      "2895 Client Side: HTML5, CSS3, Bootstrap, JQuery & JavaScript\n",
      "2896 APIS: Bambora, Stripe & other Payment Processor APIs, Shopify API, Semantics3, and more\n",
      "2897 Source Control: Git & Bitbucket\n",
      "2898 PHP: 3 years (Required)\n",
      "2899 CSS: 3 years (Required)\n",
      "2900 Javascript: 3 years (Required)\n",
      "2901 Laravel: 2 years (Required)\n",
      "2902 HTML: 3 years (Required)\n",
      "2903 You will get your hands on experience with many tools in our stack for our Closing Folders solution with a strong focus on AWS and Terraform.\n",
      "2904 Strong knowledge of Linux, Networking and System trouble shooting\n",
      "2905 Good scripting knowledge (Bash or Python)\n",
      "2906 Strong knowledge of AWS ecosystem including EC2, Cloudwatch, S3, CodeDeploy, CodePipeline, S3, Lambda, DynamoDB, X-Ray, GuardDuty, and AWS Config\n",
      "2907 Working experience with Infrastructure as a Code (Terraform)\n",
      "2908 Good knowledge of automation tools (Ansible)\n",
      "2909 Experience scaling relational databases (Postgres)\n",
      "2910 Experience with CI/CD solutions like Gitlab Runners or BitBucket Pipelines\n",
      "2911 Experience with managing and using Git-repositories (Gitlab, Bitbucket)\n",
      "2912 Proficiency in prototyping tools, must include Axure\n",
      "2913 Scientific or application based programming experience is required (e.g., Python, Golang, C++, Java, etc.)\n",
      "2914 Database experience using xSQL or NoSQL is preferred\n",
      "2915 Work experience with Unix based operating system and scripting language (e.g., Linux/Bash) is an asset\n",
      "2916 We are looking for a C# / C++ Software Developer to help us create and maintain Artificial Intelligence-based investment software.\n",
      "2917 - Develop and maintain highly parallelized optimization software using C# and C++ based plugins such as OpenCL, CUDA, IPU’s Poplar, etc.\n",
      "2918 - Excellent and demonstratable C# and C++ programming skills combined with hands-on experience in dealing with software development challenges.\n",
      "2919 - Hands-on experience with MS Azure DevOps, Visual Studio, and other common development environments.\n",
      "2920 Advanced Excel and PowerPoint skills, including presentation delivery\n",
      "2921 Strong coding skills in Python and C++.\n",
      "2922 Familiar with Linux and deep learning frameworks such as MXNET (preferred)/PyTorch/TensorFlow.\n",
      "2923 Experience delivering applications into production environments (Git workflow, CI/CD systems like CircleCI, GitLab etc).\n",
      "2924 Examples of coding in the following programming languages: Java, Python, and MySQL.\n",
      "2925 Previous tech internships or relevant work experience programming in the following languages: Java, Python, and MySQL.\n",
      "2926 Experience working with some of the following: web application development, APIs, Unix/Linux environments, Database, file system management (upload/download), mobile application development, distributed and parallel systems, natural language processing, developing large software systems, and/or security software development.\n",
      "2927 Java: 2 years (Required)\n",
      "2928 MySQL: 2 years (Required)\n",
      "2929 Python: 2 years (Required)\n",
      "2930 You've built public, product-specific APIs that are used by a variety of clients, from node.js to native mobile, and that are backed by search technologies like ElasticSearch or Vespa\n",
      "2931 Take an ownership role in developing and operating the PHP middleware that connects backend systems (including search engines, ML services, and SQL databases) to our client-facing web and native mobile applications\n",
      "2932 Contribute to the buildout of a serverless data platform using a combination of Python and AWS technologies like Lambda, Kinesis, S3, EC2, Glue, Batch, EMR, and CloudFormation.\n",
      "2933 You possess a high level of proficiency with GSuite or the Microsoft Suite of applications, Excel in particular (with an emphasis on data manipulation and visualization skills), Mailchimp, Eventbrite, Canva, WordPress, Adobe Illustrator and Zapier.\n",
      "2934 Utilisateur expérimenté de l'informatique, capable de se familiariser rapidement avec les nouveaux outils MS Windows.\n",
      "2935 Familiarité avec Linux et les scripts Shell.\n",
      "2936 Familiarité avec Jira et Confluence.\n",
      "2937 Experienced computer user, able to quickly become familiar with new MS Windows tools.\n",
      "2938 Familiarity with Linux and shell scripting.\n",
      "2939 Familiarity with jira and confluence.\n",
      "2940 Azure Time Series Insights and PowerBI), advanced analytics (e.g\n",
      "2941 Some examples of endpoints may include: Operational systems: OSIsoft PI, Ignition, ClearSCADA; Service provider’s cloud platforms: NOV MaxCloud, ABRA;\n",
      "2942 Developing dashboards and reports in Azure Time Series Insights, PowerBI and other Microsoft Partner Platforms;\n",
      "2943 Experience designing and maintaining enterprise data platforms on cloud services (Power BI, Time Series Insights, etc.) is an asset;\n",
      "2944 Familiarity with industrial specifications such as Modbus, DNP3, PROFIBUS, OPC; and any IIoT specifications such as MQTT, AMQP, MIOTY, LORAWAN is an asset;\n",
      "2945 covering SAP CRM including Call Center, SAP Marketing Cloud, various applications based on SAP Cloud Platform as well as integration to key data sources and systems via SAP Cloud Integration)\n",
      "2946 Proficient in JAVA and JAVA SCRIPT\n",
      "2947 Extracting, transforming and loading massive datasets using distributed computing framework technologies (Hadoop, Spark, etc.);\n",
      "2948 Have experience with writing software in one of the major languages such as C++, C#, Java, Python;\n",
      "2949 Have familiarity with the Unix command line and bash scripting;\n",
      "2950 Experience with Deep Learning packages such as Tensorflow, Theano, Keras and PyTorch is an asset;\n",
      "2951 Hadoop, Spark) as well as SQL, NoSQL and graph databases is an asset;\n",
      "2952 Fully proficient in Microsoft Office Suite\n",
      "2953 Connaissance de la téléphonie, des applications basées sur SIP et de l'ingénierie du trafic basée sur Erlang\n",
      "2954 Connaissance des sous-systèmes de base de données, notamment Oracle pour le reporting, l'entrepôt de données et la reprise après sinistre.\n",
      "2955 Bonne connaissance des technologies actuelles de l'informatique en nuage, notamment Azure, AWS\n",
      "2956 IVR, CTI, SS7, SIP, RTP, Cisco ICM, VMware, technologies Cisco, équilibrage de charge, conception haute disponibilité/ tolérance aux pannes, Oracle, MPLS, BGP, OSPF\n",
      "2957 5+ expérience pratique avec Linux, scripting\n",
      "2958 Connaissance de Python, GO ou de tout autre langage OO\n",
      "2959 Knowledge of telephony, SIP-based applications and Erlang-based traffic engineering\n",
      "2960 Knowledge of database subsystems including Oracle for reporting, data warehouse and disaster recovery.\n",
      "2961 Good knowledge in current cloud technology including Azure, AWS\n",
      "2962 IVR, CTI, SS7, SIP, RTP, Cisco ICM, VMware, Cisco technologies, Load balancing, High availability/fault tolerant design, Oracle, MPLS, BGP, OSPF\n",
      "2963 5 years hands on experience with Linux internals, scripting\n",
      "2964 Knowledge of Python, GO or any OO language\n",
      "2965 Expertise with Python (Pandas, SciKit, and similar) and Unix operating systems\n",
      "2966 Experience with SQL programming for data extraction\n",
      "2967 Solides compétences en matière de développement Java\n",
      "2968 Expérience de test d'applications natives en nuage à l'aide de Docker, Kubernetes, etc.\n",
      "2969 Expérience avec C# .Net\n",
      "2970 Expérience avec Python\n",
      "2971 Bonne connaissance de JavaScript et d'autres aspects des applications web côté client\n",
      "2972 Strong Java development skills\n",
      "2973 Experience with testing cloud native applications using Docker, Kubernetes etc.\n",
      "2974 Experience with C# .Net\n",
      "2975 Experience with Python\n",
      "2976 Good knowledge of JavaScript and other aspects of client-side web applications\n",
      "2977 Compréhension approfondie de la mise en place de patchs : Windows, Linux, VMWare, serveur web tel qu'Apache/Tomcat et autres plates-formes d'applications web\n",
      "2978 Forte expérience de la rédaction de scripts dans la langue de son choix, par exemple Python\n",
      "2979 Expérience avec Rapid InsightVM ou Tenable Nessus préférée\n",
      "2980 Strong understanding of patching of: Windows, Linux, VMWare, web server such as Apache/Tomcat and other web application platforms\n",
      "2981 Python\n",
      "2982 Experience with Rapid InsightVM or Tenable Nessus preferred\n",
      "2983 Experience working with Enterprise /open source tools for Automation and Performance testing (UFT, LoadRunner, JMeter, Selenium, Java and Python frameworks)\n",
      "2984 Experience working with Cloud solutions, APIs, UI, MQ Messaging and backend automation (Kafka, Postgres, MuleSoft…)\n",
      "2985 Java and Python Test frameworks\n",
      "2986 Source Code Control Tool (Example: GitHub, Bitbucket, etc.\n",
      "2987 DevSecOps Pipelines - Example: Jenkins or Azure DevOps\n",
      "2988 PHP\n",
      "2989 MySQL\n",
      "2990 Python\n",
      "2991 React.js\n",
      "2992 JavaOS\n",
      "2993 API\n",
      "2994 Advanced Excel and PowerPoint skills, including presentation delivery\n",
      "2995 Connaissance en programmation Python (librairie de traitement et analyse de données)\n",
      "2996 Connaissance en programmation en C # et .NET (4.7+ ou Core)\n",
      "2997 SQL)\n",
      "2998 Connaissance pratique du développement sous Azure\n",
      "2999 Expérience d'utilisation des services d’Azure DevOps\n",
      "3000 Knowledge of Python programming (data processing and analysis library)\n",
      "3001 Programming knowledge in C# and .NET (4.7+ or Core)\n",
      "3002 SQL)\n",
      "3003 Working knowledge of development in Azure\n",
      "3004 Experience using Azure DevOps services\n",
      "3005 Advanced Excel and PowerPoint skills, including presentation delivery\n",
      "3006 Production experience with data processing tools such as Spark or Beam\n",
      "3007 Software engineering experience in Python\n",
      "3008 Proficiency in SAS, Python, and R\n",
      "3009 Will be an advanced Excel user, proficient in pivots, formulas and have the ability to create or guide the creation of models, etc\n",
      "3010 3 – 5 years’ experience in channel sales or programs, Power Excel and MS Office User.\n",
      "3011 Proficiency in MS Office Suite and Excel.\n",
      "3012 Experience with operational tools (CRM, Salesforce.)\n",
      "3013 Strong working knowledge of MS Office skills especially Word, Excel and Outlook\n",
      "3014 Intermediate skill level of MS PowerPoint an advantage\n",
      "3015 SAP & Microsoft Dynamics experience an advantage.\n",
      "3016 Strong DevOps CI/CD knowledge including use of tools such as Git, Terraform, Jenkins, Ansible, Kubernetes, Docker, etc.\n",
      "3017 Software engineering experience in Python\n",
      "3018 Experience with Kubernetes\n",
      "3019 Experience with GCP\n",
      "3020 Ability to read and make sense of common web technologies and languages such as HTML, JavaScript, PHP etc\n",
      "3021 Python, Ruby, Java) to create research tools and ad-hoc scripts.\n",
      "3022 Working level knowledge in programming languages including R and Python software packages.\n",
      "3023 Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design\n",
      "3024 Java et J2EE\n",
      "3025 Expérience avec les technologies de la plate-forme Java d'entreprise telles que Tomcat, WebSphere et JBoss.\n",
      "3026 Expérience des technologies, de l'architecture et des services web côté serveur, tels que Spring et Apache CXF.\n",
      "3027 Expérience des systèmes d'exploitation Windows et UNIX/Linux\n",
      "3028 Systèmes VoiceXML et IVR\n",
      "3029 Technologies web de pointe telles que HTML, CSS, Angular JS, JavaScript\n",
      "3030 Systèmes de bases de données et SQL\n",
      "3031 Expérience des outils de contrôle de version (Perforce, GIT, Starteam, etc.) et des outils d'intégration continue et de révision du code\n",
      "3032 Java and J2EE\n",
      "3033 Experience with enterprise Java platform technologies such as Tomcat, WebSphere, and JBoss.\n",
      "3034 Experience with server-side web technologies, architecture, and web services, such as Spring and Apache CXF.\n",
      "3035 Windows and UNIX/Linux operating systems experience\n",
      "3036 VoiceXML and IVR systems\n",
      "3037 Front-end web technologies such as HTML, CSS, Angular JS, JavaScript\n",
      "3038 Database systems and SQL\n",
      "3039 Experience with version control tools (Perforce, GIT, Starteam, etc), and with Continuous Integration and code review tools\n",
      "3040 Experience with all or some of the following languages: Python, R, VB.net, C#, SQL\n",
      "3041 SQL\n",
      "3042 Understanding of high performance algorithms and Python statistical software\n",
      "3043 Understanding of high performance algorithms and Python statistical software\n",
      "3044 Possesses working knowledge of contemporary agile project management tools such as Jira , Rally, Kanbanize, LeanKit, VersionOne or equivalent\n",
      "3045 Experience in agile visualization toolsets (Miro, Stories onboard, etc.)\n",
      "3046 Possesses working knowledge of contemporary agile project management tools such as Jira , Rally, Kanbanize, LeanKit, VersionOne or equivalent\n",
      "3047 Experience in agile visualization toolsets (Miro, Stories onboard, etc.)\n",
      "3048 Have good understanding of mobile development for both iOS and Android\n",
      "3049 3+ years experience on ReactJS\n",
      "3050 1+ years experience on React Native development experience\n",
      "3051 3+ years experience on HTML, CSS, Bootstrap, Javascript.\n",
      "3052 2+ years experience on MEAN (MongoDB, Express, Angular, Node) experience\n",
      "3053 2+ years experience on Node.js experience\n",
      "3054 Experience working with a variety of SQL and NoSQL data stores (PostgresSQL, Aurora, Hadoop, DynamoDB, S3, BigQuery)\n",
      "3055 Experience with Git and Gitflow\n",
      "3056 Experience with TypeScript\n",
      "3057 Experience on LAMP (Linux, Apache, MySQL, PHP) Development considered an asset\n",
      "3058 ReactJS: 3 years (Preferred)\n",
      "3059 HTML/CSS: 3 years (Preferred)\n",
      "3060 AngularJS: 2 years (Preferred)\n",
      "3061 Hive / Hadoop/ Spark) & cloud technologies (e.g\n",
      "3062 AWS Sagemaker, AzureML, EMR).\n",
      "3063 SQL, Python, R, SAS, SPSS, Perl) and machine learning /deep learning algorithms/packages (e.g\n",
      "3064 XGBoost, H2O, SparkML).\n",
      "3065 Three to ten years of experience in programming in Python and/or SAS as well as an excellent knowledge of best practices (code reuse, modularity, repository)\n",
      "3066 Fluency working with big data frameworks: MapReduce, Hadoop, Hive, Spark, an asset\n",
      "3067 Active involvement in the data science community; participation in competitions like Kaggle, or active involvement in GitHub or Stack Overflow, an asset\n",
      "3068 Strong Microsoft Office skills (Excel; Word; PowerPoint).\n",
      "3069 Can “think in code” and have a deep understanding of the Java and/or Python software development stacks and ecosystems\n",
      "3070 Are familiar with cloud-native applications in AWS or Azure (or a similar cloud platform)\n",
      "3071 Intermediate knowledge of MS Excel, MS Word and MS Office (required)\n",
      "3072 Experience with MacOS, iOS, Smartphone, or similar technology.\n",
      "3073 Experience with development technologies such as JAVA and JavaScript\n",
      "3074 Expert in HTML and CSS with strong background of designing Marketo templates using a modular approach\n",
      "3075 Other platforms of interest include Adobe Campaign, Pardot, Salesforce Marketing Cloud and Eloqua\n",
      "3076 Help with improvement of UI/UX and search accuracy of the BenchSci platform\n",
      "3077 Uniprot, STRING, Kegg Pathways,...)\n",
      "3078 strategies to leverage the popular data science language Python\n",
      "3079 Cerebri AI CVX platform includes a streaming capable AI software pipeline that processes data intake thru to producing insights and actions & presenting them via our APIs, in our customers' systems, or our UX\n",
      "3080 Java, Scala, Python)\n",
      "3081 Atlassian suite (JIRA, Confluence, BitBucket)\n",
      "3082 Experience with and advanced knowledge of Microsoft Office and the Google Suite\n",
      "3083 Java, Python, Go, C/C++, C#, etc.)\n",
      "3084 Strong programming skills including knowledge of: Open CV, Matlab, Python, CUDA, and C++\n",
      "3085 deep learning frameworks, such as Tensor Flow, Keras, PyTorch, NVIDIA Deep Stream\n",
      "3086 Strong hands-on knowledge and experience with C# and C++ in a .NET development in a Windows\n",
      "3087 Working knowledge of Python.\n",
      "3088 Knowledge of database architectures and operation (SQL Server, Mongo or similar);\n",
      "3089 Experienced with OpenLDAP\n",
      "3090 Proficient in a PC environment, using MS Office, and comfortable with technology\n",
      "3091 Extensive hands-on experience and expertise in object-oriented design methodology and application development using Java/J2EE/Golang, Design Patterns, Web services.\n",
      "3092 Excellent knowledge and experience of database (MySQL, PostgreSQL, and Redis).\n",
      "3093 Familiar with Nginx, Load Balancer technologies.\n",
      "3094 Familiar with Jira, Git, Agile Development Process CI/CD, Microservices architecture, cloud computing architecture.\n",
      "3095 Ability to operate in a Linux based environment.\n",
      "3096 Familiarity with Python development tools such as pytest/unittest.\n",
      "3097 Extensive programming skills (React, and Angular).\n",
      "3098 Experience with build and deployment tools like Docker, and Ansible.\n",
      "3099 Golang development: 3 years (Preferred)\n",
      "3100 JAVA/J2EE development: 5 years (Preferred)\n",
      "3101 - Proficiency with a deep learning framework such as TensorFlow or Keras\n",
      "3102 - Proficiency with Python and basic libraries for machine learning such as scikit-learn and pandas\n",
      "3103 - Proficiency with OpenCV\n",
      "3104 - Familiarity with Linux\n",
      "3105 - Must be familiar with AWS or Microsoft Azure Cloud\n",
      "3106 AWS or Azure: 2 years (Preferred)\n",
      "3107 Python: 4 years (Required)\n",
      "3108 Product-quality code in C++ and/or Python.\n",
      "3109 Advanced usage of Excel macros and program modules\n",
      "3110 2-4 years’ experience using Tableau\n",
      "3111 2-4 years AWS\n",
      "3112 Working knowledge of Splunk\n",
      "3113 You have a strong understanding of Linux-based cloud infrastructure\n",
      "3114 You have experience using, debugging, and tuning relational databases such as PostgreSQL\n",
      "3115 We are looking for a Full Stack Developer familiar with our technologies or ready to learn them! As a full stack developer, you should have a passion for innovative data solutions and be fluent in a variety of coding languages – we primarily use Python and Elixir in the back end and JavaScript, React, CSS and HTML in the front end\n",
      "3116 Experience with or interest in learning our front-end tools (Typescript, React, GraphQL, CSS) and our back-end tools (Python, Elixir, Docker, Kubernetes, PostgreSQL)\n",
      "3117 Our back-end systems are written using Python, Elixir, Docker, Kubernetes, Elastic, PostgreSQL and TensorFlow – these systems need to be scalable and highly configurable in order to fit our customer’s various needs\n",
      "3118 We use Typescript, React, GraphQL and CSS for most of our front-end products which are used to collect and display customer data and insights\n",
      "3119 Knowledge in STEM fields preferred, such as robotics, scratch coding and familiar with programming language such as Python/C/C++/Java, etc.\n",
      "3120 Expérience avérée du scriptage, dont les scripts bash, shell ou python\n",
      "3121 Expérience avec l’environnement de développement Java\n",
      "3122 Expérience des essais d’applications infonuagiques natives à l’aide de Docker, Kubernetes, etc.\n",
      "3123 Bonne connaissance de JavaScript et des autres éléments côté clients des applications Web\n",
      "3124 bash, shell, python\n",
      "3125 Experience with Java development\n",
      "3126 Experience with testing cloud native applications using Docker, Kubernetes etc.\n",
      "3127 Good knowledge of JavaScript and other aspects of client-side web applications\n",
      "3128 In order for you to succeed in this role, you will need to be proficient in JavaScript (frameworks of Express, Nodejs, Vue, Nuxt), HTML, CSS, and not afraid to get your hands dirty in solving complex problems.\n",
      "3129 - Strong knowledge of GIT\n",
      "3130 - Proficient in JavaScript, HTML, CSS.\n",
      "3131 - Proficient in frameworks such as Nuxt, Vue, and Express\n",
      "3132 - Familiar with UNIX commands.\n",
      "3133 - Familiar with other javascript frameworks\n",
      "3134 nodejs: 1 year (Preferred)\n",
      "3135 HTML/CSS: 1 year (Preferred)\n",
      "3136 Well-versed in Python or R (and willing to continue to learn the Python ecosystem)\n",
      "3137 This role requires a deep understanding of how all of Hitachi’s capabilities can best serve our clients’ needs across technologies such as D365FO, D365CE, Azure (Infrastructure, Custom Dev, IoT, Advanced Analytics, Artificial Intelligence), UX/UI, DevOps, Mobile and Portals.\n",
      "3138 Proven experience successfully implementing multiple technologies within the Microsoft (or competitor Cloud) ecosystem, including some/all of the following: D365FO, D365CE, Azure (Infrastructure, Custom Dev, IoT, Advanced Analytics, Artificial Intelligence), UX/UI, DevOps, Mobile and Portals\n",
      "3139 5+ years of experience with Linux-based embedded systems programming (C++, Qt, …)\n",
      "3140 Expertise working with OpenEmbedded (BitBake, Yocto, Bash, …)\n",
      "3141 Expertise in Python programming\n",
      "3142 Experience in using Agile software development cycle tools (JIRA, Confluence, Git, Jenkins, ….\n",
      "3143 Experience working with embedded databases (SQLite, lmdb , …)\n",
      "3144 Experience working with QML\n",
      "3145 We are looking for a part-time or project based Unity/Unreal Developer to work on developing audiovisual environments for demonstrations for real-time audio enhancement\n",
      "3146 Strong integrated audiovisual Unity/Unreal programming experience\n",
      "3147 Very good knowledge of C++ and C#\n",
      "3148 Experience with audio programming (Max/MSP, Pure Data, Reaktor, etc.)\n",
      "3149 Github\n",
      "3150 Platform specialties include Azure, Microsoft 365, Enterprise Mobility and Security Suite, System Center, PowerBI, SharePoint, Windows 10, Artificial Intelligence, Security, and others\n",
      "3151 You will design, build, and maintain responsive web applications with Python and browser-side Javascript.\n",
      "3152 You will work with PostgreSQL, Redis, and RabbitMQ, and container technolgoies Docker and Kubernetes.\n",
      "3153 Well-versed in Python or R (and willing to continue to learn the Python ecosystem).\n",
      "3154 Au moins 1 année d'expérience à utiliser des frameworks, bibliothèques et outils de NLP (p.ex., NLTK, Gensim, SpaCy, HuggingFace, torchtext) dans un environnement de production\n",
      "3155 ex., TF, Pytorch) est considérée comme un atout.\n",
      "3156 Excellente connaissance pratique de Python et des outils de développement modernes associés\n",
      "3157 L'expérience avec d'autres langages de programmation (p.ex., JAVA, C++, Go) est considérée comme un atout.\n",
      "3158 Expérience avec des outils de gestion de versions comme Git.\n",
      "3159 At least 1 year of experience using NLP frameworks, libraries, tools (e.g.: NLTK, Gensim, SpaCy, HuggingFace, torchtext) in a production environment\n",
      "3160 Additional experience with Machine Learning (e.g.: scikit-learn) and Deep Learning (e.g.: TF, Pytorch) frameworks an asset;\n",
      "3161 Very strong working knowledge of Python and its modern development toolchain\n",
      "3162 Experience with other programming languages (e.g.: JAVA, C++, Go) an asset;\n",
      "3163 Experience with code versioning tools such as Git;\n",
      "3164 Knowledge of different type of light sources such as QTH, LED, laser, fluorescence, etc.\n",
      "3165 Expertise in using React to build SaaS web applications, including system architecture and design\n",
      "3166 The ability to establish best practices for unit, integration, end-to-end, and visual testing guidelines in React and front-end development\n",
      "3167 Expertise in building monitoring of SaaS solutions through client facing tools such as Sentry\n",
      "3168 Experience driving excellence for React and web development best practices, standards, guidelines, documentation, training, and code quality\n",
      "3169 Knowledge of Django Python and/or SQL solutions, best practices, and architecture\n",
      "3170 Intermediate to advanced computer skills with MS Office (Word, Excel, PowerPoint, Outlook), ERP, Famous, Environmental Control systems\n",
      "3171 ERP\n",
      "3172 3+ years with Microsoft Azure/WEB development background\n",
      "3173 Experience with the .NET framework, C#, WCF, APIs and design patterns (ex\n",
      "3174 Experience with Microsoft SQL Server (database design, queries/stored procedures, performance tuning, etc.)\n",
      "3175 Experience working on User Interface (WinForms, Mobile, UWP, HTML/Web, etc.)\n",
      "3176 Understanding of Web technologies (ASP.Net Core Angular, Typescript, Azure, etc.) and Service Oriented Architecture (SOA)\n",
      "3177 Experience with client side JavaScript frameworks\n",
      "3178 Reporting to the Director Development, the AWS Administrator will be responsible for configuring, evolving and maintaining the Cloud environments of mdf commerce's clients\n",
      "3179 The selected candidate for this position must be comfortable in the administration of AWS systems.\n",
      "3180 Manage access to the AWS platform;\n",
      "3181 Experience in writing Bash scripts or Build RPM packages;\n",
      "3182 Excellent skills with Linux, CentOS, RHEL, AL2 or equivalent;\n",
      "3183 Knowledge of CloudFormation and Terraform;\n",
      "3184 Knowledge of SaltStack or equivalent like Puppet or Chef;\n",
      "3185 Knowledge of EKS or any Kubernetes equivalent;\n",
      "3186 Knowledge of Spinnaker and CICD concepts\n",
      "3187 Experience in AWS security principles like Landing Zone, Security Hub and AWS Config;\n",
      "3188 A minimum of 2 years of experience as an Azure or AWS Administrator.\n",
      "3189 Experience performing data analysis and modelling with either R, Python, or Julia\n",
      "3190 Knowledge of Git based code repositories such as GitLab or GitHub\n",
      "3191 Proficiency in Python\n",
      "3192 Experience in building deep learning models, bonus points if in TensorFlow.\n",
      "3193 Ability to write simple scripts; Python experience a nice-to-have.\n",
      "3194 Sketch, Figma (an asset)\n",
      "3195 o Front-end: React, HTML, CSS, JavaScript, C3/D3\n",
      "3196 o Back-end: Python, Java, Node.js\n",
      "3197 o AI / NLP: TensorFlow, PyTorch, SpaCy, NLTK, CoreNLP\n",
      "3198 o DB: Neo4j, Elasticsearch, MySQL\n",
      "3199 Open-source frameworks: R, Python, GitHub\n",
      "3200 Experience in Google Analytics strongly preferred\n",
      "3201 Computer literacy, particularly in the use and management of Word/PowerPoint/Excel\n",
      "3202 Urbint has a mix of self-hosted services deployed within Google Cloud with most managed through Google Container Engine (Kubernetes) and a need to support on-premise deployments to address specific security postures of some clients.\n",
      "3203 Experience with Linux, Configuration Management Tools (Puppet/Chef/Ansible/Terraform), Docker, Monitoring systems (Graphite/prometheus/grafana/statsd/etc.).\n",
      "3204 Strong shell scripting ability.\n",
      "3205 Programmation en Python ou Perl\n",
      "3206 Programmation C/C\n",
      "3207 Python or Perl programming\n",
      "3208 C/C++ programming\n",
      "3209 Experience with embedded operating systems - Linux, FreeBSD, FreeRTOS, QNX, Android, Integrity, Nucleus, etc.\n",
      "3210 Network protocols (Ethernet, TCP/IP, WIFI)\n",
      "3211 C, C++ and C# and Java programming languages\n",
      "3212 Script langages: Python, PERL, TCL, LUA, BASH etc\n",
      "3213 Configuration management tools (GIT, SVN, etc.)\n",
      "3214 Front-end and back-end technologies (Cloud)\n",
      "3215 Microsoft Windows design environment (C#, .NET, MFC)\n",
      "3216 OpenGL, OpenCL, CUDA programming\n",
      "3217 Deep Knowledge of Microsoft SQL Server Enterprise technology stack, SQL and T-SQL\n",
      "3218 Fluency with at least one scripting or programming language such as R, Python or PowerShell\n",
      "3219 Experience with working with public cloud environments like Azure or AWS\n",
      "3220 Hands-on experience with Tableau or PowerBI\n",
      "3221 You are a strategic thinker and a proven development leader delivering SOA-based software with UIs, APIs, and Services that enable business agility\n",
      "3222 Solid understanding and experience with web application technologies (Java, JavaScript, Angular, Application Frameworks, CSS, HTML, REST, JSON).\n",
      "3223 Solid understanding of Service Oriented Architecture, SOAP, XML, WSDL.\n",
      "3224 Proficiency with Python, JAVA or C#\n",
      "3225 Strong experience of software engineering practices such as Agile, Devops, CI and CD and others\n",
      "3226 Strong knowledge of DevOps modern tools such as Docker, OpenShift, Kubernetes, ELK\n",
      "3227 [Asset] Experience with machine learning and scientific computing libraries such as scikit-learn, NumPy, SciPy, etc.\n",
      "3228 [Asset] Experience with deep learning framework such as Kubeflow, Tensorflow, PyTorch or other\n",
      "3229 [Asset] Good experience with Kafka, MongoDB, No SQL\n",
      "3230 Strong experience in cloud platform environment (AWS, Google and Azure) and model development skills, with a good understanding of data structures\n",
      "3231 Knowledge in Python, R and SQL programming languages, Azure DataBricks and other data modeling/machine learning technologies\n",
      "3232 Strong experience in cloud platform environment (AWS, Google and Azure) and model development skills, with a good understanding of data structures\n",
      "3233 Knowledge in Python, R and SQL programming languages, Azure DataBricks and other data modeling/machine learning technologies\n",
      "3234 Experience with SQL and no-SQL databases.\n",
      "3235 Familiarity with programming languages such as Python, R, Java, or C/C++.\n",
      "3236 Familiarity with Big Data tools such as Hadoop, Spark, or Splunk.\n",
      "3237 Experience with cloud platforms such as AWS, GCD, or Azure.\n",
      "3238 Experience with Visualization tools and libraries such as Tableau, Looker, or Matplotlib.\n",
      "3239 Python, Flask & Celery\n",
      "3240 React & ClojureScript\n",
      "3241 PostgreSQL, Redis & RabbitMQ\n",
      "3242 Docker, Kubernetes & GCP\n",
      "3243 Highly proficient with Microsoft Office suite, including Excel\n",
      "3244 Utilize big data databases or Hadoop as well as SQL, and ability to select the right tool for the job.\n",
      "3245 5+ yrs of software development experience focused on web technologies including significant production work with Python.\n",
      "3246 3+ yrs of experience designing, building and maintaining enterprise data pipelines and/or warehouses with SQL.\n",
      "3247 Excel proficiency (fairly good level required)\n",
      "3248 Strong background in Microsoft Word, Excel, Access and PowerPoint preferred\n",
      "3249 You’ll have a sound understanding of computer science fundamentals and practical industry experience, working across the stack with technology involving modern web, SOA, NoSQL databases, AI, ML, Big Data and more.\n",
      "3250 Strong programming skills in Python, R, SQL, SAS, VBA, etc\n",
      "3251 Knowledge of industry best practices for AML/ATF such as Wolfsberg Principles is a plus\n",
      "3252 Advanced skills in MS Office suite of software, including advanced skills in Excel and Powerpoint\n",
      "3253 Programming and/or SQL knowledge would be a strong asset\n",
      "3254 Working knowledge of WordPress content management system\n",
      "3255 Strong cross modular integration knowledge with FI, MM, PP, and Saleforce\n",
      "3256 Solide connaissance de l'intégration modulaire croisée avec FI, MM, PP et Saleforce\n",
      "3257 Gérer une pile de systèmes Linux physiques et virtuels principalement à source ouverte et les couches fonctionnelles correspondantes de composants et de logiciels de gestion d'infrastructure à source ouverte (Puppet, xCAT, Jenkins, etc.)\n",
      "3258 Fournir une expertise technique, guider le développement des systèmes, la modernisation des piles et la modularité sur des plateformes Linux distribuées au niveau régional, y compris la gestion des systèmes d'exploitation (RHEL, CentOS), des conteneurs (Docker, Singularity), des ordonnanceurs de calcul en grille (Slurm, Torque, UGE) et divers systèmes de fichiers haute performance (WekaIO, CEPH, Lustre).\n",
      "3259 Connaissance experte des systèmes Linux, du matériel x86 et des fonctions liées à l'infrastructure, y compris le fonctionnement des centres de données\n",
      "3260 Manage a primarily open source stack of physical and virtual Linux systems and accompanying functional layers of open source infrastructure management components and software (Puppet, xCAT, Jenkins, etc.)\n",
      "3261 Expert level storage system knowledge with a particular expertise on Object based storage (CEPH, S3, etc…)\n",
      "3262 Provide technical expertise, guiding system development, stack modernization, and modularity across regionally distributed Linux platforms including management of OS (RHEL, CentOS), containers (Docker, Singularity), grid computing schedulers (Slurm, Torque, UGE) and various high performance file systems (WekaIO, CEPH, Lustre).\n",
      "3263 Expert knowledge of Linux systems, x86 hardware, and infrastructure-related functions including datacenter operations\n",
      "3264 Proficiency in various Microsoft Office software, including Excel, Outlook and Word;\n",
      "3265 Develop automated tests to deliver high quality software to our customers (e.g., unit test, integration test, selenium, or related libraries)\n",
      "3266 Integrate and deploy microservices by using best practices and automation tools (e.g., Docker and Ansible)\n",
      "3267 Developing Restful APIs (using frameworks such as Tornado, Django, or NodeJS) secured by OAuth2/Auth\n",
      "3268 Thorough working knowledge of data structure, algorithms, databases (SQL and noSQL) and in-memory data storage\n",
      "3269 Working knowledge of Docker and Ansible\n",
      "3270 Minimum of 4 years experience with Java, Javascript, NodeJS, and PHP (Twig, preferred)\n",
      "3271 Minimum of 4 years experience with content management systems such as Craft\n",
      "3272 Experience using code versioning tools such as Github\n",
      "3273 Minimum of 2 years experience with AWS, containers, ECS, Docker\n",
      "3274 Minimum de 4 ans d'expérience avec Java, Javascript, NodeJS et PHP (préférence pour avoir travaillé avec Twig)\n",
      "3275 Expérience de l'utilisation d'outils de gestion des versions de code tels que Github\n",
      "3276 Minimum de 2 ans d'expérience avec AWS, conteneurs, ECS, Docker\n",
      "3277 GUI Rapid development and data visualization techniques: Angular, JavaScript, HighCharts or other visualization library\n",
      "3278 Very good hands on programming experience with Python, GoLang, JavaScript and Java\n",
      "3279 API Proficiency: REST API in GoLang/Python, strong OpenAPI literacy\n",
      "3280 Work experience with machine learning and statistical methodologies (decision trees, KMeans, classification, regression, SVM) preferably using Python scikit-learn\n",
      "3281 Hands-on knowledge of NoSQL, time series, in memory databases: Elasticsearch, InfluxDB, Redis, Parquet\n",
      "3282 Docker and Kubernetes expertise\n",
      "3283 Automated testing using Pytest\n",
      "3284 Real time, batch, and stream processing analytics skills using: Pandas, Koalas, Vaex, Apache Spark and/or Dask\n",
      "3285 Data Serialization using Google ProtoBuf and/or Amazon Kinesis\n",
      "3286 GitHub expertise\n",
      "3287 7+ years' experience developing software with C++, C# and/or Java in Linux and/or Windows environment\n",
      "3288 You'll work with stakeholders across AWS to collaborate and launch new services\n",
      "3289 You will own ensuring your service can scale to support the AWS Windows workload story; integrating with multiple AWS services across all AWS regions\n",
      "3290 Les responsables du marketing d’Azure auprès des développeurs se servent de leur vaste expertise auprès de la communauté de développeurs et de leurs compétences marquées en marketing pour réunir l’équipe de marketing et l’équipe technique, afin d’aider les développeurs infonuagiques professionnels à découvrir la plateforme Microsoft Azure et à l’utiliser avec succès, et ce, en personne ou en ligne\n",
      "3291 Les responsables du marketing d’Azure auprès des développeurs font connaître Azure à ceux-ci et les aident à bien le comprendre ainsi qu’à l’adopter afin de favoriser la création d’un écosystème durable de développeurs infonuagiques chevronnés.\n",
      "3292 This role will be accountable for driving awareness and engagement with the professional developer community, both as the local developer audience expert and as an Azure subject-matter expert\n",
      "3293 Azure Developer Product Marketing Managers (PMMs) use their deep developer audience expertise and excellent marketing skills to bring Microsoft’s marketing and technical teams together to help professional cloud developers discover and successfully use Microsoft’s Azure platform, both through in-person and at digital scale\n",
      "3294 Interagir activement avec les développeurs et les former, et parler d’Azure dans le cadre d’événements locaux et de communauté.\n",
      "3295 Entretenir ses connaissances techniques de la plateforme Azure (niveau 200) et être en mesure de transposer les propositions de valeur d’Azure dans un discours pertinent sur le plan local.\n",
      "3296 Plan and execute the developer engagement strategy for Microsoft Azure\n",
      "3297 Posséder une expérience éprouvée en marketing technique pour plusieurs technologies infonuagiques, dont Azure, AWS ou Google Cloud Platform.\n",
      "3298 ex., Node, Java, Python, etc.).\n",
      "3299 Demonstrated technical marketing experience across cloud technologies, including Azure, AWS, and/or Google Cloud Platform\n",
      "3300 Strong understanding of software development principles, common DevOps practices, cloud platforms, business drivers, and emerging trends in Microsoft and non-Microsoft technologies and tools (e.g., Node; Java; Python; etc.)\n",
      "3301 Networks with key contacts outside own area of expertise.\n",
      "3302 Azure Kubernetes et MCaaS\n",
      "3303 Mise en réseau avancée d’Azure\n",
      "3304 Azure Sentinel, Centre de sécurité Azure\n",
      "3305 Stockage de données Azure – Cosmos DB, HD Insights, Databricks\n",
      "3306 Azure DevOps – Azure DevOps, intégration et livraison continues, tests unitaires et d’IU\n",
      "3307 Azure Kubernetes/MCaaS\n",
      "3308 Azure Advanced Networking\n",
      "3309 Azure Sentinel, Azure Security Center\n",
      "3310 Azure Data Storage - Cosmos DB, HD Insights, Databricks\n",
      "3311 Azure DevOps - Azure DevOps, CI/CD, Unit/UI Testing\n",
      "3312 5+ years relevant work experience with Azure large scale enterprise implementations\n",
      "3313 Proven abilities with Git based code repositories such as GitLab or GitHub\n",
      "3314 Excellent hands on programming experience with Python, GoLang, JavaScript and Java\n",
      "3315 API Proficiency: REST API in GoLang/Python, strong OpenAPI literacy\n",
      "3316 Data Serialization using Google ProtoBuf and/or Amazon Kinesis\n",
      "3317 Hands-on knowledge of NoSQL, time series, in memory databases: Elasticsearch, InfluxDB, Redis, Parquet\n",
      "3318 Docker and Kubernetes expertise\n",
      "3319 Work experience with machine learning and statistical methodologies (decision trees, KMeans, classification, regression, SVM) preferably using Python scikit-learn\n",
      "3320 Automated testing using Pytest\n",
      "3321 GUI Rapid development and data visualization techniques: Angular, JavaScript, HighCharts or other visualization library\n",
      "3322 Real time, batch, and stream processing analytics skills using: Pandas, Koalas, Vaex, Apache Spark and/or Dask\n",
      "3323 GitHub expertise\n",
      "3324 Familiarity with Tableau is an asset.\n",
      "3325 Software Development (JavaScript, Java, Python, C#)\n",
      "3326 R, SQL, Linux, node.js, .Net, ReactJS\n",
      "3327 Raspberry Pi\n",
      "3328 Desire2Learn, Zoom and VMWare).\n",
      "3329 Utilisation et gestion de Jira et Sharepoint.\n",
      "3330 Use and management of Jira and Sharepoint.\n",
      "3331 Experience in Microsoft desktop and server platforms and their related software management applications\n",
      "3332 Working knowledge with MS Windows, IOS/OSX, Android, system environments\n",
      "3333 Very good hands on programming experience with Python, GoLang, JavaScript and Java\n",
      "3334 API Proficiency: REST API in GoLang/Python, strong OpenAPI literacy\n",
      "3335 Work experience with machine learning and statistical methodologies (decision trees, KMeans, classification, regression, SVM) preferably using Python scikit-learn\n",
      "3336 Hands-on knowledge of NoSQL, time series, in memory databases: Elasticsearch, InfluxDB, Redis, Parquet\n",
      "3337 Docker and Kubernetes expertise\n",
      "3338 Automated testing using Pytest\n",
      "3339 Real time, batch, and stream processing analytics skills using: Pandas, Koalas, Vaex, Apache Spark and/or Dask\n",
      "3340 GUI Rapid development and data visualization techniques: Angular, JavaScript, HighCharts or other visualization library\n",
      "3341 Data Serialization using Google ProtoBuf and/or Amazon Kinesis\n",
      "3342 GitHub expertise\n",
      "3343 Strong programming skills in Python, R, SQL, SAS, VBA, etc\n",
      "3344 Knowledge of industry best practices for AML/ATF such as Wolfsberg Principles is a plus\n",
      "3345 You are very proficient with Microsoft Excel\n",
      "3346 At least 2 years of experience working with one or more data mining tools such as R, Python, Scala or SAS\n",
      "3347 Hands-on experience working with Big Data technologies such as Spark, Cassandra, and/or Hadoop\n",
      "3348 Hands-on experience writing complex SQL queries and working with relational databases such as Oracle, DB2 or SQL Server\n",
      "3349 4 years of experience with both relational and NoSQL technologies\n",
      "3350 2 years of experience using data transformation and integration services such as Kafka Connect and/or Py.Spark\n",
      "3351 Knowledge of the Python data ecosystem using pandas and NumPy Experience building and deploying ML pipelines\n",
      "3352 web applications) in a corporate or start up engineering environment using JavaScript, PHP, Ruby, Python, C++ and/or Java / C#, HTML, CSS, React / Ember / Angular, etc\n",
      "3353 and working knowledge of relational and non-relational databases and SQL\n",
      "3354 ??? Experience using statistical computer languages (R, Python, SQL, etc.) to manipulate data and draw insights from large data sets.\n",
      "3355 ??? Coding knowledge and experience with several languages: C, C++, Java, JavaScript, etc.\n",
      "3356 ??? Experience querying databases and using statistical computer languages: R, Python, SQL, etc.\n",
      "3357 ??? Experience using cloud based services: Redshift, S3, Spark, DigitalOcean, etc.\n",
      "3358 ??? Experience analyzing data from 3rd party providers: Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc.\n",
      "3359 ??? Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc.\n",
      "3360 ??? Experience visualizing/presenting data for stakeholders using proprietary and open-source software: Tableau, Periscope, D3, ggplot, etc.\n",
      "3361 Experience with one or more general purpose programming languages including but not limited to: Python, Scala, Java, C, C++\n",
      "3362 Experience with one or more frameworks such as Tensorflow, Keras, Apache Beam, Spark\n",
      "3363 Python proficiency\n",
      "3364 python: 5 years (Required)\n",
      "3365 Unity or Unreal) & their limitations, Photoshop, and the Office Suite (especially Excel and PowerPoint).\n",
      "3366 Exceptional MS PowerPoint & MS Excel skills\n",
      "3367 Good knowledge of MS office (Excel PPT-Preferred)\n",
      "3368 Hands-on experience designing, deploying, and operating cloud services for compute and storage (Azure/AWS/GCP)\n",
      "3369 Experience in creating and deploying containers (Kubernetes, Docker).\n",
      "3370 Experience orchestrating distributed workflows with tools such as Apache Airflow, Argo, Slurm, etc...\n",
      "3371 Project experience in Git (gitflow, PRs, merges, etc.).\n",
      "3372 Familiarity with CI/CD tools such as Jenkins, Octopus Deploy, etc.\n",
      "3373 (non-web graphics experience such as Unity also acceptable)\n",
      "3374 React, Vue, etc)\n",
      "3375 Expert knowledge of web development using Typescript + React\n",
      "3376 Ability to work with non-web languages and frameworks, especially C# and Python.\n",
      "3377 Lightweight virtualization technologies (Docker, etc.)\n",
      "3378 Exposure to, or experience with IA tools such as: BluePrism, UiPath, Automation Anywhere, Workfusion, Hyperscience, ABBY would be an asset\n",
      "3379 Experience in code development in .Net or Java\n",
      "3380 Well-versed in Python or R (and willing to continue to learn the Python ecosystem).\n",
      "3381 Programming skills in Python (preferred), R, MATLAB or SQL\n",
      "3382 Strong understanding of computer basics (Windows, Excel, Word, e-mail and Internet).\n",
      "3383 Proficiency in, at least, one modern programming language such as C, C#, Java, Go, etc.\n",
      "3384 You’ll have a sound understanding of computer science fundamentals and practical industry experience, working across the stack with technology involving modern web, SOA, NoSQL databases, AI, ML, Big Data and more.\n",
      "3385 Experience with TCL, Perl, C, Python, MATLAB, or other scripting languages is desired.\n",
      "3386 Minimum of 3 years of relevant experience in Software Development: (C# .NET);\n",
      "3387 Minimum of 2 years of relevant experience in front-end development by using a framework like React JS or Angular JS;\n",
      "3388 Excellent knowledge of SQL and NoSQL databases;\n",
      "3389 Experience developing Web applications under a cloud environment like Amazon AWS or Microsoft Azure will be considered as an asset.\n",
      "3390 Java, .NET Framework, etc.)\n",
      "3391 Proficiency in technologies like SharePoint, .Net, SQL Server Database, and experienced using data analysis tools is an asset\n",
      "3392 Strong knowledge of Microsoft Office products (MS Word, Note, Excel, etc.)\n",
      "3393 Borderless Product: How may we extend our platforms key functionalities and user-interactions beyond the borders of our SaaS platform into Slack, Jira, GitHub, etc.?\n",
      "3394 AWS, Hostwinds, and Mongo Atlas for hosting\n",
      "3395 Development of scalable and reliable back end infrastructure in Node.js\n",
      "3396 Exposed to and/or experienced with building data sets in the cloud (on AWS, Azure or Google platforms), on Big Data / Hadoop (using Sqoop, Kafka, Parquet, Scala, Python, etc.), or on database platforms (using SQL-like programming on SQL Server, Oracle, Hive, HBase, NoSQL databases, etc.)\n",
      "3397 Experience with E2E automated testing tools such as Cypress, and unit testing tools like Jest for our Javascript / React functionality\n",
      "3398 Solid experience with data testing for our SQL and Python API functionality\n",
      "3399 Experience with visual testing tools like Happo\n",
      "3400 Extensive software development and design patterns experience (Java, Golang, Python)\n",
      "3401 In-depth experience in Architecture and Infrastructure management space (OpenAPI , UML)\n",
      "3402 Strong hands-on experience with Linux, Linux container technologies and Kubernetes.\n",
      "3403 Experience with AWS or GCP.\n",
      "3404 Hands-on experience working with Kubernetes – especially RBAC, Devops, CI/CD, Secret Management, certificates management, SSL/TLS, persistent storage solutions, networking.\n",
      "3405 Knowledge of Ansible and Infrastructure automation.\n",
      "3406 Strong scripting skills (Bash, Python, Ruby).\n",
      "3407 Hands-on experience with Jenkins or other CI/CD tools\n",
      "3408 Hands-on experience with GIT and GitHub.\n",
      "3409 Experience designing deployment architectures that supports a proper Disaster Recovery strategy, with Kubernetes.\n",
      "3410 (OpenShift, Rancher, K3S)\n",
      "3411 Hybrid-Cloud Management based on Kubernetes.\n",
      "3412 Experience with popular open source runtimes and application frameworks (gRPC, Redis, RabbitMQ, Nginx, Weave, GlusterFS, Helm)\n",
      "3413 Familiarity with Jira, Aha or similar tool.\n",
      "3414 In-depth knowledge of programming/implementation ability in Python, C++ or other languages, familiarity with ML paradigms (e.g\n",
      "3415 TensorFlow)\n",
      "3416 Experience with managing and delivering Salesforce.com projects using Copado; Github and Jira a plus\n",
      "3417 Minimum de 4 ans d'expérience avec Salesforce.com Sales and Service Clouds\n",
      "3418 Expérience de la gestion et de la livraison de projets Salesforce.com à l'aide de Copado; Github et Jira un plus\n",
      "3419 Automation: Python and Selenium is required\n",
      "3420 Plus de 3 ans d’expérience en développement de logiciels en langage Python, notamment la création et la prise en charge d’une base de code utilisée par d’autres développeurs, comme une bibliothèque Python sur GitHub ou une application déployée.\n",
      "3421 Expérience avec Docker, Kubernetes ou des cadres d’orchestration similaires.\n",
      "3422 3+ years of software development experience in Python that includes building and supporting a codebase used by others, such as a Python library on GitHub or a deployed application.\n",
      "3423 Experience with Docker, Kubernetes, or similar orchestration frameworks.\n",
      "3424 Expert hands on programming experience with Python, GoLang, JavaScript and Java\n",
      "3425 Work experience with machine learning and statistical methodologies (decision trees, KMeans, classification, regression, SVM) preferably using Python scikit-learn\n",
      "3426 Real time, batch, and stream processing analytics skills using: Pandas, Koalas, Vaex, Apache Spark and/or Dask\n",
      "3427 Hands-on knowledge of NoSQL, time series, in memory databases: Elasticsearch, InfluxDB, Redis, Parquet\n",
      "3428 Docker and Kubernetes expertise\n",
      "3429 Automated testing using Pytest\n",
      "3430 API Proficiency: REST API in GoLang/Python, strong OpenAPI literacy\n",
      "3431 Data Serialization using Google ProtoBuf and/or Amazon Kinesis\n",
      "3432 GUI Rapid development and data visualization techniques: Angular, JavaScript, HighCharts or other visualization library\n",
      "3433 GitHub expertise\n",
      "3434 Experience using iOS, smartphones, Tablets, and PC/Mac products\n",
      "3435 You will have to design, develop and maintain AI applications in Python\n",
      "3436 - Experience in using deep learning stack (TensorFlow, Pytorch, Keras, etc.)\n",
      "3437 - Experience in using Machine Learning stack (Scikit-Learn, Numpy, etc.)\n",
      "3438 - Good knowledge of Image processing and Computer Vision (OpenCV, CNN, etc.)\n",
      "3439 - Very good level in programming in python\n",
      "3440 - Good knowledge of SQL\n",
      "3441 - Mastery in Linux\n",
      "3442 Familiarity with MS Office tools and CRM required\n",
      "3443 Vous serez amené à concevoir, déveloper et maintenir des applications IA en python\n",
      "3444 - Expérience des outils d’apprentissage profond (TensorFlow, Pytorch, Keras, etc.)\n",
      "3445 - Expérience des outils d’apprentissaeg machine (Scikit-Learn, Numpy, etc.)\n",
      "3446 - Bonnes connaissances en traitement de l’image, et vision par ordinateur (OpenCV, CNN, etc.)\n",
      "3447 - Très bon niveau en programmation python\n",
      "3448 - Bonne maitrise du langage SQL\n",
      "3449 - Maitrise de Linux\n",
      "3450 Ariann Solutions is looking for a C++ programming role for its dynamic and multi-disciplinary team of Research and Development\n",
      "3451 You will have to design, develop and maintain applications C++\n",
      "3452 - Very good level in programming C++ and python\n",
      "3453 - Good knowledge of SQL\n",
      "3454 - Mastery in Linux\n",
      "3455 - Knowledge of Python and/or web technology (ex: React) is an asset\n",
      "3456 Must have at least 1 year of experience with Deep Learning frameworks like PyTorch or TensorFlow.\n",
      "3457 Must have at least 1-3 years of experience with C/C++, Python coding or other high-level languages.\n",
      "3458 Excellent C/C++ programming and software design skills, including debugging, performance analysis, and test design.\n",
      "3459 Excellent Python skills, and a dedication to writing clean, understandable, testable code with an eye towards maintainability.\n",
      "3460 Experience with the following technologies is a huge plus: TVM, LLVM, ARM-NN, CMSIS-NN, RISC-V, ARM, OpenCL, deep learning models and algorithms, and deep learning framework design.\n",
      "3461 Note: Advanced knowledge of ReactJS, PostgreSQL, Python, C/C++, RESTful and AWS is strictly required\n",
      "3462 ReactJS\n",
      "3463 PostgreSQL\n",
      "3464 Python\n",
      "3465 C/C++\n",
      "3466 AWS\n",
      "3467 ReactJS: 1 year (Required)\n",
      "3468 PostgreSQL: 1 year (Required)\n",
      "3469 Python: 1 year (Required)\n",
      "3470 Expertise with Python building applications (not just script work)\n",
      "3471 Familiarity working with Linux environments\n",
      "3472 C++\n",
      "3473 AWS (S3, Lambda, RDS, Redshift, Boto3)\n",
      "3474 GCP (Storage, Functions)\n",
      "3475 OpenCV\n",
      "3476 Tensorflow/Keras or PyTorch\n",
      "3477 Vous serez amené à concevoir, développer et maintenir des applications en C++ et python sur des serveurs puissants CPU&GPU\n",
      "3478 - Très bon niveau en programmation C++ et python\n",
      "3479 - Bonne maitrise du langage SQL\n",
      "3480 - Maitrise de Linux\n",
      "3481 - Des connaissances en technologie web (ex: React) sont également un plus\n",
      "3482 Must have at least 1 year of experience with Deep Learning frameworks like PyTorch or TensorFlow.\n",
      "3483 Must have at least 3 years of industry experience with C/C++, Python coding or other high-level languages.\n",
      "3484 Unity or Unreal) and productivity software (word processors, spreadsheets, etc.)\n",
      "3485 Notable experience with JavaScript and React\n",
      "3486 Experience with SQL, databases, APIs and full stack solutions\n",
      "3487 Experience with Python and Django\n",
      "3488 Salesforce Marketing Cloud, CRM);\n",
      "3489 ETL tools, Self-service BI tools, preferably Tableau and PowerBI;\n",
      "3490 Data & Infrastructure Engineer, Google Cloud Platform\n",
      "3491 Cloud application and infrastructure architectures, including distributed storage, compute, serverless, and containerized Docker / Kubernetes applications\n",
      "3492 Linux (various distributions), GAE, GCE (GCP), Cloud Run.\n",
      "3493 Node.js\n",
      "3494 Tableau, Data Studio, Looker\n",
      "3495 Git (Github, BitBucket)\n",
      "3496 JIRA and Confluence\n",
      "3497 Terraform\n",
      "3498 CI/CD (Jenkins, DockerHub)\n",
      "3499 Docker / Kubernetes\n",
      "3500 Google Cloud Platform (preferred) or equivalent cloud experience:\n",
      "3501 Firebase, Firestore or equivalent key-value store, BigQuery\n",
      "3502 App Engine or equivalent cloud application deployment framework\n",
      "3503 Machine Learning APIs and frameworks (AutoML, Translation APIs, and others)\n",
      "3504 HTML 5 / CSS 3\n",
      "3505 JavaScript and front-end frameworks (Vue.js)\n",
      "3506 Python (Django / Flask)\n",
      "3507 Jenkins / Maven / Selenium\n",
      "3508 Google Cloud Platform (GCP): 3 years (Preferred)\n",
      "3509 AI and Analytics team is seeking an experienced AWS Architect with experience\n",
      "3510 Snowflake and/or Databricks\n",
      "3511 historical data counters to the new data platform (AWS / Databricks / Snowflake\n",
      "3512 and architect solutions on AWS and related technologies including Glue, EMR, S3\n",
      "3513 , Redshift, Snowflake and other relevant data services\n",
      "3514 and Develop applications using AWS Glue and EMR\n",
      "3515 migrating complex \"on-premise\" data warehouses, ideally Oracle, to\n",
      "3516 Snowflake and/or Databricks\n",
      "3517 depth understanding of Spark Architecture including Spark Core, Spark SQL, Data\n",
      "3518 Frames, Spark Streaming, RDD caching, Spark MLib.\n",
      "3519 in using Spark SQL with various data sources like JSON, Parquet and Key Value\n",
      "3520 Spark SQL/Scala\n",
      "3521 depth understanding of AWS and Data lake and Analytics solutions on AWS\n",
      "3522 Experience in Python\n",
      "3523 Experience with SQL\n",
      "3524 Experience with Spark 2.x or Pandas\n",
      "3525 Experience with Kubernetes in production\n",
      "3526 Advanced proficiency and technical expertise with Python\n",
      "3527 Development experience in Unix-based environments and proficiency in Unix shell scripting\n",
      "3528 Experience with containerized deployment technologies (specifically Docker)\n",
      "3529 Experience with Git and related source control concepts\n",
      "3530 Experience with Kubernetes\n",
      "3531 Tensorflow, Theano, Keras, PyTorch)\n",
      "3532 Expertise in Python and programming fundamentals\n",
      "3533 Expertise in RDBMS and intermediate/advanced SQL\n",
      "3534 Experience with Kubernetes in production\n",
      "3535 Experience with data processing engines such as Spark or Beam\n",
      "3536 Expérience avec au moins un des outils suivants : Tensorflow, Pytorch ou une boîte à outils d’apprentissage automatique similaire.\n",
      "3537 Experience with at least one of the following tools: Tensorflow, Pytorch, or a similar ML toolkit.\n",
      "3538 Expertise with data processing engines such as Apache Beam\n",
      "3539 Solid experience with JavaScript and React\n",
      "3540 Experience with SQL, databases, APIs, and full stack solutions\n",
      "3541 Experience with Python and Django\n",
      "3542 2+ years of experience with scientific programming languages such as Python and/or C++/C#\n",
      "3543 Avigilon, a Motorola Solutions company, designs, develops, and manufactures advanced AI, video analytics, network video management software and hardware, surveillance cameras, and access control solutions that help change the way people interact with their security systems.\n",
      "3544 Track the execution of features, releases, and initiatives using the Atlassian tool suite (JIRA, Confluence, etc) and produce appropriate metrics to visualize teams’ work and flow\n",
      "3545 Posséder une expérience avec Pytorch ou une boîte à outils d’apprentissage automatique similaire.\n",
      "3546 Experience with Pytorch or similar Machine Learning toolkit.\n",
      "3547 Experience with Gsuite, MacOS, Linux, Windows and Jamf Pro system\n",
      "3548 Prior working experience with technology vendors such as Amazon, Google, Salesforce will be an advantage.\n",
      "3549 3+ years of software engineering experience, preferably in Python\n",
      "3550 Strong Linux system administration skills and pride in the cleanliness and reproducibility of infrastructure\n",
      "3551 Familiarity with industry standards such as MLFlow, Kubeflow, and DVC\n",
      "3552 Experience with container orchestration systems such as Kubernetes (we use GKE)\n",
      "3553 Experience with TensorFlow, PyTorch, and image processing libraries such as OpenCV and scikit-image\n",
      "3554 Experience with Spark 2.x or later\n",
      "3555 Experience with pipelining/orchestration frameworks such as Airflow or Beam\n",
      "3556 Experience with hermetic build tools such as Bazel\n",
      "3557 10 years of software development experience with programming languages (C or C++), or 8 years with an advanced degree.\n",
      "3558 Experience applying modern C++ techniques and patterns to embedded software.\n",
      "3559 Hands-on experience with Kubernetes for a demanding project/product for at least one year\n",
      "3560 Using automation tools such as Terraform, Ansible, helm(file) for deploying, integrating infrastructure at least one public cloud\n",
      "3561 Good understanding of IP/Ethernet networking, especially HTTP protocol and UNIX systems\n",
      "3562 Experience in integrating and using monitoring and logging tools such as Prometheus, Grafana, Elastic\n",
      "3563 UNIX shell expertise\n",
      "3564 Intermediary level programming skills (in Python, Go) are plus\n",
      "3565 Solid experience with JavaScript and React\n",
      "3566 Experience with SQL, databases, APIs and full stack solutions\n",
      "3567 Experience with Python and Django\n",
      "3568 Proficiency in technical skills: Design Thinking, Microsoft Project, PowerPoint, Word, and Excel, Tableau\n",
      "3569 Knowledge of best practices and tools (Keyword Tool, Google Analytics / Search Console, Moz, SEMrush, Majestic…)\n",
      "3570 Knowledge of the Google Suite\n",
      "3571 Espresso Machine\n",
      "3572 Expertise in Python and programming fundamentals\n",
      "3573 Expertise in RDBMS and NoSQL\n",
      "3574 Experience with Kubernetes in production\n",
      "3575 Experience with data processing engines such as Spark or Beam\n",
      "3576 Have good understanding of mobile development for both iOS and Android\n",
      "3577 3+ years experience on ReactJS\n",
      "3578 1+ years experience on React Native development experience\n",
      "3579 3+ years experience on HTML, CSS, Bootstrap, Javascript.\n",
      "3580 2+ years experience on MEAN (MongoDB, Express, Angular, Node) experience\n",
      "3581 2+ years experience on Node.js experience\n",
      "3582 Experience working with a variety of SQL and NoSQL data stores (PostgresSQL, Aurora, Hadoop, DynamoDB, S3, BigQuery)\n",
      "3583 Experience with Git and Gitflow\n",
      "3584 Experience with TypeScript\n",
      "3585 Experience on LAMP (Linux, Apache, MySQL, PHP) Development considered an asset\n",
      "3586 Expertise in Python\n",
      "3587 Expertise with SQL\n",
      "3588 Expertise in Spark 2.x, Dataset/DataFrame API and performance tuning\n",
      "3589 Experience with Pandas\n",
      "3590 Experience with Airflow or other workflow management systems in a distributed setup\n",
      "3591 Experience with Kubernetes in production\n",
      "3592 Create and deliver value-based sales proposals to C-level decision makers.\n",
      "3593 Advanced knowledge of MS Word and Excel\n",
      "3594 Developers (Java, C++, C#, Python, Javascript/Typescript),\n",
      "3595 Infrastructure (Linux and Windows infrastructure, Quality assurance, Cyber Security, DevOPS, Cloud computing)\n",
      "3596 Establish a professional, working, and consultative, relationship with the client, up to and including the C-level for mid-to-large accounts, by developing a core understanding of the unique business needs of the client within their industry.\n",
      "3597 Strong experience of software engineering practices such as Agile, Devops, CI and CD and others.\n",
      "3598 Strong Coding skills in Python or other data mining tools\n",
      "3599 Highly proficient in Python with a strong technical background in Pandas dataframe\n",
      "3600 Highly proficient understanding of Flask microservice implementation\n",
      "3601 Highly proficient understanding of database design and development - especially PostgresSQL, MySQL, and SQLite3\n",
      "3602 Proficient in the React JS front end library\n",
      "3603 Experience with Docker containers is an asset\n",
      "3604 Experience with cluster computing technologies (Kubernetes, Spark) is an asset\n",
      "3605 Familiarity with GRPC and GraphQL is an asset\n",
      "3606 Familiarity with Golang and Kotlin is an asset\n",
      "3607 Familiarity with Git version control\n",
      "3608 Word, Excel, Access).\n",
      "3609 Good software engineering skills with Python, Linux shell scripting, and Java is required\n",
      "3610 Knowledge with C is a plus.\n",
      "3611 Experience with machine/deep learning frameworks such as SKLearns, Keras, PyTorch, and/or TensorFlow.\n",
      "3612 Experience with SQL and NoSQL to manage and analyze data in both traditional DBMS (MS-SQL, Oracle, mainframe) and Big Data environments (i.e., HADOOP, SPARK, or similar open source and commercial technologies)\n",
      "3613 Experience in building microservices leveraging various AWS features\n",
      "3614 Working knowledge of Python, and specifically PyTorch and/or TensorFlow\n",
      "3615 Expert knowledge of SQL and experience working with relational databases, including at least 5-10 years of experience with relational databases and ETL tools, at least 5 projects of at least 3 months, at least 2 large projects of 12 months or more, preferably more than one technology stack.\n",
      "3616 Java, Python, C#, or like)\n",
      "3617 Advanced working knowledge of designing and implementing Cloud technologies such as Azure, GCP and or AWS.\n",
      "3618 4+ years’ experience building software solutions in a corporate or start up engineering environment using any or all of the following: full-stack .Python, JavaScript, JavaScript, jQuery; server-side code development using .Net, C#; database design and development experience with SQL; architecting and establishing DevOps process using AWS and Azure cloud environment or related technologies\n",
      "3619 3+ years’ of front end technologies ranging from HTML, CSS, React / Ember / Angular, etc\n",
      "3620 Experience setting up, operating Azure and AWS DevOps pipelines\n",
      "3621 Lead developer and Architecture expertise focusing on .NET, Azure, AWS as well as Portal technologies\n",
      "3622 Deploy counter measures by writing and deploying SQL fraud rules and analyze impact\n",
      "3623 Monitoring evolving fraud clusters and propose new rule criteria using SQL\n",
      "3624 Data visualization through tableau, Python, etc.\n",
      "3625 Work with data in the AWS infrastructure leveraging new cloud technologies for report and model creation\n",
      "3626 Experience developing in one or more programming languages (SQL, Python, R, etc.)\n",
      "3627 Familiar with cloud platforms such as AWS or Azure\n",
      "3628 Deep learning tools: Tensorflow, PyTorch, Scikit-learn, Keras, Python Libraries\n",
      "3629 Familiarity with software development on AWS including serverless development experience including complex integrations with AWS Lambda, Amazon Elasticsearch, Amazon Redshift, Amazon Kinesis, and Amazon DynamoDB\n",
      "3630 Agile methodology: Scrum, Kanban, Sprints, Collaboration tools: Wiki or other\n",
      "3631 Version control systems: Git, GitLab, GitHub, Bitbucket\n",
      "3632 Continuous Integration: Jenkins\n",
      "3633 Proficiency in DevOps / MLOps Cloud infrastructure: OpenStack, AWS (Amazon Web Services), Azure, Google Cloud, Virtual Environments, Cloud Containers: Docker, Kubernetes\n",
      "3634 Expertise with Python (Pandas, SciKit, and similar) and Unix operating systems\n",
      "3635 Experience with SQL programming for data extraction\n",
      "3636 Proven software development experience and iOS skills development\n",
      "3637 Proven working experience in iOS app development\n",
      "3638 Having hands on experience with C, Swift\n",
      "3639 Having strong knowledge around security aspect of mobile development (SSL Pinning, App Universal Linking, encryption/decryption, Secure Key Chain for iOS\n",
      "3640 Experience with iOS SDK\n",
      "3641 Building clean, scalable, PHP (Laravel, Yii2) applications.\n",
      "3642 5+ years of experience on PHP and Laravel/Yii2\n",
      "3643 2+ years of experience with Elasticsearch\n",
      "3644 Knowledge and experience building data pipelines, SQL, ETL/ELT\n",
      "3645 Experience with Python, with some Artificial Intelligence exposure\n",
      "3646 Experience with CD/CI tools, such as Jenkins, Docker, or Terraform\n",
      "3647 Experience with AWS\n",
      "3648 Une solide compréhension des concepts fondamentaux du web et des navigateurs, ainsi que des concepts sémantiques du HTML, du CSS et du JavaScript\n",
      "3649 Expérience de JavaScript, Typescript et React (Redux et RxJS est un atout)\n",
      "3650 Connaissance pratique du Javascript, du Typecript et de React\n",
      "3651 A solid understanding in core web and browser concepts and semantic HTML, CSS, and core JavaScript concepts\n",
      "3652 Experience with JavaScript, Typescript and React (Redux and RxJS is an asset)\n",
      "3653 Working knowledge of Javascript, Typescript and React\n",
      "3654 Use Azure Services (e.g., Synapse, Data Bricks), ML platforms, and frameworks (e.g., MXNet, TensorFlow, PyTorch, SparkML, scikit-learn) to help our customers build ML models\n",
      "3655 Experience writing code in Python, R, Scala, Java, C with documentation for reproducibility.\n",
      "3656 Experience handling terabyte size datasets, diving into data to discover hidden patterns, using data visualization tools, writing SQL, and working with GPUs to develop models.\n",
      "3657 Technical understanding of data technology as it pertains to IIoT, from Cloud (Amazon, Azure Google Cloud, etc.) to tooling (Tableau, Python, TensorFlow) and emerging AutoML solutions.\n",
      "3658 Expertise with developing modular front end applications Client Side Technologies - XHTM/HTML5, CSS3, Bootstrap, , SASS, JavaScript, JS Framework, jQuery, MVC Frameworks – REACT, TDD, BDD, Jasmine, Karma, Protractor, ES6, Babble as compiler\n",
      "3659 Front-end testing (Jasmine, Mocha, Chai, QUnit, etc.)\n",
      "3660 CRM, WCM, etc.), specifically JavaScript/ REACT work with ADOBE AEM Framework.\n",
      "3661 Experience in Responsive/Adaptive Web Design (RWD/AWD) using CSS3, Bootstrap and CSS preprocessor like SCSS\n",
      "3662 Good hands on with TDD and BDD - Test and Behaviour Driven Development using Karma, Jasmine, Protractor, Selenium\n",
      "3663 Server side Integration knowledge backend Technologies - JAVA, JSP, JSF, MS SQL\n",
      "3664 Very much familiar with Web Design/Development Tools - DreamWeaver, Photoshop, Edit Plus, Eclipse, WebStorm as an IDE\n",
      "3665 Should be aware with ADOBE AEM as Web CMS, GIT as repository and Version Control Systems and JIRA as ALM\n",
      "3666 Intrusion Detection/Prevention (IDS/IPS)\n",
      "3667 Cloud technologies; AWS, Azure, GCP\n",
      "3668 Wireless, VPN, SDN, SaaS\n",
      "3669 Ipv4/v6 Routing Protocols (RIPv1/v2/v3, OSPFv2/v3, VRRP, MPLS, BGP, PIM, etc.)\n",
      "3670 Experienced in developing frontends using web technologies such as HTML 5, Javascript, CSS, React.js & UI frameworks\n",
      "3671 Experience in programming with Java, Spring framework and/or Node.js/Python with demonstrated ability to pick up new programming languages a big plus\n",
      "3672 Design experience of SQL and No-SQL database schema and well versed in data service/data lake usage\n",
      "3673 Hands on knowledge of source control (GIT), build automation (Jenkis), CICD (Chef, Docker) & Cloud-infra (Containers and Virtualization) usage\n",
      "3674 Au sein de l'équipe Foundation, vous serez l'expert pour tout ce qui touche à Kubernetes, Azure Cloud, CI/CD, aux microservices et aux pratiques DevOps\n",
      "3675 Contribuer au développement de la logique opérationnelle de nos solutions IA hébergées sur Kubernetes et Azure;\n",
      "3676 Compétence fonctionnelle sur Docker et orchestrateurs (p.ex\n",
      "3677 Kubernetes, Mesos, Swarm);\n",
      "3678 Expérience éprouvée d'un ou plusieurs langages de programmation; nous utilisons Python et Go;\n",
      "3679 Expérience en gestion automatisée de plateformes IaaS (Azure, AWS, GCP);\n",
      "3680 As a member of the Foundation team, you'll be a subject-matter expert as it relates to Kubernetes, OpenShift, containers, microservices and DevOps practices\n",
      "3681 Contribute to the development of the operational infrastructure of our AI solutions on Kubernetes and Azure;\n",
      "3682 Working experience with Docker and container orchestrators (Kubernetes , Mesos, Swarm);\n",
      "3683 Proven development experience with one or many programming languages; we're into Python and Go, and we welcome developers who want to learn;\n",
      "3684 Proven experience automating infrastructure deployments on IaaS platforms (Azure, AWS, GCP);\n",
      "3685 Specifically Cognos BI Suite, Microsoft SQL Server Services, MS Power BI (Query, View) or MicroStrategy\n",
      "3686 Experience and technical knowledge of SQL server architecture\n",
      "3687 Experience and technical knowledge of querying data with Transact-SQL\n",
      "3688 Experience and technical knowledge of implementing a SQL data warehouse\n",
      "3689 Knowledge of Google Drive Suite\n",
      "3690 Convey business, operational and functional requirements to the development teams in Jira as complete epics/stories with acceptance criteria\n",
      "3691 Experience with Google tools (doc, sheet, slides)\n",
      "3692 Experience with the Atlassian suite of tools (Jira and Confluence)\n",
      "3693 Experience with cloud technologies (Microsoft Azure, AWS, IBM cloud, etc.) - an asset\n",
      "3694 Experience with SABA cloud would be an asset.\n",
      "3695 Experience with Microsoft Office tools including MS Project, intermediate proficiency in Microsoft Excel, and skills in process mapping tools such as Visio\n",
      "3696 Background in the travel industry and with one or more of the major GDS platforms (e.g., Travelport, Amadeus, Sabre, etc.)\n",
      "3697 Technical experience with software development (Java, .NET GoLang.), AWS, GCP, Artificial Intelligence, and cloud computing.\n",
      "3698 Advanced Excel, PowerPoint and Word skills are a must\n",
      "3699 Experience with Google Suite products is an asset\n",
      "3700 4+ years’ experience building software solutions in a corporate or start up engineering environment using any or all of the following: Informatica, SQL, Webmethods, MDM, ESB and Siebel is also a nice to have\n",
      "3701 Experience setting up, operating ETL solutions and working with Informatica\n",
      "3702 Next to several years of experience as an iOS developer, you come with excellent knowledge of the platform and experience working with complex systems\n",
      "3703 Excellent knowledge of the iOS environment (5+ years)\n",
      "3704 Knowledge of Apple Human Interface Guidelines and iOS good practices\n",
      "3705 C++\n",
      "3706 ARKit/CoreML\n",
      "3707 Programming skills data science skills such as distributed computing, predictive modelling, story-telling and visualizing, Math, statistics and various forms of technological skills (R, SAS, Python, Matlab, SQL, Hive, Pig, Spark).\n",
      "3708 Advanced Knowledge of Excel.\n",
      "3709 One of the current team AOR is migrating petabytes of data from HBase to Druid and building Data access services on top of Druid to be used by other applications of highly loaded social platform.\n",
      "3710 Hands on experience with HBase\n",
      "3711 Strong Javascript skills\n",
      "3712 3+ years of experience with React.js\n",
      "3713 Knowledge of GraphQL\n",
      "3714 Strong Python skills\n",
      "3715 Strong working knowledge of Kubernetes – installation, maintenance and operational\n",
      "3716 Coding experience in one of Python, JavaScript or Java\n",
      "3717 Expertise in Git and Jenkins pipelines\n",
      "3718 Automation tools such as Ansible, Chef, Puppet, Terraform, etc.\n",
      "3719 Strong working knowledge of AWS\n",
      "3720 Familiarity with Azure & GCP\n",
      "3721 Experience on setting up monitoring infrastructure for bare-metal deployments as well as K8s\n",
      "3722 Common Linux server distributions (e.g\n",
      "3723 Redhat, Ubuntu, etc.)\n",
      "3724 Any experience with SAP AI/Automation/RPA capabilities will be extremely valuable\n",
      "3725 5+ years of hands on experience with Java\n",
      "3726 Experience in distributed systems and big data technologies (Hadoop, ZooKeeper, etc.)\n",
      "3727 Strong debugging skills in Linux environment for solving performance issues.\n",
      "3728 Flink and / or Spark Streaming\n",
      "3729 AWS\n",
      "3730 Terraform\n",
      "3731 2+ years of experience with AWS stack (VPC, EC2, S3, KMS, ECR, IAM, Lambda, CloudWatch)\n",
      "3732 Development experience with Python, or Ruby\n",
      "3733 Strong bash scripting skills\n",
      "3734 Strong understanding of Kubernetes ecosystem.\n",
      "3735 DBA for MySQL skills\n",
      "3736 Avigilon, a Motorola Solutions company, designs, develops, and manufactures advanced AI, video analytics, network video management software and hardware, surveillance cameras, and access control solutions that help change the way people interact with their security systems.\n",
      "3737 4+ years of experience in Python backend development\n",
      "3738 Strong understanding of Python tooling\n",
      "3739 Proficient in Linux package management and resolving native library dependencies\n",
      "3740 Proficient in AWS infrastructure and configuration management\n",
      "3741 Proficiency with Docker containers and Dockerfiles\n",
      "3742 o Javascript experience\n",
      "3743 5+ years of commercial development experience including Java or Scala\n",
      "3744 2+ years experience with Spark and Hive including understanding on how these technologies work under the hood\n",
      "3745 Experience with AWS\n",
      "3746 Python development experience\n",
      "3747 Proficient with MS Excel\n",
      "3748 Expérience de travail avec l’un des outils suivants : Tensorflow, Pytorch ou une boîte à outils ML similaire.\n",
      "3749 Practical experience of working with one of the following tools: Tensorflow, Pytorch, or a similar ML toolkit.\n",
      "3750 Computer literacy (Outlook, Word, Excel, Power Point)\n",
      "3751 Microsoft Office – Excel and PowerPoint\n",
      "3752 Looking for skilled full-stack Engineers who have experience in developing scalable solutions using .NET technologies in a highly collaborative Agile environment with strong experience in C#, ASP.net Core, Microservices, OData/Web API, Front End knowledge (JavaScript & React); Design and Develop software based on Agile SDLC methodology (standups, estimation, iterative development CI, demos, retrospectives); Stay abreast of new capabilities offered by open source tools and cloud services to proactively incorporate them within the platform; help in regression testing the outcome of sprint builds; push in adoption and implementation of Unit Testing and TDD.\n",
      "3753 Solid understanding of C#, Microsoft Visual Studio IDE, .NET Framework, ASP.NET, AJAX, Entity Framework and Front-end technologies like HTML/HTML5, CSS, Javascript, React, SQL etc.\n",
      "3754 Experience with Git, Third-Party SDK integrations, RESTful APIs, OAuth, JSON & Web Services\n",
      "3755 Des brainstormings avec nos Product Owners, des sessions d'architecture technique avec nos experts, du travail de développement à l'aide de notre pipeline Gitlab CI / CD, à l'expérimentation des technologies Big Data de pointe, vous apporterez les fonctionnalités de nos clients, de l'idée à la réalité\n",
      "3756 From brainstorms with our Product Owners, technical architecture sessions with our experts, development work using our Gitlab CI/CD pipeline, to experimenting with cutting edge big data technologies, you’ll bring our customers features from idea to reality\n",
      "3757 You will be helping our clients to resolve their most complicated data & analytics problems to build, maintain, improve or re-architect solutions on Snowflake\n",
      "3758 On an average day you will help our clients understand advantages and disadvantages of specific Snowflake Data architecture choices and provide subject matter expertise and lessons learned for your previous projects\n",
      "3759 Most importantly you will develop highly efficient teams of internal resources and guide their development journey on Snowflake.\n",
      "3760 3+ years of hands-on experience Snowflake (demonstrated via hands on, specific, project experience) with at least 1+ years using serverless architecture\n",
      "3761 Examples of coding in one of the following programming languages including but not limited to: C, C++, Java, JavaScript, or Python.\n",
      "3762 Experience with cloud-based ML, AI, data analytics such as Azure Cognitive Services/Google Cloud AI/IBM Watson/Amazon Machine Learning\n",
      "3763 Expertise with Java, JavaScript, HTML5, CSS, REST, SQL\n",
      "3764 Expertise with Javascript frameworks such as React, Angular or Polymer\n",
      "3765 Experience with C/C++/C#\n",
      "3766 Experience with SQL database design\n",
      "3767 Familiarity with building large-scale services on AWS and/or Azure cloud platforms\n",
      "3768 Experience with Node.js, Elasticsearch, Redis, Linux server deployment\n",
      "3769 Application development experience on one or more of iOS, Android and Windows platforms\n",
      "3770 Android-based, Microsoft HoloLens)\n",
      "3771 Experience with any of the following: Xamarin, XCode, MySQL (or similar), OpenGL, build/test automation, user interface design, web API creation, IoT solutions\n",
      "3772 AR development experience with Vuforia/ARCore/ARKit\n",
      "3773 Familiarity with Azure DevOps\n",
      "3774 Anaplan, Hyperion, Adaptative Insights, IBM\n",
      "3775 Strong technical focus with expertise in FP&A technology solution, such as TM1, Hyperion, and/or Anaplan, is required\n",
      "3776 Knowledge of Anaplan is preferred\n",
      "3777 Scripting experience in Shell, Perl, Python and TCL is a plus\n",
      "3778 Proficiency in Adobe XD, Adobe CC, Invision and/or related design, UX, UI, and prototyping apps\n",
      "3779 Familiarity with Agile methodology, JIRA, and Scrum work flow\n",
      "3780 Have a good understanding of machine learning, in particular, deep learning (e.g., TensorFlow)\n",
      "3781 Have experience with distributed computing platforms, such as Hadoop or Spark\n",
      "3782 5+ years of commercial development experience including Python\n",
      "3783 2+ years experience in one or more open-source Big Data technologies (Hadoop, Spark, Hive, Presto)\n",
      "3784 Experience with big data workflow orchestration engines for ETL jobs, such as Airflow\n",
      "3785 Knowledge of container and orchestration frameworks such as Docker and Kubernetes\n",
      "3786 Experience with AWS\n",
      "3787 Development experience of highly loaded and distributed systems using Java\n",
      "3788 Strong knowledge of JavaScript\n",
      "3789 3+ years of experience with React.js\n",
      "3790 Experience with GraphQL\n",
      "3791 NoSQL, MongoDB, ArangoDB, Redis\n",
      "3792 Azure\n",
      "3793 Docker/K8s\n",
      "3794 Linux\n",
      "3795 Jira\n",
      "3796 Demonstrated programming skills using languages such as Go, C, C++, Python, or other\n",
      "3797 Experience in a cloud-based environment with Azure, AWS, or GCP\n",
      "3798 Skills in Linux environment\n",
      "3799 Demonstrated ability to perform analytical functions and transform database structures including creating datasets and writing computer code to execute complex queries using statistical computer languages such as Python, R, and SQL.\n",
      "3800 Demonstrated proficiency working with large volumes of data across multiple servers using distributed data/computing tools such as Hadoop, Spark, MySQL, AWS, etc.\n",
      "3801 Demonstrated proficiency working with both relational (SQL) and non-relational databases (NoSQL).\n",
      "3802 Demonstrated ability to use web services such as Redshift, S3, DigitalOcean, etc.\n",
      "3803 Demonstrated skills in using data visualization tools (such as Jupyter, Matplotlib, D3, ggplot, Periscope, Business Objects) and to visually present complex data to stakeholders for consideration.\n",
      "3804 Experience with Python and Google Cloud Platform\n",
      "3805 7+ years of experience of finance transformation and Oracle implementation experience\n",
      "3806 Knowledge of Oracle EBS Financials and Oracle Cloud is highly preferred.\n",
      "3807 Knowledge of process flows (Level 1 – Level 5), business process modelling tools (Visio, Adonis), exposure to Lean and/or Six Sigma an asset.\n",
      "3808 Exceptional Oracle PL/SQL skills to troubleshoot issues.\n",
      "3809 Working knowledge of more than one programming language (Python, R, Java, C++ etc.)\n",
      "3810 Proven experience with SQL Server SSIS, SSRS, SSAS, T-SQL queries, stored procedures, user defined functions, triggers, index, view.\n",
      "3811 Good working knowledge of data presentation software such as PowerBI (preferred), Tableau, ClikView\n",
      "3812 SkillsSAS Visual Analytics, SAS Visual Investigator, Power BI, SQL TypeContract Project Description Experience Required/ Mandatory Skills\n",
      "3813 Experience with SQL (any or all: SQL Server, Oracle, Hive, Impala, PostgreSQL, MySQL, NoSQL, etc.)\n",
      "3814 Azure Data Storage - Cosmos DB, HD Insights, Databricks\n",
      "3815 5+ years relevant work experience with Azure large scale enterprise implementations\n",
      "3816 Excellent designing, programming and debugging skills in a scripting language; Python preferred.\n",
      "3817 Experience scaling ML training pipelines using Docker, Kubernetes, etc.\n",
      "3818 Experience with cloud services & architectures (AWS, Azure, etc.)\n",
      "3819 Proficiency with modern deep learning frameworks such as PyTorch and TensorFlow\n",
      "3820 Ability to write efficient, clean, and reusable code in Python and C++\n",
      "3821 Experience with Autodesk or similar products (CAD, CAE, CAM, etc.)\n",
      "3822 To do this, Ubuntu-optimized kernels are required to support a wide variety of large-memory Intel, AMD and ARM-based cloud instance types, with a broad array of GPGPUs and networking configurations.\n",
      "3823 A secure, high-performance Linux kernel is a crucial component of Canonical products for the success of our enterprise customers, partners and Ubuntu projects\n",
      "3824 The Canonical Kernel Team is responsible for maintaining all supported Ubuntu kernels in addition to driving development of the latest Ubuntu kernel for future Ubuntu releases\n",
      "3825 Maintaining Ubuntu kernel git repositories\n",
      "3826 Troubleshooting a wide variety of kernel engineering problems both in our development environment as well as our customer's Linux-based products.\n",
      "3827 Developing, reviewing and submitting Linux kernel patches\n",
      "3828 Demonstrable proficiency in C programming language\n",
      "3829 Solid scripting skills in Bash or Python (preferred)\n",
      "3830 Ubuntu/Debian packaging experience\n",
      "3831 Familiarity with the Ubuntu Kernel SRU process and cadence\n",
      "3832 Immersive media such as AR or VR\n",
      "3833 Basic knowledge of NRC-IRAP's mandate, mission and business model.\n",
      "3834 CRM\n",
      "3835 Proficient with MS Excel\n",
      "3836 WordPress\n",
      "3837 PowerPoint\n",
      "3838 CRM (Zendesk, Hubspot, etc.)\n",
      "3839 7+ years experience leading engagements from design to implementation of creative data solutions leveraging the latest in Big Data frameworks, supporting on-premise, cloud (AWS, Azure, GCP) and hybrid architectures to enable use cases in analytics and AI\n",
      "3840 7+ years experience architecting solutions for optimal extraction, transformation and loading of data from a wide variety of traditional and non-traditional sources such as structured, unstructured, and semi-structured using SQL, NoSQL and data pipelines for real-time, streaming, batch and on-demand workloads\n",
      "3841 4+ years of Ruby on Rails experience\n",
      "3842 Experience developing in Java\n",
      "3843 Understanding of common Java patterns\n",
      "3844 Basic understanding of SQL and key value stores\n",
      "3845 Expérience avec les environnements de développement comme Tensorflow, Keras et pytorch\n",
      "3846 Expertise en développement de logiciel en langage Python et C++\n",
      "3847 2D/3D Features Detection\n",
      "3848 Experience using frameworks like Tensorflow, Keras and/or pytorch\n",
      "3849 Expertise in software development using Python and C/C++\n",
      "3850 Current knowledge of AWS, Azure, and/or GCP\n",
      "3851 The ability to effectively present information and respond to questions from groups of managers, clients and teammates (you use PowerPoint and Excel with ease);\n",
      "3852 In-depth knowledge of programming/implementation ability in Python, C++ or other languages, familiarity with ML paradigms (e.g\n",
      "3853 TensorFlow)\n",
      "3854 IITB has a need for developers with many programming skills such as: Java, .Net, Cobol, MS-Dynamics, etc.\n",
      "3855 Experience programming with .NET (VB.NET, C#, ASP.NET and/or MVC)\n",
      "3856 Experience programming with Java\n",
      "3857 Experience scripting or programming with PL/SQL (Oracle)\n",
      "3858 Experience scripting with or programming with T-SQL (MS SQL Server)\n",
      "3859 Experience in Oracle Forms or Reports 10g and up\n",
      "3860 Experience in Oracle SOA or BPM suite\n",
      "3861 Experience in Oracle Portal Technologies (Oracle WebCenter)\n",
      "3862 Experience programming with COBOL (Unisys, IBM, etc.)\n",
      "3863 Experience in Java (Drools library)\n",
      "3864 Experience programming with SAP\n",
      "3865 Experience in robotic processing automation with Blue Prism and UiPath (Studio and Orchestrator) softwares\n",
      "3866 Experience in Windows server administration\n",
      "3867 Experience in Web Services (XML/WSDL/SOAP/REST/XSLT/API)\n",
      "3868 Experience programming with Python\n",
      "3869 Experience programming with HTML (CSS, JavaScript)\n",
      "3870 Experience in event messaging platform (Kafka, Solace)\n",
      "3871 Experience with Agile frameworks (Scrum, Lean, Kanban)\n",
      "3872 Experience with Azure DevOps (latest TFS)\n",
      "3873 Establish and maintain excellent relationships with C-level executives of key target clients and channel partners\n",
      "3874 We’re a C#, .NET, JavaScript, React, Elasticsearch, Kanban-ish, Bitbucket shop\n",
      "3875 Familiarity with ECMs like SharePoint, FileNet, etc\n",
      "3876 Azure ChatBot Developer\n",
      "3877  Should be strong in Python and NLP related packages\n",
      "3878  Proficiency in, at least, one object-oriented programming language such as C#, Python\n",
      "3879  Experience with one or more leading chatbot frameworks (IBM Watson, Google DailogFlow, Azure Bot Framework, LUIS, Amazon Lex, Alexa etc.)\n",
      "3880  Worked with APIs of Salesforce, SharePoint, CRM systems, CMS Systems\n",
      "3881  Experience contributing to projects via GitHub\n",
      "3882  Experience with relational databases and proficiency in using query languages such as SQL, Hive, Pig\n",
      "3883  Experience in developing web applications using Java, NodeJS, HTML, JavaScript, Angular...etc.\n",
      "3884  Knowledge of Big Data platforms like Hadoop and its eco-system (added advantage)\n",
      "3885 Write software programs using specific programming languages/platforms such as Java or MS .NET, and related tools, platform and environment\n",
      "3886 Minimum 3+ years of experience in core programming (C#, Visual Basic or Java), Web UI development (JavaScript, CSS, HTML), SQL, relational databases, API/Web service development and testing skills\n",
      "3887 You are a Cloud technology expert, bringing extensive experience with technologies such as GCP, AWS and Azure\n",
      "3888 You are well versed in infrastructure as code (such as Terraform), data pipelines, AI model implementation and microservices architecture\n",
      "3889 Basic drawing skills or experience with a graphics editor like GIMP\n",
      "3890 Basic programming skills in C, C++ ou C#\n",
      "3891 Compétences de base en programmation en C, C++ ou C#\n",
      "3892 Azure, AWS, GCP)\n",
      "3893 3-5 years’ experience in development using Java, Python, or C# (or similar language)\n",
      "3894 3+ years implementation experience with data governance technologies such as Collibra, Informatica AXON, Alation and/or IBM IGC\n",
      "3895 Experience writing complex SQL queries, extracting and importing disparate data from source systems, and data manipulation based on requirements, ideally using Agile development methods in data-oriented projects\n",
      "3896 Proficient in MS SQL (query skills, table structure and relational databases)\n",
      "3897 Ability to establish relationships on C-level and to act as their trusted advisor for IT to business alignment and IT governance related matters.\n",
      "3898 Experience in SQL or similar languages\n",
      "3899 Development experience in at least one object-oriented language (Python, Perl, Java, etc.)\n",
      "3900 Experience with data sets, Hive, and data visualization tools\n",
      "3901 Expérience en SQL ou langages similaires\n",
      "3902 Expérience de développement dans au moins un langage orienté objet (Python, Perl, Java, etc.)\n",
      "3903 Expérience avec les ensembles de données, Hive et les outils de visualisation de données\n",
      "3904 The successful candidate will have a 5 - 7 years proven track record in strategic selling to C level executives, demonstrate strong interpersonal and communications skills, demonstrated team building, leadership and the ability to manage multiple complex sales engagements concurrently\n",
      "3905 Maintenir et améliorer notre code DevOps interne écrit dans différents langages (Bash, Python, Go).\n",
      "3906 Maintain and improve our in-house DevOps code written in different languages (Bash, Python, Go).\n",
      "3907 Strong Technical foundation of Web Content Management and AEM centric development of Web Components in HTL, Editable Templates, Sling Models, Workflows and Backend Java OSGI Services\n",
      "3908 Knowledge of developing on AEM following principles of ReactJS Framework and leveraging the AEM SPA Editor\n",
      "3909 Proficiency in Apache Sling, JCR Repository and Apache Felix OSGi Framework\n",
      "3910 Experience with Adobe Marketing Cloud Products such as Adobe Analytics, Adobe Target, Adobe Audience Manager and Adobe Launch\n",
      "3911 Des brainstormings avec nos Product Owners, des sessions d'architecture technique avec nos experts, du travail de développement à l'aide de notre pipeline Gitlab CI / CD, à l'expérimentation de technologies Big Data de pointe, vous apporterez les fonctionnalités de nos clients, de l'idée à la réalité\n",
      "3912 From brainstorms with our Product Owners, technical architecture sessions with our experts, development work using our Gitlab CI/CD pipeline, to experimenting with cutting edge big data technologies, you’ll bring our customers features from idea to reality\n",
      "3913 Maintenir et améliorer notre code DevOps interne écrit dans différents langages (Bash, Python, Go).\n",
      "3914 Maintain and improve our in-house DevOps code written in different languages (Bash, Python, Go).\n",
      "3915 Experience in target environments like Windows, Windows Azure, iOS, Android and Web browsers.\n",
      "3916 Experience and working knowledge of databases, preferably MS SQL Server.\n",
      "3917 Scripting and programming skills in .Net framework, JavaScript, VBScript, C++, C#, SQL\n",
      "3918 (Java and Python a plus).\n",
      "3919 Experience with Visual Studio, Git, and SVN.\n",
      "3920 Solid background in Object Oriented design and development in Python/Cython\n",
      "3921 Experienced with Pythonic program development.\n",
      "3922 Strong background and experienced with Python libraries specifically the ones related to computing, data analytics, and data visualization.\n",
      "3923 Experience in Web application development using FLASK/Django and SQL Server.\n",
      "3924 Familiar with Kubernetes and new deployment methods.\n",
      "3925 Familiar with Git and related tools like GitHub, GitLab, etc.\n",
      "3926 Familiar with front-end development and having a good understanding of JavaScript and CSS\n",
      "3927 (familiarity with front-end platforms like React an asset).\n",
      "3928 Experience with Azure, Webjobs SDK, Azure functions an asset.\n",
      "3929 Good knowledge of the Python programming language and data analysis and machine learning libraries such as pandas, scikit-learn, PyTorch, TensorFlow.\n",
      "3930 Asset: knowledge of other programming languages such as Java, C, C++, Scala\n",
      "3931 Asset: knowledge of commercial data science platforms (e.g., Microsoft Azure ML, Amazon SageMaker, RapidMiner)\n",
      "3932 Asset: knowledge of relational (e.g., SQL) and non-relational (e.g., MongoDB) databases\n",
      "3933 Experience in C/C++, Java, Perl, or PHP\n",
      "3934 Experience in scripting languages such as Perl, PHP, Python, and shell scripts\n",
      "3935 Experience with Hadoop/Hbase/Pig or Mapreduce/Sawzall/Bigtable\n",
      "3936 As compiler engineer, you will be responsible for developing compiler optimizations for our state-of-the-art spatial compiler - targeting Groq's revolutionary Tensor Streaming Processor\n",
      "3937 Experience with LLVM and MLIR preferred, and knowledge with functional programming languages an asset\n",
      "3938 Also, knowledge with ML frameworks such as TensorFlow and PyTorch, and portable graph models such as ONNX desired.\n",
      "3939 1+ year of experience with C/C++ or Python programming\n",
      "3940 Experience with ML frameworks such as TensorFlow or PyTorch desired\n",
      "3941 Describe in detail how you leveraged at least 3 out of these 2 components: Azure Data Factory, Azure Event Hub, Databricks\n",
      "3942 1+ years of hands-on experience with data ingestion on Azure\n",
      "3943 5+ years hands-on experience in customer support involving database in Unix/Linux environment\n",
      "3944 Experience successfully delivering technical projects in customer and marketing related areas such with CRM ecosystem (Salesforce, MS Dynamics 365, Blackbaud), Master-Data-Management platforms (MDM) that focus on customer domain, CDP (Customer Data Platform used for Marketing), Customer Warehouse design, build and applications\n",
      "3945 3+ years of experience with scientific programming languages such as Python, R, and/or C++/C#.\n",
      "3946 Hive / Hadoop/ Spark) & cloud technologies (e.g\n",
      "3947 AWS Sagemaker, AzureML).\n",
      "3948 R, Python, SQL) and machine learning /deep learning algorithms/packages (e.g\n",
      "3949 XGBoost, H2O, SparkML).\n",
      "3950 Familiar with Figma as well to Invision/Sketch, with the ability to generate the required html/css elements.\n",
      "3951 Front end coding in AngularJS and ReactJS\n",
      "3952 Développer des logiciels en C++ en appliquant les principes de développement orientés objet ;\n",
      "3953 Excellente maîtrise de C++ ;\n",
      "3954 Develop software in C ++ by applying object-oriented development principles;\n",
      "3955 Excellent command of C ++;\n",
      "3956 Gather requirements and write technical specifications for major new features on our mobile Flutter application\n",
      "3957 Lead the development of complex features on our mobile Flutter application\n",
      "3958 Experience in iOS and/or Android software development\n",
      "3959 Experience in Flutter software development\n",
      "3960 Experience with Apple Health and/or Google Fit\n",
      "3961 1~2 years of hands-on experience in Amazon Web Services including Lambda, ECS/Fargate, Kinesis, DynamoDB\n",
      "3962 Proficient and hands on with at least one programming language, prefer Python/Java\n",
      "3963 Familiar with docker container technology\n",
      "3964 Nice to have: Infrastructure as code experience, such as Terraform or CloudFormation\n",
      "3965 Proficiency with Python\n",
      "3966 Strong experience of software engineering practices such as Agile, Devops, CI/CD and others tools such as GitHub, GitLab, Jenkins, Jira, Confluence, …\n",
      "3967 Strong experience with machine learning and scientific computing libraries such as scikit-learn, NumPy, SciPy, Weka, etc.\n",
      "3968 A good knowledge of DevOps modern tools such as Docker, OpenShift, Kubernetes, ELK, Jenkins;\n",
      "3969 Knowledge of the development technologies such as MongoDB, Kafka, RabbitMQ,…\n",
      "3970 Knowledge of a deep learning framework such as Tensorflow, Caffe2, PyTorch or other.\n",
      "3971 / Staff Compiler Engineer, you will be responsible for defining and developing compiler optimizations for our state-of-the-art spatial compiler - targeting Groq's revolutionary Tensor Streaming Processor\n",
      "3972 Experience with LLVM and MLIR preferred, and knowledge with functional programming languages an asset\n",
      "3973 Also, knowledge with ML frameworks such as TensorFlow and PyTorch, and portable graph models such as ONNX desired.\n",
      "3974 5+ years of direct experience with C/C++ and LLVM or compiler frameworks\n",
      "3975 Experience with ML frameworks such as TensorFlow or PyTorch desired\n",
      "3976 Has at least 2 years hands-on project working experience with GCP technologies; Data Lake, Data Proc, BigQuery, Cloud CDN, Cloud Run, Cloud SDK, Compute Engine etc.\n",
      "3977 Experience with Linux internals and hardening\n",
      "3978 Experience with OWASP, ATT&CK Framework, DAST, and SAST\n",
      "3979 Must have experience in programming languages and frameworks such as Python and Django\n",
      "3980 La solution est composée de plusieurs modules dont une application SPA Angular, un backend .NET Core, 2 applications mobiles Xamarin, un module d'optimisation qui utilise le paradigme de programmation par contraintes (CSP) et beaucoup d'autres.\n",
      "3981 (C#, Typescript & Javascript)\n",
      "3982 Participer aux déploiements de l'application dans Azure.\n",
      "3983 Minimum de trois années d'expérience avec les langages C# et Typescript\n",
      "3984 Avoir complété au minimum un projet web utilisant un framework TypeScript/JavaScript moderne (tel qu'Angular, AureliaJS, React, etc..)\n",
      "3985 Expérience sur un projet utilisant les services Azure tel que : Azure SQL, App Services, Redis, etc..\n",
      "3986 Connaissance approfondie d'ASP.net MVC Core / Angular /Javascript / HTML / CSS / API REST\n",
      "3987 Most importantly you will develop highly efficient teams of internal resources and guide their development journey on Azure cloud.\n",
      "3988 3+ years of hands-on experience Microsoft Azure (demonstrated via hands on, specific, project experience) with at least 1+ years using serverless architecture\n",
      "3989 Has at least 2 years hands-on project working experience with GCP technologies; Data Lake, Data Proc, BigQuery, Cloud CDN, Cloud Run, Cloud SDK, Compute Engine etc.\n",
      "3990 Solid foundation in at least two programming languages (Python, Java, C/C++, etc.).\n",
      "3991 Familiar with PyTorch and TensorFlow.\n",
      "3992 Excellent software engineering skills in Python\n",
      "3993 Strong experience with TensorFlow, PyTorch, Scikit-learn, and image processing libraries such as OpenCV and Scikit-image\n",
      "3994 Experience with distributed data processing frameworks such as Apache Spark or Apache Beam\n",
      "3995 Familiarity with reference architectures on Google Cloud Platform\n",
      "3996 Familiarity with modern container orchestration systems such as Kubernetes\n",
      "3997 1~2 years of hands-on experience in Amazon Web Services including Lambda, ECS/Fargate, Kinesis, DynamoDB\n",
      "3998 Proficient and hands on with at least one programming language, prefer Python/Java\n",
      "3999 Experience in object-oriented programming languages such as Python, Java, etc.\n",
      "4000 Experience with test automation framework/tools such as Selenium WebDriver, Robot, etc.\n",
      "4001 Experience with continuous integration tools, such as Jenkins\n",
      "4002 Experience with performance testing tools such as JMeter, Locust, etc\n",
      "4003 Programming experience in one of the following languages: Python, C#, C++, or Java\n",
      "4004 Experience in one of the following libraries: TensorFlow or PyTorch\n",
      "4005 Avigilon, a Motorola Solutions company, designs, develops, and manufactures advanced AI, video analytics, network video management software and hardware, surveillance cameras, and access control solutions that help change the way people interact with their security systems.\n",
      "4006 Automation Tools: Gitlab and Jenkins\n",
      "4007 Languages: Java, Python, Ruby, Bash\n",
      "4008 Cloud Infrastructure: GCP (AWS is a plus)\n",
      "4009 Containerization: Docker and Kubernetes\n",
      "4010 Monitoring Tools: GCP Monitoring, Prometheus, ELK Stack, SonarCloud\n",
      "4011 Operating System Knowledge: Linux, Windows\n",
      "4012 Working on identifying and improving the build and deployment pipelines in GitLab and Jenkins\n",
      "4013 Documenting all the areas of work to ensure proper understanding and recreation of activities using JIRA and Confluence\n",
      "4014 Creating dashboard and monitoring resources, tasks and infrastructure with SonarCloud, GCP Monitoring and Prometheus\n",
      "4015 The work spans integration of sensors at the hardware/MIPI bus-level, through Linux driver, multimedia framework, and Hardware Abstraction Libraries.\n",
      "4016 Practical Linux kernel driver development experience is a firm requirement\n",
      "4017 Fix issues and provide technical guidance on a Linux kernel driver and Linux multimedia framework issues.\n",
      "4018 Experience with embedded processors, hardware interfaces, communication protocols, multi-threaded programming, Linux, or equivalent system testing.\n",
      "4019 Proven experience in OpenGLES, OpenCV is a plus.\n",
      "4020 Proficiency in Python/C/C++ language.\n",
      "4021 Familiarity with UNIX operating systems\n",
      "4022 Scripting language(s): PERL, python, TCL\n",
      "4023 Experience working with XML and familiar with XML modeling\n",
      "4024 Experience with Enterprise systems management, IT operations, Server platform infrastructure (Microsoft Windows and/ or Unix) Delivery\n",
      "4025 Ability to program in pertinent languages, such as Excel, C++, VBA, Python, SAS and MATLAB\n",
      "4026 Strong background in Linux/Unix administration;\n",
      "4027 Working experience with cloud environments (AWS, Azure, GCP);\n",
      "4028 Strong working knowledge of containers and orchestration (Docker + Kubernetes)\n",
      "4029 Experience with automation/configuration management using either Ansible, Chef, or an equivalent;\n",
      "4030 Experience with Terraform;\n",
      "4031 Experience with Jenkins;\n",
      "4032 Experience with ArgoCD, Spinnaker, or similar CD tools is a plus;\n",
      "4033 Working understanding of code and scripting (Node.js, PHP, Python, Go);\n",
      "4034 Familiar with MongoDB, Elasticsearch, Redis, and PostgreSQL;\n",
      "4035 Deep technical experience in more than one of the following areas: VMware solutions (vCenter, ESXi, vSAN, NSX, SRM, Horizon), NetApp, Nutanix, or data center solutions from Dell, HPE, Lenovo, or other major vendors\n",
      "4036 Hands on experience with public cloud solutions from Azure, AWS, or Google\n",
      "4037 Unity or Unreal), productivity software (word processors, spreadsheets, etc.) & familiarity with project management software (e.g\n",
      "4038 Jira) \n",
      "4039 Photoshop) and 3D software (e.g\n",
      "4040 Expérience solide avec Typescript ou JavaScript : 5 années ou plus;\n",
      "4041 Connaissance solide de frameworks modernes côté client, comme React, Angular 2+, etc.;\n",
      "4042 Connaissance approfondie des normes Web actuelles : HTML5, CSS3, ES2016;\n",
      "4043 Expérience à livrer des applications front-end dans des environnements de production (workflow Git, systèmes CI/CD comme Jenkins, CircleCI, etc.);\n",
      "4044 Expérience avec des langages de programmation parmi les suivants : Python, Java, Go, C/C++, etc;\n",
      "4045 Strong Typescript or Javascript background: 5 years or more;\n",
      "4046 Strong knowledge of a few modern client-side frameworks such as React, Angular 2+, etc.;\n",
      "4047 Extensive knowledge of modern web standards, HTML5, CSS3, ES2016;\n",
      "4048 Experience delivering frontend applications into production environments (Git workflow, CI/CD systems like Jenkins, CircleCI, etc);\n",
      "4049 Knowledge of languages among: Python, Java, Go, C/C++, etc;\n",
      "4050 Ability to program in pertinent languages, such as Excel, SAS, R, and python\n",
      "4051 Unity or Unreal) and productivity software (word processors, spreadsheets, etc.)\n",
      "4052 Experience with scripting and programming using several of the following: Perl, C, C++, TCL, Scheme, Skill and Make.\n",
      "4053 Avigilon, a Motorola Solutions company, designs, develops, and manufactures advanced AI, video analytics, network video management software and hardware, surveillance cameras, and access control solutions that help change the way people interact with their security systems.\n",
      "4054 Ability to use Microsoft Office Products such as Word and Excel or equivalent software\n",
      "4055 Unity or Unreal) and productivity software (word processors, spreadsheets, etc.)\n",
      "4056 Very strong communication skills – written, verbal and overall – very strong in executive presentation skills, working with communication tools such as MS Powerpoint, Word and other toolsets\n",
      "4057 +4 year Experience on Angular or other JS language\n",
      "4058 +4 years Java Programming or\n",
      "4059 +5 years in Jenkins/ Dev Ops.\n",
      "4060 Good solid SQL skills.\n",
      "4061 From working in Unreal Engine to prototype and implement new features to thinking of clever ways to keep track of our ever-expanding library of assets, the ideal candidate will thrive in a position where they can wear many hats and collaborate with as many team members as possible\n",
      "4062 Skilled in Python, SQLite, VEX, MAXScript/MEL, JSON, and/or other comparable languages and formats.\n",
      "4063 Strong understanding of lighting and materials in real-time rendering, Unreal Engine 4 preferred.\n",
      "4064 Working knowledge of real-time performance optimization techniques, particularly in Unreal Engine 4.\n",
      "4065 Experience developing and organizing systems in Unreal Engine Blueprints.\n",
      "4066 Excellent knowledge of Microsoft Word, Excel, and PowerPoint.\n",
      "4067 Love and hate for at least 2 client-side JavaScript frameworks\n",
      "4068 Expertise with ReactJS\n",
      "4069 Strong skills in using modern software practice and tools such as git, Jenkins, containers\n",
      "4070 Strong expertise in at least 2 languages such as Javascript, Java, Python, Go-lang, Scala\n",
      "4071 Avoir une connaissance avancée du langage Python, de ses principaux « frameworks » et outils ;\n",
      "4072 Avoir des connaissances dans les bases de données relationnelles et NoSQL ;\n",
      "4073 Maîtrise des systèmes Linux et versionnement avec Git\n",
      "4074 Expérience avec Ansible, Docker, ElasticSearch, Kubernetes, OpenStack, Slurm,Postman (ou Swagger), Swarm ou des outils équivalents ;\n",
      "4075 Connaissances intermédiaires des langages JavaScript, Java et C++ ;\n",
      "4076 Maîtrise de l’UML ;\n",
      "4077 Connaissances reliées à nos domaines d’expertises : · Librairies transversales à l’apprentissage automatique : PyTorch, ScikitLearn ; · Librairies reliées au TALN : Spacy, Transformers d’HuggingFace ; · Librairies reliées au traitement de la parole : Chaîne d’outils de traitement du signal audio (Kaldi et/ou PyKaldi) · Librairies reliées à la recherche opérationnelles : Solveurs CBC, MIPCL, Choco, OR-Tools, IBM ILOG CP, CPLEX.\n",
      "4078 Must have an advanced knowledge of the Python language, and its main ‘’frameworks“ and tools;\n",
      "4079 Proficiency in relational and NoSQL databases;\n",
      "4080 Mastery with Linux systems and versioning with Git\n",
      "4081 Experience with Ansible, Docker, ElasticSearch, Kubernetes, OpenStack, Slurm, Postman (or Swagger), Swarm or with similar tools;\n",
      "4082 Intermediate knowledge of JavaScript, Java and C++ languages;\n",
      "4083 Profiency with UML;\n",
      "4084 Knowledge related to our areas of expertise:· Libraries transversal to machine learning: PyTorch, ScikitLearn; · Libraries linked to NLP: Spacy, Transformers of HuggingFace; · Libraries related to speech processing: Chain of audio signal processing tools (Kaldi and/or PyKaldi) · Libraries linked to operational research: CBC Solvers, MIPCL, Choco, OR-Tools, IBM ILOG CP, CPLEX.\n",
      "4085 Experience developing machine learning algorithms or machine learning infrastructure in Python or C/C++\n",
      "4086 Strong PowerPoint skills and experience with Excel preferred\n",
      "4087 Excellent knowledge of DevOps modern tools such as Kubernetes, Docker, OpenShift, ELK, Jenkins, GitLab, BitBucket, GitHub or any other Git-based source code management tool.\n",
      "4088 Experience in modern tools such as MAAS, JUJU, CEPH (asset)\n",
      "4089 Good knowledge of Active Directory, authentication protocols like LDAP, Kerberos and their integration with UNIX/Kubernetes (Keystone and Dex) (asset)\n",
      "4090 Experience in automation scripts creation for infrastructure components (python, groovy, Ansible, bash or any other relevant language)\n",
      "4091 Experience with monitoring tools such as SysDig, Kibanna, etc\n",
      "4092 Experience with No SQL databases like MongoDB (asset)\n",
      "4093 6+ years’ experience building software solutions in a corporate or start up engineering environment using JavaScript, Ruby, Python and/or Java / C#, etc.\n",
      "4094 6+ years’ experience developing web applications leveraging frameworks (Django, Ruby on Rails, etc.)\n",
      "4095 6+ years of front end technologies ranging from HTML, CSS, React, Javascript, jQuery, Redux\n",
      "4096 Linux system knowledge and scripting in a linux environment\n",
      "4097 Working knowledge of Kubernetes – installation, maintenance and operational\n",
      "4098 Familiarity with AWS\n",
      "4099 Experience working in a Cloud environment such as AWS, Azure, or GCP\n",
      "4100 Familiarity with AWS tools and services (e.g\n",
      "4101 EC2 and S3)\n",
      "4102 Proficiency in one of the following programming languages: Javascript, Python or Go\n",
      "4103 Experience with containers, Kubernetes and/or similar technology\n",
      "4104 Proficient understanding of code versioning tools such as Git/Github and continuous integration tools (e.g\n",
      "4105 Jenkins and CircleCI)\n",
      "4106 Relational Databases (MySQL, PostgreSQL, Oracle)\n",
      "4107 Hadoop (Hive, Impala, HDFS)\n",
      "4108 Microservices, Docker, and Git\n",
      "4109 Bash\n",
      "4110 Ansible\n",
      "4111 Bases de données relationnelles (MySQL, PostgreSQL, Oracle)\n",
      "4112 Hadoop (Hive, Impala, HDFS)\n",
      "4113 Microservices, Docker et Git\n",
      "4114 Ansible\n",
      "4115 Work with Devops Teams to understand impacts of branches and code merges\n",
      "4116 Experience with Git, AZURE Devops or Jenkins or any other CI/CD Tools\n",
      "4117 Develop server-side software for Augmentative and Alternative Communication (AAC) solutions on iOS mobile platforms (iPhone and iPad).\n",
      "4118 AWS cloud architecture (S3, EC2, Lambda, API Gateway, Polly, DynamoDB, GraphQL)\n",
      "4119 Containers (Docker)\n",
      "4120 Server-side Javascript with nodejs\n",
      "4121 One or more of Postgresql, Mongo, AuroraDB, MySQL\n",
      "4122 OAuth architectures (Auth0)\n",
      "4123 Angular, vue.js)\n",
      "4124 Heroku\n",
      "4125 C++, Python\n",
      "4126 iOS mobile development\n",
      "4127 Arduino) using C++ or C\n",
      "4128 ReactJS or other)\n",
      "4129 Exceptional communication and presentations skills that build confidence and credibility with C and VP-level executives.\n",
      "4130 Experience with design and verification tools (VCS or equivalent simulation tools, debug tools like Debussy, GDB).\n",
      "4131 Perl and C/C++ programming language experience desirable.\n",
      "4132 Hands-on experience in Unix/Linux, and statistical approaches to analyze and visualize data sets\n",
      "4133 Unix/Linux: 3 years (Required)\n",
      "4134 Strong Microsoft Office skills (Excel; Word; PowerPoint).\n",
      "4135 Experience developing machine learning algorithms or machine learning infrastructure in Python or C/C++\n",
      "4136 Develop software for Augmentative and Alternative Communication (AAC) solutions on iOS mobile platforms (iPhone and iPad).\n",
      "4137 Develop, test, document and deploy iOS code using Xcode in Swift\n",
      "4138 iOS\n",
      "4139 Javascript, Python\n",
      "4140 Angular)\n",
      "4141 Arduino) using C++ or C\n",
      "4142 One or more of Postgresql, DynamoDB, MySQL\n",
      "4143 Server-side Javascript (nodejs)\n",
      "4144 Reactive frameworks (ReactJS, RXSwift or other)\n",
      "4145 AWS (S3, EC2, Lambda, API Gateway, Polly, DynamoDB, GraphQL)\n",
      "4146 Au sein de l'équipe Foundation, vous serez l'expert pour tout ce qui touche à Kubernetes, Azure Cloud, CI/CD, aux microservices et aux pratiques DevOps\n",
      "4147 Contribuer au développement de la logique opérationnelle de nos solutions IA hébergées sur Kubernetes et Azure;\n",
      "4148 Compétence fonctionnelle sur Docker et orchestrateurs (p.ex\n",
      "4149 Kubernetes, Mesos, Swarm);\n",
      "4150 Expérience éprouvée d'un ou plusieurs langages de programmation; nous utilisons Python et Go;\n",
      "4151 Expérience en gestion automatisée de plateformes IaaS (Azure, AWS, GCP);\n",
      "4152 As a member of the Foundation team, you'll be a subject-matter expert as it relates to Kubernetes, OpenShift, containers, microservices and DevOps practices\n",
      "4153 Contribute to the development of the operational infrastructure of our AI solutions on Kubernetes and Azure;\n",
      "4154 Working experience with Docker and container orchestrators (Kubernetes , Mesos, Swarm);\n",
      "4155 Proven development experience with one or many programming languages; we're into Python and Go, and we welcome developers who want to learn;\n",
      "4156 Proven experience automating infrastructure deployments on IaaS platforms (Azure, AWS, GCP);\n",
      "4157 Scripting and prototyping languages: Python, C/C++\n",
      "4158 Generic packages: OpenCV, Pytorch\n",
      "4159 Experience with Linux\n",
      "4160 5+ years of commercial development experience including Python\n",
      "4161 2+ years experience in one or more open-source Big Data technologies (Hadoop, Spark, Hive, Presto)\n",
      "4162 Experience with big data workflow orchestration engines for ETL jobs, such as Airflow\n",
      "4163 Knowledge of container and orchestration frameworks such as Docker and Kubernetes\n",
      "4164 Experience with AWS\n",
      "4165 Development experience of highly loaded and distributed systems using Java\n",
      "4166 Experience with programming in Java, C++ or other languages\n",
      "4167 Design, build, and maintain high performance, reusable, and reliable Java code\n",
      "4168 Strong knowledge of Kotlin, Android SDK, different versions of Android, and how to deal with different screen sizes\n",
      "4169 Familiarity with RESTful APIs to connect Android applications to back-end services\n",
      "4170 Strong knowledge of Android UI design principles, patterns, and best practices\n",
      "4171 Knowledge of the open-source Android ecosystem and the libraries available for common tasks\n",
      "4172 Understanding of Google’s Android design principles and interface guidelines\n",
      "4173 Proficient understanding of code versioning tools, such as Git\n",
      "4174 Très bonnes connaissances des langages C# et C++;\n",
      "4175 Very good knowledge of C++ and C#;\n",
      "4176 Avigilon, a Motorola Solutions company, designs, develops, and manufactures advanced AI, video analytics, network video management software and hardware, surveillance cameras, and access control solutions that help change the way people interact with their security systems.\n",
      "4177 Avigilon’s analytic based, video surveillance software interfaces to a variety of external systems, including mobile, web, cloud, and 3rd party systems\n",
      "4178 Experience with JavaScript ES6 in a Node.js environment.\n",
      "4179 Experience with C++ is also an asset.\n",
      "4180 Must have: JavaScript ES6 and Node.js\n",
      "4181 Google Protobuf, WebRTC, STUN, and TURN\n",
      "4182 3+ years of JavaScript experience building web applications, HTML/CSS experience, including concepts like layout, specificity, cross browser compatibility, and accessibility\n",
      "4183 2+ years with experience in the development of the Front-End React and React Native applications\n",
      "4184 3+ years experience with browser APIs and optimizing front end performance with backend development in Node.js building API / Microservices.\n",
      "4185 Mustache, Handlebars, Jade)\n",
      "4186 Experience with source control and working with data-handling using AJAX, JSON, and REST API\n",
      "4187 Experience with Conversational Interfaces (IVR, Alexa, SMS, Google Assistant), Artificial Intelligence, Data Science, and Augmented/Mixed/Virtual Reality would be a massive asset\n",
      "4188 Comfort and experience prototyping with controller boards, like Raspberry Pi or Arduino, is always helpful\n",
      "4189 Avigilon designs, develops, and manufactures video analytics, network video management software and hardware, surveillance cameras, and access control solutions\n",
      "4190 Avigilon’s analytic based, video surveillance software interfaces to a variety of Avigilon and 3rd party cameras, and other sensors\n",
      "4191 Demonstrated C++ design and programming ability.\n",
      "4192 C++ v11/v14 in a Windows or Linux Environment.\n",
      "4193 Working with servers and serverless technologies like AWS Lambda, Azure Functions, Google Cloud Functions, IBM OpenWhisk, or Auth0 WebTask;\n",
      "4194 Excellent knowledge and demonstrated experience with Node.js and Typescript;\n",
      "4195 Experience working in cloud based technologies such as AWS and Azure;\n",
      "4196 Python and Angular (Full Stack) will be considered an asset;\n",
      "4197 Experience from working in an Agile environment, using Devops and CI/CD.\n",
      "4198 Strong knowledge and ability in C++, as well as a deep understanding of algorithms and data structures\n",
      "4199 Experience with source code management systems (ClearCase, Git, SVN, Perforce)\n",
      "4200 Experience with shell scripting languages (Perl, Python, Bash, TCL)\n",
      "4201 Comfortable with large-scale software development in a Linux environment\n",
      "4202 Deploy and maintain performant and scalable applications using Docker on Kubernetes\n",
      "4203 Proficiency in Python, NoSQL databases (Mongo, Cassandra, etc.)\n",
      "4204 Familiar with Redis\n",
      "4205 Must have Linux expertise\n",
      "4206 Proficiency in at least one modern PWA framework (Vue, React, Angular, etc.\n",
      "4207 Familiarity with GitLab (or similar tools) as well as software versioning and management\n",
      "4208 Knowledge of Docker\n",
      "4209 Knowledge of cloud platforms (AWS, Google Cloud, Azure), test driven development, and databases (including time series, relational, and NoSQL variants)\n",
      "4210 3+ years implementation experience with data governance technologies such as Collibra, Informatica AXON, Alation and/or IBM IGC\n",
      "4211 Jira, Confluence\n",
      "4212 In this role, you will be responsible for the microservices architecture of Kepler\n",
      "4213 Experience working in Cloud Services providers (AWS, Azure, Google Cloud);\n",
      "4214 Knowledge of REST, Node JS\n",
      "4215 Python, Kubernetes, SQL and NoSQL databases, including but not limited too Postgres, Mongo and ElasticSearch;\n",
      "4216 Great in SQL.\n",
      "4217 Experience with Talend.\n",
      "4218 Knowledge and/or experience with Microsoft enterprise solutions (Microsoft Dynamics 365, Microsoft Power Apps, Microsoft SharePoint, Microsoft Azure etc.) would be considered an asset\n",
      "4219 Experience using Python and/or R\n",
      "4220 Knowledge of SparkML\n",
      "4221 Knowledge and experience of writing and tuning SQL\n",
      "4222 Understand the customer’s business need and guide them to a solution using our AWS AI Services, AWS AI Platforms, AWS AI Frameworks, and AWS AI EC2 Instances .\n",
      "4223 Use Deep Learning frameworks like MXNet, Caffe 2, Tensorflow, Theano, CNTK, and Keras to help our customers build DL models.\n",
      "4224 Use SparkML and Amazon Machine Learning (AML) to help our customers build ML models.\n",
      "4225 Good skills with programming languages, such as Java or C/C++\n",
      "4226 Experience with AWS technologies like Redshift, S3, EC2, Data Pipeline, & EMR\n",
      "4227 Excellente maîtrise du moteur de jeu Unity et/ou Unreal;\n",
      "4228 Solides connaissances du langage C#/C++ et bonnes aptitudes en optimisation;\n",
      "4229 : Python, SciPy, OpenCV, TensorFlow, etc.);\n",
      "4230 Excellent mastery of the Unity and/or Unreal game engine;\n",
      "4231 Strong knowledge of the C#/C++ language and good optimization skills;\n",
      "4232 Python, SciPy, OpenCV, TensorFlow, etc.);\n",
      "4233 Strong JavaScript skills\n",
      "4234 3+ years of experience with React\n",
      "4235 Good knowledge of GraphQL\n",
      "4236 Experience with Hacklang and HHVM\n",
      "4237 We are looking for a Senior System Specialist (Linux) to design, implement, maintain, and support our growing Linux environment\n",
      "4238 You will be part of a team that is responsible for designing and developing a scalable, maintainable Linux environment that meets business objectives and SLAs.\n",
      "4239 Manage and maintain the Linux server environment which consists of CentOS, Debian, and Ubuntu installations including deployment of new servers on a VMware platform\n",
      "4240 Manage and deploy common Linux applications including mail, web, DHCP, databases, proxy, and syslog\n",
      "4241 Code compilation and packaging into standard Linux package formats such as RPM and DEB\n",
      "4242 Maintain and improve local package repositories for Linux applications\n",
      "4243 Handle network configuration at an OS level with knowledge of basic routing and Linux netfilter (iptables) layers\n",
      "4244 Deep understanding of Enterprise systems (e.g.,Virtualization, Enterprise Backup,Network block storage, clustering and load balancing technologies, Linux )\n",
      "4245 Preferred vendors: VMWare, Microsoft Active Directory, Red Hat, CentOS, Debian, and Ubuntu\n",
      "4246 Familiarity with automation process and tools such as Chef, Ansible, Puppet, or similar\n",
      "4247 Understanding of single sign-on technologies such as Kerberos, OAuth2, and SAML\n",
      "4248 Working knowledge using Python and Python based machine learning modules such as Scikit-learn, Keras, Tensorflow, Keras-RL, PyTorch and Pandas libraries.\n",
      "4249 Hands-on experiencing integrating Python ML modules with wireless system simulators.\n",
      "4250 What will you do? • Support IT equipment in large corporate environment • Desktop/laptop tech support • Windows 7/10, Android, and iOS operating systems • Support mobile devices, printers, scanners, wireless, VPN, etc\n",
      "4251 Design and construct Data Lake ingestion and staging of corporate data sources for Analytics purposes using Azure Data Factory.\n",
      "4252 Design and implement ETL routines using Azure Data Factory to load transformed data into the Data Warehouse.\n",
      "4253 Deliver and plan all Analytics change activities using a Devops approach, making use of Azure Devops tools\n",
      "4254 Must have experience delivering projects leveraging all of the Azure analytic components end-to-end.\n",
      "4255 Proven experience implementing Azure Stream Analytics for IOT data analytic purposes\n",
      "4256 Experience in delivering analytics development within a Devops environment with excellence shown in backlog planning, building, testing and delivery.\n",
      "4257 Solid knowledge of Azure analytic components such as Data Lake/Blob Storage, Azure Data Factory, Data Bricks, Azure SQL, Azure SQL Data Warehouse, Azure Analysis Services and Power BI Services.\n",
      "4258 Familiar with SQL Master Data Services (MDS) and Data Quality Services (DQS).\n",
      "4259 Knowledge in SAP technologies will be considered an asset.\n",
      "4260 Expert in Java and Android SDK\n",
      "4261 Experience creating custom UI elements, UI animation techniques and creating a rich, interactive UX on Android\n",
      "4262 Fluent in using tools like IntelliJ, Github, Charles and Flipper\n",
      "4263 You are expert in data mining, machine learning, deep learning, statistical modeling, and data visualization techniques using data-oriented tools and languages such as Python, R, and MATLAB or statistical analysis environments including SPSS or SAS\n",
      "4264 You have over ten years of experience or demonstrated fluency in relevant programming languages (Python, R, Scala, Java, C/C++)\n",
      "4265 You have over ten years of experience working with SQL (MySQL, SQL Server) as well as NoSQL (Cassandra, Hbase) databases\n",
      "4266 You have experience setting up and using large-scale distributed data-processing frameworks such as Apache Spark and Hadoop MapReduce\n",
      "4267 You have experience working with enterprise-grade cloud computing platforms such as Microsoft Azure, Amazon Web Services, or Google Cloud\n"
     ]
    }
   ],
   "source": [
    "for id in range(len(dataset)):\n",
    "    print(str(id) + \" \" + df_t.at[id,'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_2nd(string, substring):\n",
    "   return string.find(substring, string.find(substring) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in dictio:\n",
    "    colours[key] = \"#ECFF33\"\n",
    "    key_list.append(key)\n",
    "    for entity in dictio[key]:\n",
    "        count[key][entity] = 0\n",
    "        if entity.count(\" \") == 2:\n",
    "            space = find_2nd(entity, \" \")\n",
    "            sub_pattern1 = [{\"LOWER\": entity[:entity.find(\" \")].lower()}, {\"LOWER\": entity[entity.find(\" \") + 1: space].lower()}, {\"LOWER\": entity[space + 1:].lower()}]\n",
    "            sub_pattern2 = [{\"LOWER\": entity[:entity.find(\" \")].lower()}, {\"TEXT\": \"-\"}, {\"LOWER\": entity[entity.find(\" \") + 1: space].lower()}, {\"LOWER\": entity[space + 1:].lower()}]\n",
    "            sub_pattern3 = [{\"LOWER\": entity[:entity.find(\" \")].lower()}, {\"TEXT\": \"-\"}, {\"LOWER\": entity[entity.find(\" \") + 1: space].lower()}, {\"TEXT\": \"-\"}, {\"LOWER\": entity[space + 1:].lower()}]\n",
    "            sub_pattern4 = [{\"LOWER\": entity[:entity.find(\" \")].lower()}, {\"LOWER\": entity[entity.find(\" \") + 1: space].lower()}, {\"TEXT\": \"-\"}, {\"LOWER\": entity[space + 1:].lower()}]\n",
    "            sub_pattern5 = [{\"LOWER\": \"-\" + entity[:entity.find(\" \")].lower()}, {\"LOWER\": entity[entity.find(\" \") + 1: space].lower()}, {\"LOWER\": entity[space + 1:].lower()}]\n",
    "            sub_pattern6 = [{\"LOWER\": \"-\" + entity[:entity.find(\" \")].lower()}, {\"TEXT\": \"-\"}, {\"LOWER\": entity[entity.find(\" \") + 1: space].lower()}, {\"LOWER\": entity[space + 1:].lower()}]\n",
    "            sub_pattern7 = [{\"LOWER\": \"-\" + entity[:entity.find(\" \")].lower()}, {\"TEXT\": \"-\"}, {\"LOWER\": entity[entity.find(\" \") + 1: space].lower()}, {\"TEXT\": \"-\"}, {\"LOWER\": entity[space + 1:].lower()}]\n",
    "            sub_pattern8 = [{\"LOWER\": \"-\" + entity[:entity.find(\" \")].lower()}, {\"LOWER\": entity[entity.find(\" \") + 1: space].lower()}, {\"TEXT\": \"-\"}, {\"LOWER\": entity[space + 1:].lower()}]\n",
    "            pattern = [\n",
    "                sub_pattern1,\n",
    "                sub_pattern2,\n",
    "                sub_pattern3,\n",
    "                sub_pattern4,\n",
    "                sub_pattern5,\n",
    "                sub_pattern6,\n",
    "                sub_pattern7,\n",
    "                sub_pattern8\n",
    "            ]\n",
    "            patterns = [\n",
    "                {\"label\": key, \"pattern\": sub_pattern1, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern2, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern3, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern4, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern5, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern6, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern7, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern8, \"id\": entity}\n",
    "            ]\n",
    "        elif \" \" in entity and len(entity[entity.find(\" \") + 1:]) == 1:\n",
    "            sub_pattern1 = [{\"LOWER\": entity[:entity.find(\" \")].lower()}, {\"LOWER\": entity[entity.find(\" \") + 1:].lower()}]\n",
    "            sub_pattern2 = [{\"LOWER\": entity[:entity.find(\" \")].lower()}, {\"TEXT\": \"-\"}, {\"LOWER\": entity[entity.find(\" \") + 1:].lower()}]\n",
    "            sub_pattern3 = [{\"LOWER\": \"-\" + entity[:entity.find(\" \")].lower()}, {\"LOWER\": entity[entity.find(\" \") + 1:].lower()}]\n",
    "            sub_pattern4 = [{\"LOWER\": \"-\" + entity[:entity.find(\" \")].lower()}, {\"TEXT\": \"-\"}, {\"LOWER\": entity[entity.find(\" \") + 1:].lower()}]\n",
    "            sub_pattern5 = [{\"LOWER\": entity[:entity.find(\" \")].lower()}, {\"LOWER\": entity[entity.find(\" \") + 1:].lower() + \".\"}]\n",
    "            sub_pattern6 = [{\"LOWER\": entity[:entity.find(\" \")].lower()}, {\"TEXT\": \"-\"}, {\"LOWER\": entity[entity.find(\" \") + 1:].lower() + \".\"}]\n",
    "            pattern = [\n",
    "                sub_pattern1,\n",
    "                sub_pattern2,\n",
    "                sub_pattern3,\n",
    "                sub_pattern4,\n",
    "                sub_pattern5,\n",
    "                sub_pattern6\n",
    "            ]\n",
    "            patterns = [\n",
    "                {\"label\": key, \"pattern\": sub_pattern1, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern2, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern3, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern4, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern5, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern6, \"id\": entity}\n",
    "            ]\n",
    "        elif \" \" in entity:\n",
    "            sub_pattern1 = [{\"LOWER\": entity[:entity.find(\" \")].lower()}, {\"LOWER\": entity[entity.find(\" \") + 1:].lower()}]\n",
    "            sub_pattern2 = [{\"LOWER\": entity[:entity.find(\" \")].lower()}, {\"TEXT\": \"-\"}, {\"LOWER\": entity[entity.find(\" \") + 1:].lower()}]\n",
    "            sub_pattern3 = [{\"LOWER\": \"-\" + entity[:entity.find(\" \")].lower()}, {\"LOWER\": entity[entity.find(\" \") + 1:].lower()}]\n",
    "            sub_pattern4 = [{\"LOWER\": \"-\" + entity[:entity.find(\" \")].lower()}, {\"TEXT\": \"-\"}, {\"LOWER\": entity[entity.find(\" \") + 1:].lower()}]\n",
    "            pattern = [\n",
    "                sub_pattern1,\n",
    "                sub_pattern2,\n",
    "                sub_pattern3,\n",
    "                sub_pattern4   \n",
    "            ]\n",
    "            patterns = [\n",
    "                {\"label\": key, \"pattern\": sub_pattern1, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern2, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern3, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern4, \"id\": entity}\n",
    "            ]\n",
    "        elif \"+\" in entity:\n",
    "            sub_pattern1 = [{\"LOWER\": entity.lower()}]\n",
    "            sub_pattern2 = [{\"LOWER\": \"-\" + entity.lower()}]\n",
    "            sub_pattern3 = [{\"LOWER\": {\"REGEX\": entity.replace(\"+\", \"\\+\").lower() + \"/\"}}]\n",
    "            sub_pattern4 = [{\"LOWER\": {\"REGEX\": \"/\" + entity.replace(\"+\", \"\\+\").lower()}}]\n",
    "            pattern = [\n",
    "                sub_pattern1,\n",
    "                sub_pattern2,\n",
    "                sub_pattern3,\n",
    "                sub_pattern4\n",
    "            ]\n",
    "            patterns = [\n",
    "                {\"label\": key, \"pattern\": sub_pattern1, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern2, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern3, \"id\": entity}\n",
    "            ]\n",
    "        elif \"/\" in entity:\n",
    "            sub_pattern1 = [{\"LOWER\": {\"REGEX\": entity[:entity.find(\"#\")].lower() + \"#/\"}}]\n",
    "            sub_pattern2 = [{\"LOWER\": {\"REGEX\": \"/\" + entity[:entity.find(\"#\")].lower()}}, {\"LOWER\": \"#\"}]\n",
    "            pattern = [\n",
    "                sub_pattern1,\n",
    "                sub_pattern2\n",
    "             ]\n",
    "            patterns = [\n",
    "                {\"label\": key, \"pattern\": sub_pattern1, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern2, \"id\": entity}\n",
    "            ]\n",
    "        elif \"#\" in entity:\n",
    "            sub_pattern1 = [{\"LOWER\": entity[:entity.find(\"#\")].lower()}, {\"LOWER\": \"#\"}]\n",
    "            sub_pattern2 = [{\"LOWER\": \"-\" + entity[:entity.find(\"#\")].lower()}, {\"LOWER\": \"#\"}]\n",
    "            pattern = [\n",
    "                sub_pattern1,\n",
    "                sub_pattern2\n",
    "            ]\n",
    "            patterns = [\n",
    "                {\"label\": key, \"pattern\": sub_pattern1, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern2, \"id\": entity}\n",
    "            ]\n",
    "        elif len(entity) == 1:\n",
    "            sub_pattern1 = [{\"LOWER\": entity.lower()}]\n",
    "            sub_pattern2 = [{\"LOWER\": \"-\" + entity.lower()}]\n",
    "            sub_pattern3 = [{\"LOWER\": entity.lower() + \".\"}]\n",
    "            sub_pattern4 = [{\"LOWER\": {\"REGEX\": \"/\" + entity.lower()}}]\n",
    "            sub_pattern5 = [{\"LOWER\": {\"REGEX\": entity.lower() + \"/\"}}]\n",
    "            pattern = [\n",
    "                sub_pattern1,\n",
    "                sub_pattern2,\n",
    "                sub_pattern3,\n",
    "                sub_pattern4,\n",
    "                sub_pattern5\n",
    "            ]\n",
    "            patterns = [\n",
    "                {\"label\": key, \"pattern\": sub_pattern1, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern2, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern3, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern4, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern5, \"id\": entity}\n",
    "            ]\n",
    "        elif entity[0] == \"A\" or entity[0] == \"E\" or entity[0] == \"H\" or entity[0] == \"I\" or entity[0] == \"O\" or entity[0] == \"U\":\n",
    "            sub_pattern1 = [{\"LOWER\": entity.lower()}]\n",
    "            sub_pattern2 = [{\"LOWER\": \"-\" + entity.lower()}]\n",
    "            sub_pattern3 = [{\"LOWER\": {\"REGEX\": \"/\" + entity.lower()}}]\n",
    "            sub_pattern4 = [{\"LOWER\": {\"REGEX\": entity.lower() + \"/\"}}]\n",
    "            sub_pattern5 = [{\"LOWER\": \"d'\" + entity.lower()}]\n",
    "            sub_pattern6 = [{\"LOWER\": \"-\" + \"d'\" + entity.lower()}]\n",
    "            sub_pattern7 = [{\"LOWER\": {\"REGEX\": \"/\" + \"d'\" + entity.lower()}}]\n",
    "            sub_pattern8 = [{\"LOWER\": {\"REGEX\": \"d'\" + entity.lower() + \"/\"}}]\n",
    "            sub_pattern9 = [{\"LOWER\": \"l'\" + entity.lower()}]\n",
    "            sub_pattern10 = [{\"LOWER\": \"-\" + \"l'\" + entity.lower()}]\n",
    "            sub_pattern11 = [{\"LOWER\": {\"REGEX\": \"/\" + \"l'\" + entity.lower()}}]\n",
    "            sub_pattern12 = [{\"LOWER\": {\"REGEX\": \"l'\" + entity.lower() + \"/\"}}]\n",
    "            sub_pattern13 = [{\"LOWER\": \"d’\" + entity.lower()}]\n",
    "            sub_pattern14 = [{\"LOWER\": \"-\" + \"d’\" + entity.lower()}]\n",
    "            sub_pattern15 = [{\"LOWER\": {\"REGEX\": \"/\" + \"d’\" + entity.lower()}}]\n",
    "            sub_pattern16 = [{\"LOWER\": {\"REGEX\": \"d’\" + entity.lower() + \"/\"}}]\n",
    "            sub_pattern17 = [{\"LOWER\": \"l’\" + entity.lower()}]\n",
    "            sub_pattern18 = [{\"LOWER\": \"-\" + \"l’\" + entity.lower()}]\n",
    "            sub_pattern19 = [{\"LOWER\": {\"REGEX\": \"/\" + \"l’\" + entity.lower()}}]\n",
    "            sub_pattern20 = [{\"LOWER\": {\"REGEX\": \"l’\" + entity.lower() + \"/\"}}]\n",
    "            pattern = [\n",
    "                sub_pattern1,\n",
    "                sub_pattern2,\n",
    "                sub_pattern3,\n",
    "                sub_pattern4,\n",
    "                sub_pattern5,\n",
    "                sub_pattern6,\n",
    "                sub_pattern7,\n",
    "                sub_pattern8,\n",
    "                sub_pattern9,\n",
    "                sub_pattern10,\n",
    "                sub_pattern11,\n",
    "                sub_pattern12,\n",
    "                sub_pattern13,\n",
    "                sub_pattern14,\n",
    "                sub_pattern15,\n",
    "                sub_pattern16,\n",
    "                sub_pattern17,\n",
    "                sub_pattern18,\n",
    "                sub_pattern19,\n",
    "                sub_pattern20\n",
    "            ]\n",
    "            patterns = [\n",
    "                {\"label\": key, \"pattern\": sub_pattern1, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern2, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern3, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern4, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern5, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern6, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern7, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern8, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern9, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern10, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern11, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern12, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern13, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern14, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern15, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern16, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern17, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern18, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern19, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern20, \"id\": entity}\n",
    "            ]\n",
    "        elif \"(s)\" in entity:\n",
    "            sub_pattern1 = [{\"LOWER\": entity[:entity.find(\"(\")].lower()}]\n",
    "            sub_pattern2 = [{\"LOWER\": \"-\" + entity[:entity.find(\"(\")].lower()}]\n",
    "            sub_pattern3 = [{\"LOWER\": {\"REGEX\": \"/\" + entity[:entity.find(\"(\")].lower()}}]\n",
    "            sub_pattern4 = [{\"LOWER\": {\"REGEX\": entity[:entity.find(\"(\")].lower() + \"/\"}}]\n",
    "            sub_pattern5 = [{\"LOWER\": entity[:entity.find(\"(\")].lower() + \"s\"}]\n",
    "            sub_pattern6 = [{\"LOWER\": \"-\" + entity[:entity.find(\"(\")].lower() + \"s\"}]\n",
    "            sub_pattern7 = [{\"LOWER\": {\"REGEX\": \"/\" + entity[:entity.find(\"(\")].lower() + \"s\"}}]\n",
    "            sub_pattern8 = [{\"LOWER\": {\"REGEX\": entity[:entity.find(\"(\")].lower() + \"s\" + \"/\"}}]\n",
    "            pattern = [\n",
    "                sub_pattern1,\n",
    "                sub_pattern2,\n",
    "                sub_pattern3,\n",
    "                sub_pattern4,\n",
    "                sub_pattern5,\n",
    "                sub_pattern6,\n",
    "                sub_pattern7,\n",
    "                sub_pattern8\n",
    "            ]\n",
    "            patterns = [\n",
    "                {\"label\": key, \"pattern\": sub_pattern1, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern2, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern3, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern4, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern5, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern6, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern7, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern8, \"id\": entity}\n",
    "            ]\n",
    "        else:\n",
    "            sub_pattern1 = [{\"LOWER\": entity.lower()}]\n",
    "            sub_pattern2 = [{\"LOWER\": \"-\" + entity.lower()}]\n",
    "            sub_pattern3 = [{\"LOWER\": {\"REGEX\": \"/\" + entity.lower()}}]\n",
    "            sub_pattern4 = [{\"LOWER\": {\"REGEX\": entity.lower() + \"/\"}}]\n",
    "            pattern = [\n",
    "                sub_pattern1,\n",
    "                sub_pattern2,\n",
    "                sub_pattern3,\n",
    "                sub_pattern4\n",
    "            ]\n",
    "            patterns = [\n",
    "                {\"label\": key, \"pattern\": sub_pattern1, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern2, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern3, \"id\": entity},\n",
    "                {\"label\": key, \"pattern\": sub_pattern4, \"id\": entity}\n",
    "            ]\n",
    "        matcher.add(entity, pattern)\n",
    "        ruler.add_patterns(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 Knowledge of computer vision neural networks such as Fast-RCNN, ResNet, Mask-RCNN\n",
      "76 Network Protocols (TCP/IP, HTTP, ISO/OSI,etc).\n",
      "99 APIs\n",
      "112 Relational and NoSql database systems experience\n",
      "157 Familiar with well known deep learning models such as Yolo, SSD, faster RCNN and able to adapt it to new applications\n",
      "165 Interfaces such as GMSL2, FPDLINK III\n",
      "183 Experience with security products, such as Firewalls, IPSec, IDS/IPS, Anti -Spam, Anti-Virus, Web Security proxies, Email Security filters, VPNs\n",
      "219 stereo cameras, IMU, LiDAR);\n",
      "245 HJ Machine & Pattern(HJMP) is looking for a smart, creative, and experienced CMM Tech & quality engineering professional who has a working knowledge of GD&T and other quality tools\n",
      "293 Experience with large scale Whole page Optimization, Search or Recommendation algorithms\n",
      "296 Knowledge of computer vision neural networks such as Fast-RCNN, ResNet, Mask-RCNN\n",
      "348 Experience with security products, such as Firewalls, IPSec, IDS/IPS, Anti -Spam, Anti-Virus, Web Security proxies, Email Security filters, VPNs\n",
      "366 Computer Programming Skills: capability to develop test platforms in C#.net\n",
      "370 Hands-on experience with the installation, configuration, and/or operation of network equipment such as Cisco, Juniper or other network hardware manufacturers – a valuable asset\n",
      "509 Must have APQP experience\n",
      "551 C++17 experience\n",
      "577 o 4 years of experience with both relational and NoSQL technologies\n",
      "591 In-depth knowledge of Ethernet switching, routing and application level protocols (L2/L3 protocols) – RSTP, LLDP, STP, IGMP, VRRP, RIP, OSPF, TCP/IP, HTTP, NAT, IGMP, QoS, VLAN, VPN etc.\n",
      "593 Strong experience with low level device drivers (I2C, SPI Master/Slave, Serial/HCI, GPIO, USB, SD, NAND, NOR, RAM, FPGA/CPLD, SerDes, PHY).\n",
      "594 Able to read schematic diagrams, experience with debug and test tools such as Oscilloscope, Logic Analyzer, Multi-meter, JTAG debugger.\n",
      "781 Exposure to Automotive Platforms, such as Ethernet/CAN/LIN, AUTOSAR\n",
      "806 Knowledge of security measures like HTTPS and Kerberos\n",
      "866 In-depth understanding of TCP/IP and network security (SSL/TLS, VPN, Firewall)\n",
      "868 Good knowledge of authentication protocols and methods (LDAP, Kerberos)\n",
      "893  NoSQL DB experience\n",
      "927 Design, implement, and refine NoSQL database models for the application\n",
      "943 Knowledge of hardware design practices, schematic capture(Orcad), PCB Layout(Allegro), thermal management\n",
      "981 Knowledge of security measures like HTTPS and Kerberos\n",
      "982 Experience using NoSQL databases.\n",
      "1004 Implement or port machine learning and image processing algorithms to NVIDIA Drive AGX, Intel Movidius Myriad VPU, etc.\n",
      "1005 Write application software on automotive DNN platforms, such as NVIDIA, Movidius, Qualcomm, and Renesas.\n",
      "1024 ITIL, Zachman, TOGAF, etc.)\n",
      "1036 ITIL, Zachman, TOGAF, etc.)\n",
      "1104 Apache) and UI/UX design\n",
      "1113 IIoT, PC based HMI\n",
      "1259 Database Administration Experience, relational and NoSQL.\n",
      "1291 In-depth knowledge of Ethernet switching, routing and application level protocols (L2/L3 protocols) – RSTP, LLDP, STP, IGMP, VRRP, RIP, OSPF, TCP/IP, HTTP, NAT, IGMP, QoS, VLAN, VPN etc.\n",
      "1293 Experience developing any of the following is a plus: Firewall, VPN, IDS/IPS, SDN.\n",
      "1295 Knowledge of SCADA communications protocols like DNP, Modbus etc\n",
      "1303 Integrate the application with external apps using OAuth2\n",
      "1312 Experience integrating with other applications using OAuth2\n",
      "1317 Experience with agile development processes such as Lean/Scrum/Kanban\n",
      "1393 Excels when working with a small team using a lightweight agile process.\n",
      "1430 Apache) and UI/UX design\n",
      "1452 OSPF, IS-IS, BGP, RIP), and MPLS\n",
      "1460 Experience working with external independent assessors (TUV, Exida, etc)\n",
      "1481 Agile & Shift Left Methodologies, along with exposure to environments that actively used threat modelling methodologies in the SDLC\n",
      "1512 Experience with Industrial control protocols, such as Modbus, CANbus etd.\n",
      "1518 Expérience avec des protocoles IP industriels (Modbus, CANbus, etc.)\n",
      "1546 Agile & Shift Left Methodologies\n",
      "1555 Experience of working on Layer3 IP technologies (IPv4/IPv6, SNMP, IPSEC, VRRP, RIP, ISIS, OSPF, BGP, EIRGP, MPLS, PBR, ACL etc…).\n",
      "1576 Basic knowledge of embedded processors such as ARM Cortex-M3 or RISC-V and familiarity with AMBA bus protocols such as APB, AHB, AXI, ACE and familiarity with commonly used peripherals such as SPI,12C, UART, Ethernet, PCle, HDMI and USB.\n",
      "1577 Experience in developing, working with Machine Learning/ Inference Engine for FPGAs.\n",
      "1633 NoSQL database experience\n",
      "1722 OSPF/ISIS, BGP), MPLS, IP VPN, VLAN, L2 and L3 VPN Services\n",
      "1743 Understanding of web services technologies such as SOAP, HTTP, WSDL, XSD, and REST\n",
      "1748 Experience of working on Layer3 IP technologies (IPv4/IPv6, SNMP, IPSEC, VRRP, RIP, ISIS, OSPF, BGP, EIRGP, MPLS, PBR, ACL etc…).\n",
      "1753 Microchip is also a pioneer in embedding RiscV processors in FPGAs\n",
      "1765 Excellent knowledge of using medium resolution optical satellite data (e.g., Sentinel-2 or Landsat-7/8)\n",
      "1769 Experience with RESTFull APIs, CMS\n",
      "1772 Knowledge of relational databases and NoSQL\n",
      "1813 A minimum of 2 years of experience working with NoSQL databases\n",
      "1912 Create solutions aligned with the long-term architecture and technology strategy using Amazon Web Services(AWS) for Cloud development\n",
      "1915 English: C1 Advanced\n",
      "1923 Experience with the databases (Relation and/or NoSQL) and query considerations with large amounts of data\n",
      "1934 o Experience in storing, manipulating and integrating NoSQL data to BI reporting.\n",
      "1936 CDA, DALSM, DASM) (an asset)\n",
      "1963 Understanding of protocols such as Modbus, DNP3, OPC UA/DA, SNMP, and others\n",
      "1984 Working knowledge of relational and NoSQL databases.\n",
      "2016 Experience with game console development Nintendo, PlayStation, Xbox).\n",
      "2025 In-depth knowledge of Ethernet switching, routing and application level protocols (L2/L3 protocols) – RSTP, LLDP, STP, IGMP, VRRP, RIP, OSPF, TCP/IP, HTTP, NAT, IGMP, QoS, VLAN, VPN etc.\n",
      "2027 Strong experience with low level device drivers (I2C, SPI Master/Slave, Serial/HCI, GPIO, USB, SD, NAND, NOR, RAM).\n",
      "2028 Able to read schematic diagrams, experience with debug and test tools such as Oscilloscope, Logic Analyzer, Multi-meter, JTAG debugger.\n",
      "2043 Expertise with RDBMS and NoSQL databases at scale\n",
      "2102 XP, Scrum)\n",
      "2133 Excellent knowledge in RDBMS and/or NoSQL database technologies\n",
      "2154 Database experience must be familiar with RDBMS and NoSQL databases\n",
      "2177 NoSQL database experience\n",
      "2181 Expertise with RDBMS and NoSQL databases at scale\n",
      "2267 Experience designing and building SOA, microservices, web services, API based architectures\n",
      "2286 Experience with Industrial control protocols, such as Modbus, CANbus etc.\n",
      "2292 Expérience avec des protocoles IP industriels (Modbus, CANbus, etc.)\n",
      "2307 ZScaler with ZScaler Private Access (ZPA)\n",
      "2320 Excellent knowledge in RDBMS and/or NoSQL database technologies\n",
      "2326 Experience working with FICO / TSYS / CGI decision systems (TRIAD, OM, ACE, CACS)\n",
      "2338 Excellent knowledge in RDBMS and/or NoSQL database technologies\n",
      "2347 Networking and Cloud Networks\n",
      "2364 Experience with Bootstrap or other UI frameworks\n",
      "2428 Experience working with Epic\n",
      "2483 RX, TX, PLL, etc…)\n",
      "2484 Verification tools: ICV, Calibre, Star-RCXT, PERC\n",
      "2494 RX, TX, PLL, etc…)\n",
      "2495 Verification tools: ICV, Calibre, Star-RCXT, PERC\n",
      "2511 Avigilon, a Motorola Solutions company, designs, develops, and manufactures advanced AI, video analytics, network video management software and hardware, surveillance cameras, and access control solutions that help change the way people interact with their security systems.\n",
      "2526 Experience with SOA, Web Services and SOAP is desirable\n",
      "2542 As a Principle Software Developer on the Avigilon Cloud Services team, you will help us architect and build new features, enhance our existing software, tools, and experiences to help delight our customers by extending our application capabilities and enhancing the existing AI technologies we use\n",
      "2545 We contribute to Avigilon Cloud's success by producing software, services and API's that are robust, reliable and scalable\n",
      "2602 Experience working with GPUs/FPGAs.\n",
      "2605 Strong skills managing Search Tool, integrating data collection, visualization, analysis, logging and storage\n",
      "2609 Front-end & Server-side programming technologies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2627 CPU: Intel i5 or higher (or its AMD equivalent)\n",
      "2658 Experience with cross-browser and cross-platform issues (IE, Firefox, Safari, etc.)\n",
      "2670 Monitor pests and diseases on greenhouse crops, such as Spider mites, Aphids, Thrips, Botrytis, Pythium, Fusarium, etc.\n",
      "2750 Have a working knowledge if various deep learning models and techniques including neural-networks, Random Forrest, Gradient Boost, Euclidean Distance, etc.\n",
      "2759 Experience with different kinds of architectures and their respective pros/cons: microservices, SOA, monolithics etc.\n",
      "2805 Build deploy and manage CI/CD workflows which leverage GitOps practices\n",
      "2882 NoSQL Database\n",
      "2891 NoSQL Database\n",
      "2896 APIS: Bambora, Stripe & other Payment Processor APIs, Shopify API, Semantics3, and more\n",
      "2944 Familiarity with industrial specifications such as Modbus, DNP3, PROFIBUS, OPC; and any IIoT specifications such as MQTT, AMQP, MIOTY, LORAWAN is an asset;\n",
      "2993 API\n",
      "3045 Experience in agile visualization toolsets (Miro, Stories onboard, etc.)\n",
      "3047 Experience in agile visualization toolsets (Miro, Stories onboard, etc.)\n",
      "3076 Help with improvement of UI/UX and search accuracy of the BenchSci platform\n",
      "3079 Cerebri AI CVX platform includes a streaming capable AI software pipeline that processes data intake thru to producing insights and actions & presenting them via our APIs, in our customers' systems, or our UX\n",
      "3164 Knowledge of different type of light sources such as QTH, LED, laser, fluorescence, etc.\n",
      "3171 ERP\n",
      "3210 Network protocols (Ethernet, TCP/IP, WIFI)\n",
      "3214 Front-end and back-end technologies (Cloud)\n",
      "3221 You are a strategic thinker and a proven development leader delivering SOA-based software with UIs, APIs, and Services that enable business agility\n",
      "3225 Strong experience of software engineering practices such as Agile, Devops, CI and CD and others\n",
      "3249 You’ll have a sound understanding of computer science fundamentals and practical industry experience, working across the stack with technology involving modern web, SOA, NoSQL databases, AI, ML, Big Data and more.\n",
      "3251 Knowledge of industry best practices for AML/ATF such as Wolfsberg Principles is a plus\n",
      "3301 Networks with key contacts outside own area of expertise.\n",
      "3327 Raspberry Pi\n",
      "3331 Experience in Microsoft desktop and server platforms and their related software management applications\n",
      "3344 Knowledge of industry best practices for AML/ATF such as Wolfsberg Principles is a plus\n",
      "3349 4 years of experience with both relational and NoSQL technologies\n",
      "3384 You’ll have a sound understanding of computer science fundamentals and practical industry experience, working across the stack with technology involving modern web, SOA, NoSQL databases, AI, ML, Big Data and more.\n",
      "3503 Machine Learning APIs and frameworks (AutoML, Translation APIs, and others)\n",
      "3543 Avigilon, a Motorola Solutions company, designs, develops, and manufactures advanced AI, video analytics, network video management software and hardware, surveillance cameras, and access control solutions that help change the way people interact with their security systems.\n",
      "3571 Espresso Machine\n",
      "3573 Expertise in RDBMS and NoSQL\n",
      "3597 Strong experience of software engineering practices such as Agile, Devops, CI and CD and others.\n",
      "3630 Agile methodology: Scrum, Kanban, Sprints, Collaboration tools: Wiki or other\n",
      "3666 Intrusion Detection/Prevention (IDS/IPS)\n",
      "3668 Wireless, VPN, SDN, SaaS\n",
      "3669 Ipv4/v6 Routing Protocols (RIPv1/v2/v3, OSPFv2/v3, VRRP, MPLS, BGP, PIM, etc.)\n",
      "3689 Knowledge of Google Drive Suite\n",
      "3736 Avigilon, a Motorola Solutions company, designs, develops, and manufactures advanced AI, video analytics, network video management software and hardware, surveillance cameras, and access control solutions that help change the way people interact with their security systems.\n",
      "3832 Immersive media such as AR or VR\n",
      "3833 Basic knowledge of NRC-IRAP's mandate, mission and business model.\n",
      "3834 CRM\n",
      "3847 2D/3D Features Detection\n",
      "3871 Experience with Agile frameworks (Scrum, Lean, Kanban)\n",
      "3921 Experienced with Pythonic program development.\n",
      "3936 As compiler engineer, you will be responsible for developing compiler optimizations for our state-of-the-art spatial compiler - targeting Groq's revolutionary Tensor Streaming Processor\n",
      "3971 / Staff Compiler Engineer, you will be responsible for defining and developing compiler optimizations for our state-of-the-art spatial compiler - targeting Groq's revolutionary Tensor Streaming Processor\n",
      "4005 Avigilon, a Motorola Solutions company, designs, develops, and manufactures advanced AI, video analytics, network video management software and hardware, surveillance cameras, and access control solutions that help change the way people interact with their security systems.\n",
      "4053 Avigilon, a Motorola Solutions company, designs, develops, and manufactures advanced AI, video analytics, network video management software and hardware, surveillance cameras, and access control solutions that help change the way people interact with their security systems.\n",
      "4072 Avoir des connaissances dans les bases de données relationnelles et NoSQL ;\n",
      "4079 Proficiency in relational and NoSQL databases;\n",
      "4115 Work with Devops Teams to understand impacts of branches and code merges\n",
      "4176 Avigilon, a Motorola Solutions company, designs, develops, and manufactures advanced AI, video analytics, network video management software and hardware, surveillance cameras, and access control solutions that help change the way people interact with their security systems.\n",
      "4177 Avigilon’s analytic based, video surveillance software interfaces to a variety of external systems, including mobile, web, cloud, and 3rd party systems\n",
      "4186 Experience with source control and working with data-handling using AJAX, JSON, and REST API\n",
      "4187 Experience with Conversational Interfaces (IVR, Alexa, SMS, Google Assistant), Artificial Intelligence, Data Science, and Augmented/Mixed/Virtual Reality would be a massive asset\n",
      "4188 Comfort and experience prototyping with controller boards, like Raspberry Pi or Arduino, is always helpful\n",
      "4189 Avigilon designs, develops, and manufactures video analytics, network video management software and hardware, surveillance cameras, and access control solutions\n",
      "4190 Avigilon’s analytic based, video surveillance software interfaces to a variety of Avigilon and 3rd party cameras, and other sensors\n",
      "4197 Experience from working in an Agile environment, using Devops and CI/CD.\n",
      "4212 In this role, you will be responsible for the microservices architecture of Kepler\n",
      "4247 Understanding of single sign-on technologies such as Kerberos, OAuth2, and SAML\n",
      "4256 Experience in delivering analytics development within a Devops environment with excellence shown in backlog planning, building, testing and delivery.\n"
     ]
    }
   ],
   "source": [
    "for numb in range(len(dataset)):\n",
    "    doc = nlp(df_t.at[numb,'text'])\n",
    "    matches = matcher(doc)\n",
    "    for match_id, start, end in matches:\n",
    "        string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "        span = doc[start:end]  # The matched span\n",
    "        temp.append(string_id)\n",
    "    if temp:\n",
    "        for word in temp:\n",
    "            cnt[word] += 1\n",
    "    else:\n",
    "        print(str(numb) + \" \" + df_t.at[numb, 'text'])\n",
    "    temp.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Python': 732,\n",
       "         'NumPy': 35,\n",
       "         'Pandas': 44,\n",
       "         'SciKit Learn': 52,\n",
       "         'PyTorch': 96,\n",
       "         'Torch': 3,\n",
       "         'TensorFlow': 135,\n",
       "         'Linux': 271,\n",
       "         'Unix': 77,\n",
       "         'NLTK': 6,\n",
       "         'Keras': 38,\n",
       "         'Git': 141,\n",
       "         'Jira': 93,\n",
       "         'Confluence': 40,\n",
       "         'GitHub': 54,\n",
       "         'AWS': 396,\n",
       "         'Bash': 62,\n",
       "         'Zsh': 1,\n",
       "         'Ksh': 1,\n",
       "         'Ruby': 45,\n",
       "         'Splunk': 13,\n",
       "         'New Relic': 3,\n",
       "         'SageMaker': 18,\n",
       "         'Cykit': 1,\n",
       "         'Google Cloud': 47,\n",
       "         'AppEngine': 1,\n",
       "         'Go': 70,\n",
       "         'NestJS': 1,\n",
       "         'iOS': 57,\n",
       "         'Android': 50,\n",
       "         'Windows': 111,\n",
       "         'R': 110,\n",
       "         'Scipy': 14,\n",
       "         'C': 293,\n",
       "         'C#': 119,\n",
       "         'Java': 373,\n",
       "         'C++': 321,\n",
       "         'SQL': 389,\n",
       "         'SKlearn': 1,\n",
       "         'Azure': 355,\n",
       "         'GCP': 89,\n",
       "         'Docker(s)': 179,\n",
       "         'Spark': 166,\n",
       "         'Airflow': 34,\n",
       "         'Horovod': 3,\n",
       "         'Snowflake': 29,\n",
       "         'DBT': 4,\n",
       "         'Sisense': 2,\n",
       "         'Scala': 53,\n",
       "         'CUDA': 21,\n",
       "         'Kubernetes': 189,\n",
       "         'BigQuery': 21,\n",
       "         'Kafka': 56,\n",
       "         'Jenkins': 79,\n",
       "         'ElasticSearch': 32,\n",
       "         'Google Analytics': 7,\n",
       "         'DVC': 2,\n",
       "         'Caffe': 8,\n",
       "         'ONNX': 8,\n",
       "         'OpenCl': 15,\n",
       "         'HLSL': 2,\n",
       "         'YAML': 1,\n",
       "         'ELK': 12,\n",
       "         'PagerDuty': 4,\n",
       "         'SumoLogic': 4,\n",
       "         'ServiceNow': 4,\n",
       "         'OpenCV': 23,\n",
       "         'DirectX': 6,\n",
       "         'TVM': 5,\n",
       "         'Glow': 2,\n",
       "         'XLA': 2,\n",
       "         'LLVM': 11,\n",
       "         'Flink': 9,\n",
       "         'Beam': 16,\n",
       "         'ZMQ': 1,\n",
       "         'MongoDB': 35,\n",
       "         'Cypress': 6,\n",
       "         'Mocha': 5,\n",
       "         'Amazon Web Services': 15,\n",
       "         'PowerShell': 20,\n",
       "         'Hadoop': 104,\n",
       "         'Hive': 50,\n",
       "         'Mac': 15,\n",
       "         'EMR': 25,\n",
       "         'Theano': 6,\n",
       "         '.NET': 58,\n",
       "         'Oracle': 56,\n",
       "         'MySQL': 59,\n",
       "         'PostgreSQL': 52,\n",
       "         'EC2': 22,\n",
       "         'VPC(s)': 5,\n",
       "         'Lambda(s)': 33,\n",
       "         'API Gateway': 5,\n",
       "         'Terraform': 62,\n",
       "         'CloudFormation': 13,\n",
       "         'Haskell': 1,\n",
       "         'MLlib': 5,\n",
       "         'Elastic Search': 6,\n",
       "         'Lucene': 4,\n",
       "         'AFT Fathom': 1,\n",
       "         'Ansys': 1,\n",
       "         'Mathcad': 1,\n",
       "         'MicroStation': 1,\n",
       "         'Golang': 26,\n",
       "         'VMWare': 17,\n",
       "         'vSphere': 1,\n",
       "         'Openstack': 7,\n",
       "         'Swarm': 10,\n",
       "         'Excel': 104,\n",
       "         'Powerpoint': 52,\n",
       "         'Selenium': 25,\n",
       "         'OS X': 4,\n",
       "         'SAP': 23,\n",
       "         'Salesforce': 11,\n",
       "         'Azure SQL': 7,\n",
       "         'DB2': 7,\n",
       "         'Teradata': 6,\n",
       "         'Power BI': 29,\n",
       "         'Microstrategy': 4,\n",
       "         'Tableau': 70,\n",
       "         'Qlik': 2,\n",
       "         'OpenMP': 1,\n",
       "         'Azure DevOps': 21,\n",
       "         'H2O': 7,\n",
       "         'Databrick(s)': 43,\n",
       "         'Kotlin': 13,\n",
       "         'DynamoDB': 29,\n",
       "         'DataFlow': 2,\n",
       "         'MS Office': 26,\n",
       "         'Word': 52,\n",
       "         'Yocto': 5,\n",
       "         'Data bricks': 6,\n",
       "         'C#/': 12,\n",
       "         'Ubuntu': 19,\n",
       "         'Rust': 12,\n",
       "         'SolidWorks': 2,\n",
       "         'ECS': 18,\n",
       "         'OpenShift': 12,\n",
       "         'Perl': 44,\n",
       "         'TypeScript': 52,\n",
       "         'EKS': 17,\n",
       "         'Kubeflow': 8,\n",
       "         'Tensor Flow': 4,\n",
       "         'Flow': 8,\n",
       "         'Protractor': 6,\n",
       "         'JavaScript': 235,\n",
       "         'Cucumber': 4,\n",
       "         'Angular': 73,\n",
       "         'PHP': 33,\n",
       "         'Laravel': 8,\n",
       "         'Eloquent': 1,\n",
       "         'MasterCAM': 1,\n",
       "         'Onshape': 1,\n",
       "         'AutoCAD': 2,\n",
       "         'XML': 22,\n",
       "         'S3': 43,\n",
       "         'Cassandra': 11,\n",
       "         'SQLServer': 2,\n",
       "         'Redis': 28,\n",
       "         'GRPC': 6,\n",
       "         'Spring': 26,\n",
       "         'Spring Boot': 7,\n",
       "         'React': 115,\n",
       "         'RESTful': 26,\n",
       "         'JS': 30,\n",
       "         'Data Studio': 4,\n",
       "         'PowerBI': 22,\n",
       "         'Looker': 7,\n",
       "         'Matplotlib': 11,\n",
       "         'Google Marketing Platform': 2,\n",
       "         'GA360': 2,\n",
       "         'Google Ads': 2,\n",
       "         'Presto': 11,\n",
       "         'React Native': 10,\n",
       "         'Electron': 3,\n",
       "         'Qt': 4,\n",
       "         'Vue.js': 8,\n",
       "         'Unreal': 16,\n",
       "         'Unity': 13,\n",
       "         'WebGL': 2,\n",
       "         'Babylon.js': 2,\n",
       "         'Three.js': 3,\n",
       "         'HTML': 68,\n",
       "         'CSS': 90,\n",
       "         'Vue': 23,\n",
       "         'Cordova': 3,\n",
       "         'Fast.io': 3,\n",
       "         'Quarkus': 4,\n",
       "         'Postgres': 23,\n",
       "         'Statsmodel(s)': 2,\n",
       "         'Seaborn': 2,\n",
       "         'PySpark': 9,\n",
       "         'VSCode': 1,\n",
       "         'PyCharm': 3,\n",
       "         'Jupyter': 8,\n",
       "         'Jupyter Notebook': 1,\n",
       "         'Debian': 6,\n",
       "         'Ansible': 40,\n",
       "         'Chef': 16,\n",
       "         'SaltStack': 2,\n",
       "         'WebdriverIO': 1,\n",
       "         'DNS': 8,\n",
       "         'Microsoft SQL Server': 6,\n",
       "         'SAS': 28,\n",
       "         'Azure Machine Learning': 6,\n",
       "         'DataRobot': 1,\n",
       "         'MLFlow': 8,\n",
       "         'RSpec': 1,\n",
       "         'React.js': 14,\n",
       "         'Matlab': 21,\n",
       "         'BSD': 2,\n",
       "         'Solaris': 2,\n",
       "         'NET': 1,\n",
       "         'Microsoft Office': 26,\n",
       "         'Groovy': 6,\n",
       "         'Karate': 1,\n",
       "         'Maven': 6,\n",
       "         'Gradle': 3,\n",
       "         'Ant': 2,\n",
       "         'Gitlab': 39,\n",
       "         'Redshift': 51,\n",
       "         'R Shiny': 2,\n",
       "         'JMP': 1,\n",
       "         'Dask': 9,\n",
       "         'Argo': 2,\n",
       "         'Dash': 1,\n",
       "         'Streamlit': 1,\n",
       "         'Bitbucket': 19,\n",
       "         'Azure Data Lake': 8,\n",
       "         'Java Script': 6,\n",
       "         'Node.js': 32,\n",
       "         'GKE': 4,\n",
       "         'Shell': 35,\n",
       "         'Julia': 2,\n",
       "         'MXNet': 12,\n",
       "         'UrbanCode': 1,\n",
       "         'Logstash': 4,\n",
       "         'Kibana': 7,\n",
       "         'ROS': 6,\n",
       "         'GStreamer': 2,\n",
       "         'SVN': 8,\n",
       "         'HyperV': 1,\n",
       "         'Test Rail': 1,\n",
       "         'PlayFab': 1,\n",
       "         'Firebase': 4,\n",
       "         'Slurm': 7,\n",
       "         'Singularity': 6,\n",
       "         'OpenVINO': 5,\n",
       "         'ArcGIS': 7,\n",
       "         'QGIS': 5,\n",
       "         'RabbitMQ': 15,\n",
       "         'Express': 10,\n",
       "         'ECMAScript': 2,\n",
       "         'Zookeeper': 3,\n",
       "         'RAML': 1,\n",
       "         'Swagger': 3,\n",
       "         'Node': 21,\n",
       "         'Swift': 10,\n",
       "         'Dialogflow': 2,\n",
       "         'UiPath': 6,\n",
       "         'Blue Prism': 3,\n",
       "         'ReactJS': 20,\n",
       "         'Objective C': 8,\n",
       "         'Puppet': 15,\n",
       "         'Prometheus': 14,\n",
       "         'InfluxDB': 8,\n",
       "         'Grafana': 11,\n",
       "         'SQLite': 4,\n",
       "         'MacOS': 12,\n",
       "         'Dynamo DB': 3,\n",
       "         'Flutter': 4,\n",
       "         'Dart': 1,\n",
       "         'HTML5': 21,\n",
       "         'AngularJS': 8,\n",
       "         'GraphQL': 17,\n",
       "         'Gatsby': 1,\n",
       "         'OAuth': 4,\n",
       "         'Iceberg': 1,\n",
       "         'Hudi': 1,\n",
       "         'Delta': 5,\n",
       "         'Kinesis': 20,\n",
       "         'Slim': 2,\n",
       "         'Restlet': 2,\n",
       "         'Falcon': 2,\n",
       "         'Subversion': 2,\n",
       "         'Delta lake': 2,\n",
       "         'Whois': 1,\n",
       "         'Photoshop': 7,\n",
       "         'Illustrator': 3,\n",
       "         'Figma': 8,\n",
       "         'Lua': 4,\n",
       "         'Django': 30,\n",
       "         'Flask': 12,\n",
       "         'JMeter': 5,\n",
       "         'Flood.io': 1,\n",
       "         'BlazeMeter': 1,\n",
       "         'Redux': 9,\n",
       "         'ArgoCD': 2,\n",
       "         'Neo4j': 5,\n",
       "         'Cypher': 2,\n",
       "         'Cosmos DB': 7,\n",
       "         'Verilog': 6,\n",
       "         'Erwin': 2,\n",
       "         'Assembly': 3,\n",
       "         'Istio': 4,\n",
       "         'K8(s)': 4,\n",
       "         'Dynatrace': 5,\n",
       "         'Ixia': 1,\n",
       "         'Hyper V': 3,\n",
       "         'Rook': 3,\n",
       "         'Ceph': 5,\n",
       "         'Vyond': 1,\n",
       "         'Gimp': 2,\n",
       "         'Camtasia': 1,\n",
       "         'TestRail': 1,\n",
       "         'CoreML': 3,\n",
       "         'GDB': 2,\n",
       "         'LLDB': 1,\n",
       "         'Valgrind': 1,\n",
       "         'CMake': 1,\n",
       "         'Ruby on Rails': 8,\n",
       "         'jQuery': 20,\n",
       "         'Informatica': 12,\n",
       "         'Buck': 1,\n",
       "         'Bazel': 2,\n",
       "         'NodeJS': 18,\n",
       "         'Eclipse': 4,\n",
       "         'Collibra': 3,\n",
       "         'CSS3': 12,\n",
       "         'VBA': 9,\n",
       "         'TM1Py': 1,\n",
       "         'Microsoft Project': 2,\n",
       "         'Visio': 6,\n",
       "         'SharePoint': 14,\n",
       "         'HBase': 13,\n",
       "         'Solr': 4,\n",
       "         'Elastic Beanstalk': 1,\n",
       "         'Hibernate': 9,\n",
       "         'Mockito': 1,\n",
       "         'Tomcat': 5,\n",
       "         'Vagrant': 2,\n",
       "         'Datadog': 6,\n",
       "         'SignalFx': 2,\n",
       "         'MS 365': 1,\n",
       "         'Gmail': 2,\n",
       "         'Google Calendar': 2,\n",
       "         'AKS': 4,\n",
       "         'ClickHouse': 1,\n",
       "         'Visual Studio': 9,\n",
       "         'DPDK': 2,\n",
       "         'Locust': 2,\n",
       "         'Nexus': 2,\n",
       "         'O365': 1,\n",
       "         '.NET Core': 7,\n",
       "         'OpenGL': 8,\n",
       "         'Fortran': 1,\n",
       "         'Metasploit': 1,\n",
       "         'Microsoft Deployment Toolkit': 1,\n",
       "         'FOG': 1,\n",
       "         'Vulkan': 3,\n",
       "         'Talend': 4,\n",
       "         'Envoy Proxy': 1,\n",
       "         'Nginx': 4,\n",
       "         'CentOS': 10,\n",
       "         'VHDL': 2,\n",
       "         'IBM Cloud': 2,\n",
       "         'SparkML': 9,\n",
       "         'Adobe Analytics': 4,\n",
       "         'EPICS': 3,\n",
       "         'FME Desktop': 2,\n",
       "         'FME Server': 2,\n",
       "         'Virtual Agent Designer': 2,\n",
       "         'Cognitive Search': 2,\n",
       "         'Couchbase': 5,\n",
       "         'Sketch': 7,\n",
       "         'WinDbg': 1,\n",
       "         'DataStage': 1,\n",
       "         'ARKit': 3,\n",
       "         'ARCore': 2,\n",
       "         'Yarn': 2,\n",
       "         '.NET Framework': 6,\n",
       "         'Google Tag Manager': 1,\n",
       "         'Tealium': 1,\n",
       "         'JupyterLab': 3,\n",
       "         'JupyterNotebook': 3,\n",
       "         'Heroku': 5,\n",
       "         'Sentry': 3,\n",
       "         'Rasa': 1,\n",
       "         'LUIS': 2,\n",
       "         'Lex': 2,\n",
       "         'PostGIS': 1,\n",
       "         'LeafletJS': 1,\n",
       "         'Obj C': 1,\n",
       "         'BluePrism': 3,\n",
       "         'Automation Anywhere': 3,\n",
       "         'Workfusion': 2,\n",
       "         'Hyperscience': 2,\n",
       "         'ABBY': 2,\n",
       "         'ABBYY': 1,\n",
       "         'Google Suite': 4,\n",
       "         'AdobeXD': 1,\n",
       "         'Salesforce.com': 4,\n",
       "         'MS Project': 3,\n",
       "         'Mercurial': 2,\n",
       "         'Slack': 5,\n",
       "         'Microsoft Cloud': 1,\n",
       "         'Pega': 1,\n",
       "         'Office 365': 1,\n",
       "         'Discord': 2,\n",
       "         'Zoom': 3,\n",
       "         'Perforce': 4,\n",
       "         'Sheet(s)': 2,\n",
       "         'Pytest': 7,\n",
       "         'Mypy': 2,\n",
       "         'Flake': 2,\n",
       "         'Pre Commit': 2,\n",
       "         'FastAPI': 2,\n",
       "         'PyQt': 1,\n",
       "         'Ziva': 1,\n",
       "         'Maya': 1,\n",
       "         'Mari': 1,\n",
       "         'Nuke': 1,\n",
       "         'Hootsuite': 1,\n",
       "         'Asana': 1,\n",
       "         'Zoho': 1,\n",
       "         'ASP.NET': 6,\n",
       "         'Altium Designer': 1,\n",
       "         'OrCAD': 1,\n",
       "         'Omnify': 1,\n",
       "         'Avaya': 2,\n",
       "         'Botmock': 1,\n",
       "         'Botsociety': 1,\n",
       "         'Lucid Chart': 1,\n",
       "         'Amazon Connect': 1,\n",
       "         'Nuance': 1,\n",
       "         'PureCloud': 1,\n",
       "         'PureConnect': 1,\n",
       "         'HubSpot': 2,\n",
       "         'Wordpress': 4,\n",
       "         'Xamarin': 4,\n",
       "         'Sling': 4,\n",
       "         'OSGI': 4,\n",
       "         'Felix': 2,\n",
       "         'Jackrabbit': 1,\n",
       "         'JCR': 2,\n",
       "         'Mustache': 2,\n",
       "         'Handlebars': 2,\n",
       "         'Drupal': 1,\n",
       "         'Oak': 1,\n",
       "         'Dispatcher': 1,\n",
       "         'Calico': 2,\n",
       "         'OpenTracing': 2,\n",
       "         'Jaeger': 2,\n",
       "         'MSTeams': 2,\n",
       "         'ScalaJS': 2,\n",
       "         'Linode': 1,\n",
       "         'Axure': 1,\n",
       "         'xSQL': 1,\n",
       "         'ClearSCADA': 1,\n",
       "         'Erlang': 2,\n",
       "         'InsightVM': 2,\n",
       "         'Nessus': 2,\n",
       "         'JavaOS': 1,\n",
       "         'VoiceXML': 2,\n",
       "         'Uniprot': 1,\n",
       "         'STRING': 1,\n",
       "         'Kegg': 1,\n",
       "         'OpenLDAP': 1,\n",
       "         'Elixir': 3,\n",
       "         'QML': 1,\n",
       "         'Max': 1,\n",
       "         'Pure Data': 1,\n",
       "         'Reaktor': 1,\n",
       "         'Microsoft 365': 1,\n",
       "         'Spinnaker': 2,\n",
       "         'Saleforce': 2,\n",
       "         'Craft': 1,\n",
       "         'ProtoBuf': 5,\n",
       "         'DigitalOcean': 2,\n",
       "         'Happo': 1,\n",
       "         'UML': 3,\n",
       "         'App Engine': 1,\n",
       "         'Webstorm': 1,\n",
       "         'Doc(s)': 1,\n",
       "         'Slide(s)': 1,\n",
       "         'SABA cloud': 1,\n",
       "         'Travelport': 1,\n",
       "         'Amadeus': 1,\n",
       "         'Sabre': 1,\n",
       "         'Druid': 2,\n",
       "         'IBM Watson': 2,\n",
       "         'Xcode': 2,\n",
       "         'Vuforia': 1,\n",
       "         'Anaplan': 3,\n",
       "         'Hyperion': 2,\n",
       "         'Adobe XD': 1,\n",
       "         'Adobe CC': 1,\n",
       "         'Invision': 2,\n",
       "         'Oracle Cloud': 1,\n",
       "         'ADONIS': 1,\n",
       "         'Autodesk': 1,\n",
       "         'Zendesk': 1,\n",
       "         'COBOL': 2,\n",
       "         'FileNet': 1,\n",
       "         'Alation': 2,\n",
       "         'IBM IGC': 2,\n",
       "         'Adobe Target': 1,\n",
       "         'Adobe Audience Manager': 1,\n",
       "         'Adobe Launch': 1,\n",
       "         'Cython': 1,\n",
       "         'Apple Health': 1,\n",
       "         'Google Fit': 1,\n",
       "         'OWASP': 1,\n",
       "         'ES2016': 2,\n",
       "         'Juju': 1,\n",
       "         'SysDig': 1,\n",
       "         'VCS': 1,\n",
       "         'Debussy': 1,\n",
       "         'RxSwift': 1,\n",
       "         'WebRTC': 1,\n",
       "         'JADE': 1,\n",
       "         'Hacklang': 1,\n",
       "         'HHVM': 1,\n",
       "         'IntelliJ': 1})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in count:\n",
    "    for entity in count[key]:\n",
    "        count[key][entity] = cnt[entity]\n",
    "count[\"test\"][\"Android\"] = cnt[\"Android\"] - cnt[\"Android Studio\"]\n",
    "count[\"test\"][\"Argo\"] = cnt[\"Argo\"] - cnt[\"Argo CD\"]\n",
    "count[\"test\"][\"Azure\"] = cnt[\"Azure\"] - cnt[\"Azure Data Lake\"] - cnt[\"Azure DevOps\"] - cnt[\"Azure Machine Learning\"] - cnt[\"Azure SQL\"]\n",
    "count[\"test\"][\"C\"] = cnt[\"C\"] - cnt[\"C#\"] - cnt[\"Objective C\"] - cnt[\"Obj C\"]\n",
    "count[\"test\"][\"R\"] = cnt[\"R\"] - cnt[\"R Shiny\"]\n",
    "count[\"test\"][\"React\"] = cnt[\"React\"] - cnt[\"React Native\"]\n",
    "count[\"test\"][\"Ruby\"] = cnt[\"Ruby\"] - cnt[\"Ruby on Rails\"]\n",
    "count[\"test\"][\"SQL\"] = cnt[\"SQL\"] - cnt[\"Azure SQL\"] - cnt[\"Microsoft SQL Server\"]\n",
    "count[\"test\"][\"Visual Studio\"] = cnt[\"Visual Studio\"] - cnt[\"Visual Studio Code\"]\n",
    "count[\"test\"][\"ABBYY\"] = cnt[\"ABBYY\"] + cnt[\"ABBY\"]\n",
    "count[\"test\"][\"Adobe XD\"] = cnt[\"Adobe XD\"] + cnt[\"AdobeXD\"]\n",
    "count[\"test\"][\"App Engine\"] = cnt[\"App Engine\"] + cnt[\"AppEngine\"]\n",
    "count[\"test\"][\"Amazon Web Services\"] = cnt[\"Amazon Web Services\"] + cnt[\"AWS\"]\n",
    "count[\"test\"][\"Argo CD\"] = cnt[\"Argo CD\"] + cnt[\"ArgoCD\"]\n",
    "count[\"test\"][\"Azure\"] = cnt[\"Azure\"] + cnt[\"Microsoft Cloud\"]\n",
    "count[\"test\"][\"Azure DevOps\"] = cnt[\"Azure DevOps\"] + cnt[\"Microsoft TFS\"]\n",
    "count[\"test\"][\"Blue Prism\"] = cnt[\"Blue Prism\"] + cnt[\"BluePrism\"]\n",
    "count[\"test\"][\"C#\"] = cnt[\"C#\"] + cnt[\"C#/\"]\n",
    "count[\"test\"][\"Core ML\"] = cnt[\"Core ML\"] + cnt[\"CoreML\"]\n",
    "count[\"test\"][\"CSS\"] = cnt[\"CSS\"] + cnt[\"CSS3\"]\n",
    "count[\"test\"][\"Databrick(s)\"] = cnt[\"Databrick(s)\"] + cnt[\"Data bricks\"]\n",
    "count[\"test\"][\"Delta Lake\"] = cnt[\"Delta lake\"] + cnt[\"Delta\"]\n",
    "count[\"test\"][\"DynamoDB\"] = cnt[\"DynamoDB\"] + cnt[\"Dynamo DB\"]\n",
    "count[\"test\"][\"ECMAScript\"] = cnt[\"ECMAScript\"] + cnt[\"ES2016\"]\n",
    "count[\"test\"][\"ElasticSearch\"] = cnt[\"ElasticSearch\"] + cnt[\"Elastic Search\"]\n",
    "count[\"test\"][\"F#\"] = cnt[\"F#\"] + cnt[\"F#/\"]\n",
    "count[\"test\"][\"Flake8\"] = cnt[\"Flake8\"] + cnt[\"Flake\"]\n",
    "count[\"test\"][\"Google Cloud\"] = cnt[\"Google Cloud\"] + cnt[\"GCP\"]\n",
    "count[\"test\"][\"Go\"] = cnt[\"Go\"] + cnt[\"Golang\"]\n",
    "count[\"test\"][\"Google Analytics\"] = cnt[\"Google Analytics\"] + cnt[\"GA360\"]\n",
    "count[\"test\"][\"Hack\"] = cnt[\"Hack\"] + cnt[\"Hacklang\"]\n",
    "count[\"test\"][\"HTML\"] = cnt[\"HTML\"] + cnt[\"HTML5\"]\n",
    "count[\"test\"][\"Hyper V\"] = cnt[\"Hyper V\"] + cnt[\"HyperV\"]\n",
    "count[\"test\"][\"Jackrabbit\"] = cnt[\"Jackrabbit\"] + cnt[\"Oak\"]\n",
    "count[\"test\"][\"JavaScript\"] = cnt[\"JavaScript\"] + cnt[\"JS\"] + cnt[\"Java Script\"]\n",
    "count[\"test\"][\"Jupyter Notebook\"] = cnt[\"Jupyter Notebook\"] + cnt[\"JupyterNotebook\"]\n",
    "count[\"test\"][\"Kubernetes\"] = cnt[\"Kubernetes\"] + cnt[\"K8(s)\"]\n",
    "count[\"test\"][\"Leaflet\"] = cnt[\"Leaflet\"] + cnt[\"LeafletJS\"]\n",
    "count[\"test\"][\"Lucidchart\"] = cnt[\"Lucidchart\"] + cnt[\"Lucid Chart\"]\n",
    "count[\"test\"][\"MacOS\"] = cnt[\"MacOS\"] + cnt[\"Mac\"] + cnt[\"OS X\"]\n",
    "count[\"test\"][\"Microsoft 365\"] = cnt[\"Microsoft 365\"] + cnt[\"Office 365\"] + cnt[\"O365\"] + cnt[\"MS 365\"]\n",
    "count[\"test\"][\"Microsoft Office\"] = cnt[\"Microsoft Office\"] + cnt[\"MS Office\"]\n",
    "count[\"test\"][\"Microsoft Project\"] = cnt[\"Microsoft Project\"] + cnt[\"MS Project\"]\n",
    "count[\"test\"][\"Microsoft SQL Server\"] = cnt[\"Microsoft SQL Server\"] + cnt[\"SQLServer\"]\n",
    "count[\"test\"][\"Microsoft Teams\"] = cnt[\"Microsoft Teams\"] + cnt[\"MSTeams\"]\n",
    "count[\"test\"][\"MLlib\"] = cnt[\"MLlib\"] + cnt[\"SparkML\"]\n",
    "count[\"test\"][\".NET\"] = cnt[\".NET\"] + cnt[\"NET\"]\n",
    "count[\"test\"][\"Node.js\"] = cnt[\"Node.js\"] + cnt[\"Node\"] + cnt[\"NodeJS\"]\n",
    "count[\"test\"][\"Objective C\"] = cnt[\"Objective C\"] + cnt[\"Obj C\"]\n",
    "count[\"test\"][\"PostgreSQL\"] = cnt[\"PostgreSQL\"] + cnt[\"Postgres\"]\n",
    "count[\"test\"][\"Power BI\"] = cnt[\"Power BI\"] + cnt[\"PowerBI\"]\n",
    "count[\"test\"][\"React\"] = cnt[\"React\"] + cnt[\"React.js\"] + cnt[\"ReactJS\"]\n",
    "count[\"test\"][\"Salesforce\"] = cnt[\"Salesforce\"] + cnt[\"Salesforce.com\"] + cnt[\"Saleforce\"]\n",
    "count[\"test\"][\"Scala.js\"] = cnt[\"Scala.js\"] + cnt[\"ScalaJS\"]\n",
    "count[\"test\"][\"SciKit Learn\"] = cnt[\"SciKit Learn\"] + cnt[\"SKlearn\"]\n",
    "count[\"test\"][\"Subversion\"] = cnt[\"Subversion\"] + cnt[\"SVN\"]\n",
    "count[\"test\"][\"Sumo Logic\"] = cnt[\"Sumo Logic\"] + cnt[\"SumoLogic\"]\n",
    "count[\"test\"][\"TensorFlow\"] = cnt[\"TensorFlow\"] + cnt[\"Tensor Flow\"]\n",
    "count[\"test\"][\"TestRail\"] = cnt[\"TestRail\"] + cnt[\"Test Rail\"]\n",
    "count[\"test\"][\"Visual Studio Code\"] = cnt[\"Visual Studio Code\"] + cnt[\"VSCode\"]\n",
    "count[\"test\"][\"Vue.js\"] = cnt[\"Vue.js\"] + cnt[\"Vue\"]\n",
    "del count[\"test\"][\"ABBY\"]\n",
    "del count[\"test\"][\"AdobeXD\"]\n",
    "del count[\"test\"][\"AppEngine\"]\n",
    "del count[\"test\"][\"AWS\"]\n",
    "del count[\"test\"][\"ArgoCD\"]\n",
    "del count[\"test\"][\"Microsoft Cloud\"]\n",
    "del count[\"test\"][\"Microsoft TFS\"]\n",
    "del count[\"test\"][\"BluePrism\"]\n",
    "del count[\"test\"][\"C#/\"]\n",
    "del count[\"test\"][\"CoreML\"]\n",
    "del count[\"test\"][\"CSS3\"]\n",
    "del count[\"test\"][\"Data bricks\"]\n",
    "del count[\"test\"][\"Delta\"]\n",
    "del count[\"test\"][\"Dynamo DB\"]\n",
    "del count[\"test\"][\"ES2016\"]\n",
    "del count[\"test\"][\"Elastic Search\"]\n",
    "del count[\"test\"][\"F#/\"]\n",
    "del count[\"test\"][\"Flake\"]\n",
    "del count[\"test\"][\"GCP\"]\n",
    "del count[\"test\"][\"Golang\"]\n",
    "del count[\"test\"][\"GA360\"]\n",
    "del count[\"test\"][\"HTML5\"]\n",
    "del count[\"test\"][\"HyperV\"]\n",
    "del count[\"test\"][\"Oak\"]\n",
    "del count[\"test\"][\"JS\"]\n",
    "del count[\"test\"][\"Java Script\"]\n",
    "del count[\"test\"][\"JupyterNotebook\"]\n",
    "del count[\"test\"][\"K8(s)\"]\n",
    "del count[\"test\"][\"LeafletJS\"]\n",
    "del count[\"test\"][\"Lucid Chart\"]\n",
    "del count[\"test\"][\"Mac\"]\n",
    "del count[\"test\"][\"OS X\"]\n",
    "del count[\"test\"][\"Office 365\"]\n",
    "del count[\"test\"][\"O365\"]\n",
    "del count[\"test\"][\"MS 365\"]\n",
    "del count[\"test\"][\"MS Office\"]\n",
    "del count[\"test\"][\"MS Project\"]\n",
    "del count[\"test\"][\"SQLServer\"]\n",
    "del count[\"test\"][\"MSTeams\"]\n",
    "del count[\"test\"][\"SparkML\"]\n",
    "del count[\"test\"][\"NET\"]\n",
    "del count[\"test\"][\"Node\"]\n",
    "del count[\"test\"][\"NodeJS\"]\n",
    "del count[\"test\"][\"Obj C\"]\n",
    "del count[\"test\"][\"Postgres\"]\n",
    "del count[\"test\"][\"PowerBI\"]\n",
    "del count[\"test\"][\"React.js\"]\n",
    "del count[\"test\"][\"ReactJS\"]\n",
    "del count[\"test\"][\"Salesforce.com\"]\n",
    "del count[\"test\"][\"Saleforce\"]\n",
    "del count[\"test\"][\"ScalaJS\"]\n",
    "del count[\"test\"][\"SKlearn\"]\n",
    "del count[\"test\"][\"SVN\"]\n",
    "del count[\"test\"][\"SumoLogic\"]\n",
    "del count[\"test\"][\"Tensor Flow\"]\n",
    "del count[\"test\"][\"Test Rail\"]\n",
    "del count[\"test\"][\"VSCode\"]\n",
    "del count[\"test\"][\"Vue\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'test': {'ABBYY': 3,\n",
       "              'Adobe Analytics': 4,\n",
       "              'Adobe Audience Manager': 1,\n",
       "              'Adobe CC': 1,\n",
       "              'Adobe Launch': 1,\n",
       "              'Adobe Target': 1,\n",
       "              'Adobe XD': 2,\n",
       "              'ADONIS': 1,\n",
       "              'AFT Fathom': 1,\n",
       "              'Airflow': 34,\n",
       "              'AKS': 4,\n",
       "              'Alation': 2,\n",
       "              'Altium Designer': 1,\n",
       "              'Amadeus': 1,\n",
       "              'Amazon Connect': 1,\n",
       "              'Anaplan': 3,\n",
       "              'Android': 50,\n",
       "              'Android Studio': 0,\n",
       "              'Angular': 73,\n",
       "              'AngularJS': 8,\n",
       "              'Ansible': 40,\n",
       "              'Ansys': 1,\n",
       "              'Ant': 2,\n",
       "              'API Gateway': 5,\n",
       "              'APL': 0,\n",
       "              'App Engine': 2,\n",
       "              'Apple Health': 1,\n",
       "              'ArcGIS': 7,\n",
       "              'ARCore': 2,\n",
       "              'Argo': 2,\n",
       "              'Argo CD': 2,\n",
       "              'ARKit': 3,\n",
       "              'Asana': 1,\n",
       "              'ASP.NET': 6,\n",
       "              'Assembly': 3,\n",
       "              'Atom': 0,\n",
       "              'AutoCAD': 2,\n",
       "              'Autodesk': 1,\n",
       "              'Automation Anywhere': 3,\n",
       "              'Avaya': 2,\n",
       "              'Amazon Web Services': 411,\n",
       "              'Axure': 1,\n",
       "              'Azure': 356,\n",
       "              'Azure Data Lake': 8,\n",
       "              'Azure DevOps': 21,\n",
       "              'Azure Machine Learning': 6,\n",
       "              'Azure SQL': 7,\n",
       "              'Babylon.js': 2,\n",
       "              'Bash': 62,\n",
       "              'Bazel': 2,\n",
       "              'Beam': 16,\n",
       "              'BigQuery': 21,\n",
       "              'Bitbucket': 19,\n",
       "              'BlazeMeter': 1,\n",
       "              'Blue Prism': 6,\n",
       "              'Botmock': 1,\n",
       "              'Botsociety': 1,\n",
       "              'BSD': 2,\n",
       "              'Buck': 1,\n",
       "              'C#': 131,\n",
       "              'C++': 321,\n",
       "              'C': 165,\n",
       "              'Caffe': 8,\n",
       "              'Calico': 2,\n",
       "              'Camtasia': 1,\n",
       "              'Cassandra': 11,\n",
       "              'CentOS': 10,\n",
       "              'Ceph': 5,\n",
       "              'Chef': 16,\n",
       "              'ClearSCADA': 1,\n",
       "              'ClickHouse': 1,\n",
       "              'Clojure': 0,\n",
       "              'CloudFormation': 13,\n",
       "              'CMake': 1,\n",
       "              'COBOL': 2,\n",
       "              'Cognitive Search': 2,\n",
       "              'Collibra': 3,\n",
       "              'Confluence': 40,\n",
       "              'Cordova': 3,\n",
       "              'Core ML': 3,\n",
       "              'Cosmos DB': 7,\n",
       "              'Couchbase': 5,\n",
       "              'Craft': 1,\n",
       "              'CSS': 102,\n",
       "              'Cucumber': 4,\n",
       "              'CUDA': 21,\n",
       "              'Cykit': 1,\n",
       "              'Cypher': 2,\n",
       "              'Cypress': 6,\n",
       "              'Cython': 1,\n",
       "              'Dart': 1,\n",
       "              'Dash': 1,\n",
       "              'Dask': 9,\n",
       "              'Databrick(s)': 49,\n",
       "              'Datadog': 6,\n",
       "              'DataFlow': 2,\n",
       "              'DataRobot': 1,\n",
       "              'DataStage': 1,\n",
       "              'Data Studio': 4,\n",
       "              'DB2': 7,\n",
       "              'DBT': 4,\n",
       "              'Debian': 6,\n",
       "              'Debussy': 1,\n",
       "              'Delphi': 0,\n",
       "              'Delta lake': 2,\n",
       "              'Deno': 0,\n",
       "              'Dialogflow': 2,\n",
       "              'DigitalOcean': 2,\n",
       "              'DirectX': 6,\n",
       "              'Discord': 2,\n",
       "              'Dispatcher': 1,\n",
       "              'Django': 30,\n",
       "              'DNS': 8,\n",
       "              'Doc(s)': 1,\n",
       "              'Docker(s)': 179,\n",
       "              'DPDK': 2,\n",
       "              'Druid': 2,\n",
       "              'Drupal': 1,\n",
       "              'DVC': 2,\n",
       "              'DynamoDB': 32,\n",
       "              'Dynatrace': 5,\n",
       "              'EC2': 22,\n",
       "              'Eclipse': 4,\n",
       "              'ECMAScript': 4,\n",
       "              'ECS': 18,\n",
       "              'EKS': 17,\n",
       "              'Elastic Beanstalk': 1,\n",
       "              'ElasticSearch': 38,\n",
       "              'Electron': 3,\n",
       "              'Elixir': 3,\n",
       "              'ELK': 12,\n",
       "              'Eloquent': 1,\n",
       "              'Emacs': 0,\n",
       "              'EMR': 25,\n",
       "              'Envoy Proxy': 1,\n",
       "              'EPICS': 3,\n",
       "              'Erlang': 2,\n",
       "              'Erwin': 2,\n",
       "              'Excel': 104,\n",
       "              'Express': 10,\n",
       "              'F#': 0,\n",
       "              'Falcon': 2,\n",
       "              'Fast.io': 3,\n",
       "              'FastAPI': 2,\n",
       "              'Felix': 2,\n",
       "              'Figma': 8,\n",
       "              'FileNet': 1,\n",
       "              'Firebase': 4,\n",
       "              'Flake8': 2,\n",
       "              'Flask': 12,\n",
       "              'Flink': 9,\n",
       "              'Flood.io': 1,\n",
       "              'Flow': 8,\n",
       "              'Flutter': 4,\n",
       "              'FME Desktop': 2,\n",
       "              'FME Server': 2,\n",
       "              'FOG': 1,\n",
       "              'Fortran': 1,\n",
       "              'Gatsby': 1,\n",
       "              'Google Cloud': 136,\n",
       "              'GDB': 2,\n",
       "              'Gimp': 2,\n",
       "              'Git': 141,\n",
       "              'GitHub': 54,\n",
       "              'Gitlab': 39,\n",
       "              'GKE': 4,\n",
       "              'Glow': 2,\n",
       "              'Gmail': 2,\n",
       "              'Go': 96,\n",
       "              'Google Ads': 2,\n",
       "              'Google Analytics': 9,\n",
       "              'Google Calendar': 2,\n",
       "              'Google Fit': 1,\n",
       "              'Google Marketing Platform': 2,\n",
       "              'Google Suite': 4,\n",
       "              'Google Tag Manager': 1,\n",
       "              'Gradle': 3,\n",
       "              'Grafana': 11,\n",
       "              'GraphQL': 17,\n",
       "              'Groovy': 6,\n",
       "              'GRPC': 6,\n",
       "              'GStreamer': 2,\n",
       "              'H2O': 7,\n",
       "              'Hack': 1,\n",
       "              'Hacklang': 1,\n",
       "              'Hadoop': 104,\n",
       "              'Handlebars': 2,\n",
       "              'Happo': 1,\n",
       "              'Haskell': 1,\n",
       "              'HBase': 13,\n",
       "              'Heroku': 5,\n",
       "              'HDInsight(s)': 0,\n",
       "              'HHVM': 1,\n",
       "              'Hibernate': 9,\n",
       "              'HIP': 0,\n",
       "              'Hive': 50,\n",
       "              'HLSL': 2,\n",
       "              'Hootsuite': 1,\n",
       "              'Horovod': 3,\n",
       "              'HTML': 89,\n",
       "              'HubSpot': 2,\n",
       "              'Hudi': 1,\n",
       "              'Hyperion': 2,\n",
       "              'Hyperscience': 2,\n",
       "              'Hyper V': 4,\n",
       "              'IBM Cloud': 2,\n",
       "              'IBM IGC': 2,\n",
       "              'IBM Watson': 2,\n",
       "              'Iceberg': 1,\n",
       "              'Illustrator': 3,\n",
       "              'InfluxDB': 8,\n",
       "              'Informatica': 12,\n",
       "              'InsightVM': 2,\n",
       "              'InSpec': 0,\n",
       "              'IntelliJ': 1,\n",
       "              'Invision': 2,\n",
       "              'iOS': 57,\n",
       "              'Istio': 4,\n",
       "              'Ixia': 1,\n",
       "              'Jackrabbit': 2,\n",
       "              'JADE': 1,\n",
       "              'Jaeger': 2,\n",
       "              'Java': 373,\n",
       "              'JavaOS': 1,\n",
       "              'JavaScript': 271,\n",
       "              'JCR': 2,\n",
       "              'Jenkins': 79,\n",
       "              'Jetson': 0,\n",
       "              'Jira': 93,\n",
       "              'JMeter': 5,\n",
       "              'JMP': 1,\n",
       "              'jQuery': 20,\n",
       "              'Juju': 1,\n",
       "              'Julia': 2,\n",
       "              'Jupyter': 8,\n",
       "              'JupyterLab': 3,\n",
       "              'Jupyter Notebook': 4,\n",
       "              'Kafka': 56,\n",
       "              'Karate': 1,\n",
       "              'Kegg': 1,\n",
       "              'Keras': 38,\n",
       "              'Kibana': 7,\n",
       "              'Kinesis': 20,\n",
       "              'Kotlin': 13,\n",
       "              'Ksh': 1,\n",
       "              'Kubeflow': 8,\n",
       "              'Kubernetes': 193,\n",
       "              'Lambda(s)': 33,\n",
       "              'Laravel': 8,\n",
       "              'LDQ': 0,\n",
       "              'Leaflet': 1,\n",
       "              'Lex': 2,\n",
       "              'Linode': 1,\n",
       "              'Linux': 271,\n",
       "              'LISP': 0,\n",
       "              'LLDB': 1,\n",
       "              'LLVM': 11,\n",
       "              'Locust': 2,\n",
       "              'Logstash': 4,\n",
       "              'Looker': 7,\n",
       "              'Lua': 4,\n",
       "              'Lucene': 4,\n",
       "              'Lucidchart': 1,\n",
       "              'LUIS': 2,\n",
       "              'MacOS': 31,\n",
       "              'Mari': 1,\n",
       "              'MariaDB': 0,\n",
       "              'MasterCAM': 1,\n",
       "              'Mathcad': 1,\n",
       "              'Matlab': 21,\n",
       "              'Matplotlib': 11,\n",
       "              'Maven': 6,\n",
       "              'Max': 1,\n",
       "              'Maya': 1,\n",
       "              'Mercurial': 2,\n",
       "              'Metasploit': 1,\n",
       "              'Microsoft 365': 4,\n",
       "              'Microsoft Deployment Toolkit': 1,\n",
       "              'Microsoft Office': 52,\n",
       "              'Microsoft Project': 5,\n",
       "              'Microsoft SQL Server': 8,\n",
       "              'Microsoft Teams': 2,\n",
       "              'MicroStation': 1,\n",
       "              'Microstrategy': 4,\n",
       "              'MLFlow': 8,\n",
       "              'MLlib': 14,\n",
       "              'Mocha': 5,\n",
       "              'Mockito': 1,\n",
       "              'MongoDB': 35,\n",
       "              'Mustache': 2,\n",
       "              'MXNet': 12,\n",
       "              'Mypy': 2,\n",
       "              'MySQL': 59,\n",
       "              'Neo4j': 5,\n",
       "              'Neovim': 0,\n",
       "              'Nessus': 2,\n",
       "              'NestJS': 1,\n",
       "              '.NET': 59,\n",
       "              '.NET Core': 7,\n",
       "              '.NET Framework': 6,\n",
       "              'NetBeans': 0,\n",
       "              'New Relic': 3,\n",
       "              'Nexus': 2,\n",
       "              'Nginx': 4,\n",
       "              'NLTK': 6,\n",
       "              'Node.js': 71,\n",
       "              'Notepad++': 0,\n",
       "              'Nuance': 1,\n",
       "              'Nuke': 1,\n",
       "              'NumPy': 35,\n",
       "              'OAuth': 4,\n",
       "              'Objective C': 9,\n",
       "              'Omnify': 1,\n",
       "              'Onshape': 1,\n",
       "              'ONNX': 8,\n",
       "              'OpenCl': 15,\n",
       "              'OpenCV': 23,\n",
       "              'OpenGL': 8,\n",
       "              'OpenLDAP': 1,\n",
       "              'OpenMP': 1,\n",
       "              'OpenShift': 12,\n",
       "              'Openstack': 7,\n",
       "              'OpenTracing': 2,\n",
       "              'OpenVINO': 5,\n",
       "              'Oracle': 56,\n",
       "              'Oracle Cloud': 1,\n",
       "              'OrCAD': 1,\n",
       "              'OSGI': 4,\n",
       "              'OWASP': 1,\n",
       "              'PagerDuty': 4,\n",
       "              'Pandas': 44,\n",
       "              'Pega': 1,\n",
       "              'Perforce': 4,\n",
       "              'Perl': 44,\n",
       "              'Photoshop': 7,\n",
       "              'PHP': 33,\n",
       "              'PHPStorm': 0,\n",
       "              'PlayFab': 1,\n",
       "              'PostGIS': 1,\n",
       "              'PostgreSQL': 75,\n",
       "              'Power BI': 51,\n",
       "              'Powerpoint': 52,\n",
       "              'PowerShell': 20,\n",
       "              'Pre Commit': 2,\n",
       "              'Presto': 11,\n",
       "              'Prometheus': 14,\n",
       "              'ProtoBuf': 5,\n",
       "              'Protractor': 6,\n",
       "              'Pulumi': 0,\n",
       "              'Puppet': 15,\n",
       "              'PureCloud': 1,\n",
       "              'PureConnect': 1,\n",
       "              'Pure Data': 1,\n",
       "              'PyCharm': 3,\n",
       "              'PyQt': 1,\n",
       "              'PySpark': 9,\n",
       "              'Pytest': 7,\n",
       "              'Python': 732,\n",
       "              'PyTorch': 96,\n",
       "              'QGIS': 5,\n",
       "              'Qlik': 2,\n",
       "              'QML': 1,\n",
       "              'Qt': 4,\n",
       "              'Quarkus': 4,\n",
       "              'R': 108,\n",
       "              'RabbitMQ': 15,\n",
       "              'Radium': 0,\n",
       "              'RAML': 1,\n",
       "              'Rasa': 1,\n",
       "              'React': 149,\n",
       "              'React Native': 10,\n",
       "              'Reaktor': 1,\n",
       "              'Redis': 28,\n",
       "              'Redshift': 51,\n",
       "              'Redux': 9,\n",
       "              'RESTful': 26,\n",
       "              'Restlet': 2,\n",
       "              'Rider': 0,\n",
       "              'Rook': 3,\n",
       "              'ROS': 6,\n",
       "              'R Shiny': 2,\n",
       "              'RSpec': 1,\n",
       "              'RStudio': 0,\n",
       "              'Ruby': 37,\n",
       "              'RubyMine': 0,\n",
       "              'Ruby on Rails': 8,\n",
       "              'Rust': 12,\n",
       "              'RxSwift': 1,\n",
       "              'S3': 43,\n",
       "              'SABA cloud': 1,\n",
       "              'Sabre': 1,\n",
       "              'SageMaker': 18,\n",
       "              'Salesforce': 17,\n",
       "              'SaltStack': 2,\n",
       "              'SAP': 23,\n",
       "              'SAS': 28,\n",
       "              'Scala': 53,\n",
       "              'Scala.js': 2,\n",
       "              'SciKit Learn': 53,\n",
       "              'Scipy': 14,\n",
       "              'Seaborn': 2,\n",
       "              'Selenium': 25,\n",
       "              'Sentry': 3,\n",
       "              'ServiceNow': 4,\n",
       "              'SharePoint': 14,\n",
       "              'Sheet(s)': 2,\n",
       "              'Shell': 35,\n",
       "              'SignalFx': 2,\n",
       "              'Singularity': 6,\n",
       "              'Sisense': 2,\n",
       "              'Sketch': 7,\n",
       "              'Slack': 5,\n",
       "              'Slide(s)': 1,\n",
       "              'Slim': 2,\n",
       "              'Sling': 4,\n",
       "              'Slurm': 7,\n",
       "              'Snowflake': 29,\n",
       "              'Solaris': 2,\n",
       "              'SolidWorks': 2,\n",
       "              'Solr': 4,\n",
       "              'Spark': 166,\n",
       "              'Spinnaker': 2,\n",
       "              'Splunk': 13,\n",
       "              'Spring': 26,\n",
       "              'Spring Boot': 7,\n",
       "              'SQL': 376,\n",
       "              'SQLite': 4,\n",
       "              'Statsmodel(s)': 2,\n",
       "              'Streamlit': 1,\n",
       "              'STRING': 1,\n",
       "              'Sublime Text': 0,\n",
       "              'Subversion': 10,\n",
       "              'Sumo Logic': 4,\n",
       "              'Svelte': 0,\n",
       "              'Swagger': 3,\n",
       "              'Swarm': 10,\n",
       "              'Swift': 10,\n",
       "              'Symfony': 0,\n",
       "              'SysDig': 1,\n",
       "              'Tableau': 70,\n",
       "              'Talend': 4,\n",
       "              'TBB': 0,\n",
       "              'Tealium': 1,\n",
       "              'TensorFlow': 139,\n",
       "              'Teradata': 6,\n",
       "              'Terraform': 62,\n",
       "              'TestRail': 2,\n",
       "              'TextMate': 0,\n",
       "              'Theano': 6,\n",
       "              'Three.js': 3,\n",
       "              'TM1Py': 1,\n",
       "              'Tomcat': 5,\n",
       "              'Torch': 3,\n",
       "              'Travelport': 1,\n",
       "              'TVM': 5,\n",
       "              'TypeScript': 52,\n",
       "              'Ubuntu': 19,\n",
       "              'UiPath': 6,\n",
       "              'UML': 3,\n",
       "              'Uniprot': 1,\n",
       "              'Unity': 13,\n",
       "              'Unix': 77,\n",
       "              'Unreal': 16,\n",
       "              'UrbanCode': 1,\n",
       "              'Vagrant': 2,\n",
       "              'Valgrind': 1,\n",
       "              'VBA': 9,\n",
       "              'VCS': 1,\n",
       "              'Verilog': 6,\n",
       "              'VHDL': 2,\n",
       "              'Vim': 0,\n",
       "              'Virtual Agent Designer': 2,\n",
       "              'Visio': 6,\n",
       "              'Visual Studio': 9,\n",
       "              'Visual Studio Code': 1,\n",
       "              'VMWare': 17,\n",
       "              'VoiceXML': 2,\n",
       "              'VPC(s)': 5,\n",
       "              'vSphere': 1,\n",
       "              'Vue.js': 31,\n",
       "              'Vuforia': 1,\n",
       "              'Vulkan': 3,\n",
       "              'Vyond': 1,\n",
       "              'WebdriverIO': 1,\n",
       "              'WebGL': 2,\n",
       "              'WebRTC': 1,\n",
       "              'Webstorm': 1,\n",
       "              'Whois': 1,\n",
       "              'WinDbg': 1,\n",
       "              'Windows': 111,\n",
       "              'Word': 52,\n",
       "              'Wordpress': 4,\n",
       "              'Workfusion': 2,\n",
       "              'WSL': 0,\n",
       "              'Xamarin': 4,\n",
       "              'Xcode': 2,\n",
       "              'XLA': 2,\n",
       "              'XML': 22,\n",
       "              'xSQL': 1,\n",
       "              'YAML': 1,\n",
       "              'Yarn': 2,\n",
       "              'Yocto': 5,\n",
       "              'Zendesk': 1,\n",
       "              'Ziva': 1,\n",
       "              'ZMQ': 1,\n",
       "              'Zoho': 1,\n",
       "              'Zookeeper': 3,\n",
       "              'Zoom': 3,\n",
       "              'Zsh': 1,\n",
       "              'Delta Lake': 7}})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sandi/.local/lib/python3.8/site-packages/spacy/displacy/__init__.py:205: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
      "  warnings.warn(Warnings.W006)\n"
     ]
    }
   ],
   "source": [
    "text = []\n",
    "options = {\"ents\": key_list, \"colors\": colours}\n",
    "for numb in range(len(dataset)):\n",
    "    doc = nlp(df_t.at[numb,'text'])\n",
    "    text.append(doc)\n",
    "html = displacy.render(text, style=\"ent\", page = True, jupyter = False, options = options)\n",
    "file = open(\"TEST_HTML.html\",\"w\")\n",
    "file.write(html)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = pd.DataFrame(columns=['type', 'tech', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for key in count:\n",
    "    for lock in count[key]:\n",
    "        value = count[key][lock]\n",
    "        cdf.at[i] = [key, lock, value] \n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>tech</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>ABBYY</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>Adobe Analytics</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>Adobe Audience Manager</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>Adobe CC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test</td>\n",
       "      <td>Adobe Launch</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>test</td>\n",
       "      <td>Zoho</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>test</td>\n",
       "      <td>Zookeeper</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>test</td>\n",
       "      <td>Zoom</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>test</td>\n",
       "      <td>Zsh</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>test</td>\n",
       "      <td>Delta Lake</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>510 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     type                    tech count\n",
       "0    test                   ABBYY     3\n",
       "1    test         Adobe Analytics     4\n",
       "2    test  Adobe Audience Manager     1\n",
       "3    test                Adobe CC     1\n",
       "4    test            Adobe Launch     1\n",
       "..    ...                     ...   ...\n",
       "505  test                    Zoho     1\n",
       "506  test               Zookeeper     3\n",
       "507  test                    Zoom     3\n",
       "508  test                     Zsh     1\n",
       "509  test              Delta Lake     7\n",
       "\n",
       "[510 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf.to_csv('TEST_tech_counts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
